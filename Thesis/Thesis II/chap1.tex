\chapter{Introduction}

Cognates are words across different languages that are known to have originated from the same word in a common ancestral language. For example, the English word `\textit{Night}' and the German `\textit{Nacht}', both meaning \textit{night} and English `\textit{Hound}' and German `\textit{Hund}', meaning \textit{dog} are cognates whose origin can be traced back to Proto-Germanic \cite{rama2015automatic}. Cognates are not always revealingly similar and can change substantially over time such that they do not share form similarity. The English word `\textit{wheel}' and the Sanskrit word `\textit{chakra}' are in fact cognates which are traced back to `$*k^wek^welo$' from Proto-Indo-European.

Traditionally, the identification of cognates was carried out by historical linguists, using word lists and establishing sound correspondences between words. These are useful in determining linguistic distance within a language family, and also to understand the process of language change. While the task of cognate identification is an interesting problem in its own right, cognate information has also been used in several downstream NLP tasks, like sentence alignment in bitexts \cite{simard1993using}, improving statistical machine translation models \cite{kondrak2003cognates}, inducing translation lexicons \cite{mann2001multipath}\cite{tufis2002cheap} and identification of confusable drug names \cite{kondrak2004identification}. Additionally, it has been proposed that cognates can be used to share lexical resources among languages that are closely related \citep{Singh:07b}. 

For some time now, there has been a growing interest in automatic cognate identification techniques. Most approaches for this task focus on finding similarity measures between a pair of words (e.g. orthographic or phonetic similarity). \cite{hauer2011clustering} \cite{inkpen2005similarity} \cite{List2016g}. These are used as features for classifiers to identify cognacy for a particular word-pair. Surface similarity measures like these miss out on capturing generalizations beyond string similarity. For example, the cognate words \textit{Que} in Spanish and \textit{Hvad} in Danish both map to the concept \textsc{WHAT}, but have nothing in common with each other orthographically. For such pairs, surface similarity measures that rely on sub-sequence similarity are not useful. Instead, we require information about phonological similarity that is beyond surface similarity, such as the sound correspondences that are used in historical linguistics to narrow down candidate pairs as cognates.

Our work shows that an end-to-end recurrent neural network based model is able to outperform both surface similarity as well as a recent Convolutional Neural Network based Siamese-style model \citep{rama2016siamese} on the task. LSTM (Long Short Term Memory) networks are being used in an extensive range of NLP tasks to build end-to-end systems. LSTMs have been successfully applied to machine translation \citep{bahdanau2014neural}. language modeling \citep{mikolov2010recurrent}, information retrieval \citep{sordoni2015hierarchical} and RTE \citep{snli:emnlp2015}. In the subsequent sections, we describe our LSTM based Siamese-style architecture which uses character by character attention to enrich the representations of the input word pairs and make the cognate prediction. We perform thorough analysis on the performance of our model and compare it against existing supervised approaches, including the subsequence model described in \citep{rama2015automatic} and its variants.

The task of discovering cognates can possibly be particularly useful among the languages of South Asia, which are not rich in lexical resources. Information about cognates can become an important source for assisting the creation and sharing of lexical resources between languages. Therefore, another contribution of this work is to apply our cognate detection model to a real language pair. We apply our model to the domain of Hindi-Marathi, using a large unlabeled corpus of aligned texts to find cognate pairs.

In the following chapters, we first describe the previous works on this task followed by the datasets and language families used in our work. In chapter 4, we explore the models that exploit surface similarity between words highlighting its limitations and reasoning why a richer representation and alignment is needed for the task. Chapter 5 introduces our LSTM based end-to-end neural network model and its performance and comparisons with other models, including the results from the Hindi-Marathi domain test.
