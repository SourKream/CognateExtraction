32  CHARACTERS
[' ', '"', '%', '3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', '~']
30  LANGUAGES
['SIPAKAPENSE', 'TZUTUJIL_SAN_JUAN_LA_LAGUNA', 'MAM_NORTHERN', 'CHORTI', 'POQOMCHI_WESTERN', 'TZELTAL_BACHAJON', 'SOUTHERN_CAKCHIQUEL_SAN_ANDRES_ITZAPA', 'MAYA_YUCATAN', 'CHONTAL_TABASCO', 'CENTRAL_QUICHE', 'EASTERN_KEKCHI_CAHABON', 'TECO_TECTITAN', 'JACALTEC', 'QANJOBAL_SANTA_EULALIA', 'LACANDON', 'ZINACANTAN_TZOTZIL', 'POCOMAM_EASTERN', 'IXIL_CHAJUL', 'CHUJ', 'CHOL_TUMBALA', 'AGUACATEC', 'MOPAN', 'MOCHO', 'ITZAJ', 'HUASTEC', 'USPANTEKO', 'ACATECO_SAN_MIGUEL_ACATAN', 'SACAPULTECO_SACAPULAS_CENTRO', 'TOJOLABAL', 'CHICOMUCELTEC']
lstm_units 40
epochs 40
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Vocab Size :  34
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       340
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 80)	       16320
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 80)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 80), (Non 25680
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 160)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 160)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       3220
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 45,581.0
Trainable params: 45,581.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/40
25472/25473 [============================>.] - ETA: 0ss--loss::1.06360

Training -> Precision:	0.594286644421	 Recall:  0.759517370501	 F-Score:  0.666818866718
Testing	 -> Precision:	0.476033057851	 Recall:  0.65306122449		 F-Score:  0.550669216061

25473/25473 [==============================] - 36s - loss: 1.0636
Epoch 2/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.81090

Training -> Precision:	0.58093346574	 Recall:  0.791033908883	 F-Score:  0.669896498569
Testing	 -> Precision:	0.464285714286	 Recall:  0.678004535147	 F-Score:  0.551152073733

25473/25473 [==============================] - 29s - loss: 0.8109
Epoch 3/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.77362

Training -> Precision:	0.684282907662	 Recall:  0.724568337841	 F-Score:  0.70384965141
Testing	 -> Precision:	0.54641350211	 Recall:  0.587301587302	 F-Score:  0.566120218579

25473/25473 [==============================] - 29s - loss: 0.7736
Epoch 4/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.73918

Training -> Precision:	0.66550554588	 Recall:  0.755148741419	 F-Score:  0.707498903669
Testing	 -> Precision:	0.541425818882	 Recall:  0.637188208617	 F-Score:  0.585416666667

25473/25473 [==============================] - 29s - loss: 0.7391
Epoch 5/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.71567

Training -> Precision:	0.751928846978	 Recall:  0.729873101727	 F-Score:  0.740736830993
Testing	 -> Precision:	0.611607142857	 Recall:  0.621315192744	 F-Score:  0.616422947132

25473/25473 [==============================] - 29s - loss: 0.7156
Epoch 6/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.69097

Training -> Precision:	0.881538685706	 Recall:  0.629290617849	 F-Score:  0.73435698246
Testing	 -> Precision:	0.753623188406	 Recall:  0.471655328798	 F-Score:  0.58019525802

25473/25473 [==============================] - 29s - loss: 0.6909
Epoch 7/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.69817

Training -> Precision:	0.801570801571	 Recall:  0.721863948409	 F-Score:  0.759632224168
Testing	 -> Precision:	0.681462140992	 Recall:  0.591836734694	 F-Score:  0.633495145631

25473/25473 [==============================] - 29s - loss: 0.6980
Epoch 8/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.68364

Training -> Precision:	0.764430577223	 Recall:  0.764510089453	 F-Score:  0.76447033127
Testing	 -> Precision:	0.631696428571	 Recall:  0.641723356009	 F-Score:  0.636670416198

25473/25473 [==============================] - 29s - loss: 0.6836
Epoch 9/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.68092

Training -> Precision:	0.584887924801	 Recall:  0.841377158311	 F-Score:  0.690069953933
Testing	 -> Precision:	0.495562130178	 Recall:  0.759637188209	 F-Score:  0.59982094897

25473/25473 [==============================] - 29s - loss: 0.6809
Epoch 10/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.78195

Training -> Precision:	0.567245044921	 Recall:  0.860307884335	 F-Score:  0.683694978301
Testing	 -> Precision:	0.492937853107	 Recall:  0.791383219955	 F-Score:  0.607484769365

25473/25473 [==============================] - 29s - loss: 0.7819
Epoch 11/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.76441

Training -> Precision:	0.788971756939	 Recall:  0.671208654046	 F-Score:  0.725341426404
Testing	 -> Precision:	0.652298850575	 Recall:  0.514739229025	 F-Score:  0.575411913815

25473/25473 [==============================] - 29s - loss: 0.7644
Epoch 12/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.88943

Training -> Precision:	0.378673284488	 Recall:  0.999895985022	 F-Score:  0.549314285714
Testing	 -> Precision:	0.304768486524	 Recall:  1.0	 F-Score:  0.467161016949

25473/25473 [==============================] - 29s - loss: 0.8895
Epoch 13/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.96226

Training -> Precision:	0.378777729619	 Recall:  0.999895985022	 F-Score:  0.549424170548
Testing	 -> Precision:	0.304768486524	 Recall:  1.0	 F-Score:  0.467161016949

25473/25473 [==============================] - 29s - loss: 0.9622
Epoch 14/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.95703

Training -> Precision:	0.377493324957	 Recall:  1.0	 F-Score:  0.548087338236
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9570
Epoch 15/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.95386

Training -> Precision:	0.377493324957	 Recall:  1.0	 F-Score:  0.548087338236
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9538
Epoch 16/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.95240

Training -> Precision:	0.377493324957	 Recall:  1.0	 F-Score:  0.548087338236
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9524
Epoch 17/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.95153

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9515
Epoch 18/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.95067

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9506
Epoch 19/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.95028

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9502
Epoch 20/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94969

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9496
Epoch 21/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94932

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9493
Epoch 22/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94961

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9496
Epoch 23/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94911

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9491
Epoch 24/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94924

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9492
Epoch 25/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94900

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9490
Epoch 26/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94925

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9492
Epoch 27/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94907

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9490
Epoch 28/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94943

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9494
Epoch 29/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94915

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9491
Epoch 30/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94907

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9490
Epoch 31/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94910

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9491
Epoch 32/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94890

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9489
Epoch 33/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94886

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9488
Epoch 34/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94888

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9488
Epoch 35/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94884

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9488
Epoch 36/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94895

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9489
Epoch 37/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94886

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9488
Epoch 38/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94878

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9487
Epoch 39/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94879

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9487
Epoch 40/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.94861

Training -> Precision:	0.377419228202	 Recall:  1.0	 F-Score:  0.548009234189
Testing	 -> Precision:	0.302469135802	 Recall:  1.0	 F-Score:  0.464454976303

25473/25473 [==============================] - 29s - loss: 0.9487
25473/25473 [==============================] - 13s: 0ss
1440/1458 [============================>.] - ETA: 0s

Average Precision Score 0.651234567901
Training
	     precision	  recall  f1-score   support

	  0	 0.000	   0.000     0.000     15859
	  1	 0.377	   1.000     0.548	9614

avg / total	 0.142	   0.377     0.207     25473

Testing
	     precision	  recall  f1-score   support

	  0	 0.000	   0.000     0.000	1017
	  1	 0.302	   1.000     0.464	 441

avg / total	 0.091	   0.302     0.140	1458

Testing Accuracy
0.302469135802
