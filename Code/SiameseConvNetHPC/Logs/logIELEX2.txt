38  CHARACTERS
[u'o', u'k', u's', u'i', u'f', u't', u'e', u'r', u'w', u'u', u'3', u'G', u'C', u'y', u'g', u'z', u'd', u'h', u'a', u'S', u'n', u'v', u'x', u'b', u'p', u'E', u'l', u'8', u'm', u'T', u'7', u'Z', u'L', u'c', u'5', u'N', u'j', u'q']
52  LANGUAGES
[u'ANCIENT_GREEK', u'GREEK', u'CLASSICAL_ARMENIAN', u'ARMENIAN_EASTERN', u'OSSETIC', u'OSSETIC_IRON', u'OSSETIC_DIGOR', u'BIHARI', u'URDU', u'MARATHI', u'OLD_CHURCH_SLAVONIC', u'SERBO-CROATIAN', u'BULGARIAN', u'MACEDONIAN', u'RUSSIAN', u'POLISH', u'BELARUSIAN', u'UKRAINIAN', u'SLOVAK', u'CZECH', u'SORBIAN_UPPER', u'SORBIAN_LOWER', u'SLOVENIAN', u'OLD_NORSE', u'ICELANDIC', u'FAROESE', u'NORWEGIAN_RIKSMAL', u'STAVANGERSK', u'OLD_SWEDISH', u'SWEDISH', u'ELFDALIAN', u'DANISH', u'DANISH_FJOLDE', u'GUTNISH_LAU', u'ENGLISH', u'FRISIAN', u'DUTCH', u'GERMAN', u'LATIN', u'PORTUGUESE', u'SPANISH', u'FRENCH', u'ITALIAN', u'OLD_IRISH', u'MIDDLE_CORNISH', u'MIDDLE_BRETON', u'IRISH', u'ORIYA', u'MAGAHI', u'CATALAN', u'BRETON', u'ASSAMESE']
lstm_units 40
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 6
Tokenize Simple False
Using Concept Fold Data False
No. of concepts 207
No. of training concepts 144 testing concepts 63
Vocab Size :  41
Building model
MASKING PRESENT
MASKING PRESENT
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 6)	       246
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 6)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 80)	       15040
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 80)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 80), (Non 25680
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 160)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 160)	       0
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       161
====================================================================================================
Total params: 41,127.0
Trainable params: 41,127.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.762133

Training -> Precision:	0.504609360396	 Recall:  0.829167744439	 F-Score:  0.62739989113
Testing	 -> Precision:	0.362508208972	 Recall:  0.742934051144	 F-Score:  0.487261437312

223666/223666 [==============================] - 350s - loss: 0.7621
Epoch 2/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.6838485

Training -> Precision:	0.483702515786	 Recall:  0.780183005691	 F-Score:  0.597168772351
Testing	 -> Precision:	0.355666682467	 Recall:  0.696477467861	 F-Score:  0.470874319512

223666/223666 [==============================] - 339s - loss: 0.6838
Epoch 3/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.754786

Training -> Precision:	0.624928555727	 Recall:  0.229791774444	 F-Score:  0.336024396875
Testing	 -> Precision:	0.487186091436	 Recall:  0.175569684875	 F-Score:  0.258119541485

223666/223666 [==============================] - 345s - loss: 0.7547
Epoch 4/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.8741275

Training -> Precision:	0.476311974485	 Recall:  0.265584583549	 F-Score:  0.341020903826
Testing	 -> Precision:	0.340822732529	 Recall:  0.191488374252	 F-Score:  0.245208450955

223666/223666 [==============================] - 333s - loss: 0.8741
Epoch 5/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.867059

Training -> Precision:	0.64459477622	 Recall:  0.232604759441	 F-Score:  0.341851099469
Testing	 -> Precision:	0.527383931054	 Recall:  0.176080196779	 F-Score:  0.264013082356

223666/223666 [==============================] - 331s - loss: 0.8670
Epoch 6/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.867786

Training -> Precision:	0.612073150995	 Recall:  0.244568028971	 F-Score:  0.349489442314
Testing	 -> Precision:	0.481382004639	 Recall:  0.182995312573	 F-Score:  0.26518259466

223666/223666 [==============================] - 330s - loss: 0.8677
Epoch 7/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.865911

Training -> Precision:	0.609596053611	 Recall:  0.211766037248	 F-Score:  0.314335765022
Testing	 -> Precision:	0.517504968659	 Recall:  0.157098435977	 F-Score:  0.241028197095

223666/223666 [==============================] - 331s - loss: 0.8659
Epoch 8/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.859077

Training -> Precision:	0.628014721801	 Recall:  0.234480082773	 F-Score:  0.341467434168
Testing	 -> Precision:	0.499463806971	 Recall:  0.172924305008	 F-Score:  0.25690350605

223666/223666 [==============================] - 330s - loss: 0.8590
Epoch 9/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.861594

Training -> Precision:	0.429180406981	 Recall:  0.258794619762	 F-Score:  0.322888407039
Testing	 -> Precision:	0.323185386957	 Recall:  0.187218638326	 F-Score:  0.23709189221

223666/223666 [==============================] - 330s - loss: 0.8615
Epoch 10/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.859784

Training -> Precision:	0.676986897354	 Recall:  0.216341179514	 F-Score:  0.327897773912
Testing	 -> Precision:	0.567787971458	 Recall:  0.155102798533	 F-Score:  0.243648160974

223666/223666 [==============================] - 330s - loss: 0.8597
Epoch 11/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.860092

Training -> Precision:	0.675084429659	 Recall:  0.216519011899	 F-Score:  0.327878083114
Testing	 -> Precision:	0.56752629793	 Recall:  0.155242029053	 F-Score:  0.243795780037

223666/223666 [==============================] - 330s - loss: 0.8600
Epoch 12/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.859838

Training -> Precision:	0.677123918433	 Recall:  0.216341179514	 F-Score:  0.32791384359
Testing	 -> Precision:	0.567691523696	 Recall:  0.155102798533	 F-Score:  0.243639279726

223666/223666 [==============================] - 330s - loss: 0.8598
Epoch 13/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.867094

Training -> Precision:	0.385987114588	 Recall:  0.325433264356	 F-Score:  0.353133113466
Testing	 -> Precision:	0.279775973692	 Recall:  0.252703392584	 F-Score:  0.265551464313

223666/223666 [==============================] - 330s - loss: 0.8670
Epoch 14/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.867027

Training -> Precision:	0.452575970533	 Recall:  0.301927056389	 F-Score:  0.36221174919
Testing	 -> Precision:	0.344531464688	 Recall:  0.232747018146	 F-Score:  0.277816247957

223666/223666 [==============================] - 330s - loss: 0.8670
Epoch 15/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.862702

Training -> Precision:	0.5777657682	 Recall:  0.414802121055	 F-Score:  0.48290594269
Testing	 -> Precision:	0.423846048487	 Recall:  0.287232561377	 F-Score:  0.342416111096

223666/223666 [==============================] - 330s - loss: 0.8626
Epoch 16/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.857386

Training -> Precision:	0.53466396099	 Recall:  0.285388644594	 F-Score:  0.372139597146
Testing	 -> Precision:	0.424626104691	 Recall:  0.23191163503		 F-Score:  0.299984991745

223666/223666 [==============================] - 332s - loss: 0.8573
Epoch 17/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.863879

Training -> Precision:	0.556563661321	 Recall:  0.268753233316	 F-Score:  0.362474788771
Testing	 -> Precision:	0.449423076923	 Recall:  0.216921149116	 F-Score:  0.292609634707

223666/223666 [==============================] - 330s - loss: 0.8638
Epoch 18/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.863537

Training -> Precision:	0.391806958474	 Recall:  0.338625193999	 F-Score:  0.363280030525
Testing	 -> Precision:	0.30014790636	 Recall:  0.273123868752	 F-Score:  0.285998930845

223666/223666 [==============================] - 330s - loss: 0.8635
Epoch 19/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.865380

Training -> Precision:	0.521439181383	 Recall:  0.255383471288	 F-Score:  0.342850321755
Testing	 -> Precision:	0.425871402792	 Recall:  0.208103216225	 F-Score:  0.27958598329

223666/223666 [==============================] - 338s - loss: 0.8653
Epoch 20/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.8638670

Training -> Precision:	0.415180822295	 Recall:  0.29287377134		 F-Score:  0.343463835435
Testing	 -> Precision:	0.299144304092	 Recall:  0.238501879612	 F-Score:  0.265403088364

223666/223666 [==============================] - 333s - loss: 0.8638
103040/103092 [============================>.] - ETA: 0sss

Average Precision Score 0.265718926446
Training
	     precision	  recall  f1-score   support

	  0	 0.757	   0.842     0.797    161810
	  1	 0.415	   0.293     0.343     61856

avg / total	 0.662	   0.690     0.672    223666

Testing
	     precision	  recall  f1-score   support

	  0	 0.809	   0.852     0.830     81545
	  1	 0.299	   0.239     0.265     21547

avg / total	 0.702	   0.724     0.712    103092

Testing Accuracy
0.724052302798
