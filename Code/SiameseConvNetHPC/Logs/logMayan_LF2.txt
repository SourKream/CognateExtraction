33  CHARACTERS
[u'i', u'n', u'k', u'e', u'h', u'a', u'y', u't', u'7', u'r', u'o', u'5', u'w', u'C', u'S', u'v', u'N', u'q', u'x', u'u', u'l', u'c', u'd', u'm', u'T', u'b', u's', u'3', u'p', u'g', u'8', u'f', u'X']
30  LANGUAGES
[u'HUASTEC', u'TOJOLABAL', u'CHUJ', u'JACALTEC', u'QANJOBAL_SANTA_EULALIA', u'ACATECO_SAN_MIGUEL_ACATAN', u'IXIL_CHAJUL', u'AGUACATEC', u'TECO_TECTITAN', u'MAM_NORTHERN', u'SIPAKAPENSE', u'SACAPULTECO_SACAPULAS_CENTRO', u'CENTRAL_QUICHE', u'SOUTHERN_CAKCHIQUEL_SAN_ANDRES_ITZAPA', u'TZUTUJIL_SAN_JUAN_LA_LAGUNA', u'POQOMCHI_WESTERN', u'POCOMAM_EASTERN', u'USPANTEKO', u'EASTERN_KEKCHI_CAHABON', u'TZELTAL_BACHAJON', u'CHOL_TUMBALA', u'CHORTI', u'ITZAJ', u'MOPAN', u'MAYA_YUCATAN', u'ZINACANTAN_TZOTZIL', u'CHONTAL_TABASCO', u'LACANDON', u'MOCHO', u'CHICOMUCELTEC']
lstm_units 15
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 8
Tokenize Simple False
Using Concept Fold Data False
No. of concepts 100
No. of training concepts 70 testing concepts 30
Vocab Size :  36
Building model
MASKING PRESENT
MASKING PRESENT
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 8)	       288
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 8)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 30)	       2880
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 30)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 30), (Non 3630
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 30)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 30)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 60)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 60)	       0
____________________________________________________________________________________________________
Input Lang Feat (InputLayer)	 (None, 30)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 90)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       1820
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 8,639.0
Trainable params: 8,639.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
28160/28222 [============================>.] - ETA: 0ss--loss::1.13803

Training -> Precision:	0.567843571881	 Recall:  0.684315970235	 F-Score:  0.620662801765
Testing	 -> Precision:	0.539123630673	 Recall:  0.80172213172		 F-Score:  0.644708524375

28222/28222 [==============================] - 48s - loss: 1.1373
Epoch 2/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.85636

Training -> Precision:	0.591573516767	 Recall:  0.721999618393	 F-Score:  0.650311493018
Testing	 -> Precision:	0.569776909298	 Recall:  0.814289038864	 F-Score:  0.670434949224

28222/28222 [==============================] - 35s - loss: 0.8564
Epoch 3/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.82118

Training -> Precision:	0.640891098223	 Recall:  0.664186224003	 F-Score:  0.652330756617
Testing	 -> Precision:	0.593521229868	 Recall:  0.754712590179	 F-Score:  0.664481098248

28222/28222 [==============================] - 35s - loss: 0.8215
Epoch 4/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.80439

Training -> Precision:	0.60536756126	 Recall:  0.742415569548	 F-Score:  0.666923769122
Testing	 -> Precision:	0.550937904269	 Recall:  0.792878752618	 F-Score:  0.650128804503

28222/28222 [==============================] - 35s - loss: 0.8043
Epoch 5/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.78668

Training -> Precision:	0.618074656189	 Recall:  0.750333905743	 F-Score:  0.677812728918
Testing	 -> Precision:	0.540941328175	 Recall:  0.781010006982	 F-Score:  0.639177221217

28222/28222 [==============================] - 35s - loss: 0.7867
Epoch 6/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.76163

Training -> Precision:	0.652279340446	 Recall:  0.769891242129	 F-Score:  0.70622210554
Testing	 -> Precision:	0.561394380853	 Recall:  0.753316267163	 F-Score:  0.643346914439

28222/28222 [==============================] - 35s - loss: 0.7614
Epoch 7/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.73141

Training -> Precision:	0.662782109151	 Recall:  0.770463651975	 F-Score:  0.712577756209
Testing	 -> Precision:	0.563124894086	 Recall:  0.773330230393	 F-Score:  0.651696411061

28222/28222 [==============================] - 35s - loss: 0.7313
Epoch 8/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.70634

Training -> Precision:	0.626638353958	 Recall:  0.816447242893	 F-Score:  0.709060027342
Testing	 -> Precision:	0.514273036533	 Recall:  0.809169187805	 F-Score:  0.628865979381

28222/28222 [==============================] - 35s - loss: 0.7063
Epoch 9/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.68610

Training -> Precision:	0.687013926569	 Recall:  0.72476626598		 F-Score:  0.705385329619
Testing	 -> Precision:	0.564816630712	 Recall:  0.670235047708	 F-Score:  0.613026819923

28222/28222 [==============================] - 35s - loss: 0.6860
Epoch 10/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.66613

Training -> Precision:	0.688002625964	 Recall:  0.799847357375	 F-Score:  0.739721192871
Testing	 -> Precision:	0.552541648868	 Recall:  0.602047940424	 F-Score:  0.576233433567

28222/28222 [==============================] - 35s - loss: 0.6660
Epoch 11/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.64330

Training -> Precision:	0.697746635879	 Recall:  0.836004579279	 F-Score:  0.760644069268
Testing	 -> Precision:	0.578150351541	 Recall:  0.746334652083	 F-Score:  0.651564404714

28222/28222 [==============================] - 35s - loss: 0.6434
Epoch 12/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.62114

Training -> Precision:	0.694754464286	 Recall:  0.831425300515	 F-Score:  0.756970381308
Testing	 -> Precision:	0.572165865812	 Recall:  0.748196416104	 F-Score:  0.648446954417

28222/28222 [==============================] - 35s - loss: 0.6214
Epoch 13/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.60287

Training -> Precision:	0.716776664222	 Recall:  0.83924823507		 F-Score:  0.7731927049
Testing	 -> Precision:	0.569173465768	 Recall:  0.746800093088	 F-Score:  0.645998993457

28222/28222 [==============================] - 35s - loss: 0.6024
Epoch 14/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.59054

Training -> Precision:	0.743993930709	 Recall:  0.842014882656	 F-Score:  0.789975385992
Testing	 -> Precision:	0.578441194149	 Recall:  0.671864091226	 F-Score:  0.621662360034

28222/28222 [==============================] - 35s - loss: 0.5902
Epoch 15/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.58134

Training -> Precision:	0.75206119847	 Recall:  0.844113718756	 F-Score:  0.795433092102
Testing	 -> Precision:	0.559243612955	 Recall:  0.64696299744		 F-Score:  0.599913681485

28222/28222 [==============================] - 35s - loss: 0.5813
Epoch 16/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.57044

Training -> Precision:	0.739995089615	 Recall:  0.862621637092	 F-Score:  0.796616889124
Testing	 -> Precision:	0.577247443029	 Recall:  0.74866185711		 F-Score:  0.651874366768

28222/28222 [==============================] - 35s - loss: 0.5704
Epoch 17/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.56179

Training -> Precision:	0.754337671004	 Recall:  0.862717038733	 F-Score:  0.80489541611
Testing	 -> Precision:	0.557196339434	 Recall:  0.62345822667		 F-Score:  0.588467874794

28222/28222 [==============================] - 35s - loss: 0.5617
Epoch 18/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.55103

Training -> Precision:	0.735306039724	 Recall:  0.865292883038	 F-Score:  0.795021256081
Testing	 -> Precision:	0.529598308668	 Recall:  0.582964859204	 F-Score:  0.555001661682

28222/28222 [==============================] - 35s - loss: 0.5512
Epoch 19/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.54956

Training -> Precision:	0.796761280932	 Recall:  0.835527571074	 F-Score:  0.815684083077
Testing	 -> Precision:	0.576410484229	 Recall:  0.603909704445	 F-Score:  0.589839754518

28222/28222 [==============================] - 35s - loss: 0.5492
Epoch 20/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.54227

Training -> Precision:	0.795101606176	 Recall:  0.854798702538	 F-Score:  0.823870166889
Testing	 -> Precision:	0.594083812654	 Recall:  0.67302769374		 F-Score:  0.631096563011

28222/28222 [==============================] - 35s - loss: 0.5419
28222/28222 [==============================] - 14s: 0ss
12344/12344 [==============================] - 6sA: 0s


Average Precision Score 0.637028979735
Training
	     precision	  recall  f1-score   support

	  0	 0.910	   0.870     0.890     17740
	  1	 0.795	   0.855     0.824     10482

avg / total	 0.867	   0.864     0.865     28222

Testing
	     precision	  recall  f1-score   support

	  0	 0.812	   0.754     0.782	8047
	  1	 0.594	   0.673     0.631	4297

avg / total	 0.736	   0.726     0.730     12344

Testing Accuracy
0.726101749838
