38  CHARACTERS
[u'o', u'k', u's', u'i', u'f', u't', u'e', u'r', u'w', u'u', u'3', u'G', u'C', u'y', u'g', u'z', u'd', u'h', u'a', u'S', u'n', u'v', u'x', u'b', u'p', u'E', u'l', u'8', u'm', u'T', u'7', u'Z', u'L', u'c', u'5', u'N', u'j', u'q']
52  LANGUAGES
[u'ANCIENT_GREEK', u'GREEK', u'CLASSICAL_ARMENIAN', u'ARMENIAN_EASTERN', u'OSSETIC', u'OSSETIC_IRON', u'OSSETIC_DIGOR', u'BIHARI', u'URDU', u'MARATHI', u'OLD_CHURCH_SLAVONIC', u'SERBO-CROATIAN', u'BULGARIAN', u'MACEDONIAN', u'RUSSIAN', u'POLISH', u'BELARUSIAN', u'UKRAINIAN', u'SLOVAK', u'CZECH', u'SORBIAN_UPPER', u'SORBIAN_LOWER', u'SLOVENIAN', u'OLD_NORSE', u'ICELANDIC', u'FAROESE', u'NORWEGIAN_RIKSMAL', u'STAVANGERSK', u'OLD_SWEDISH', u'SWEDISH', u'ELFDALIAN', u'DANISH', u'DANISH_FJOLDE', u'GUTNISH_LAU', u'ENGLISH', u'FRISIAN', u'DUTCH', u'GERMAN', u'LATIN', u'PORTUGUESE', u'SPANISH', u'FRENCH', u'ITALIAN', u'OLD_IRISH', u'MIDDLE_CORNISH', u'MIDDLE_BRETON', u'IRISH', u'ORIYA', u'MAGAHI', u'CATALAN', u'BRETON', u'ASSAMESE']
lstm_units 25
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.01
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
No. of concepts 207
No. of training concepts 144 testing concepts 63
Vocab Size :  41
Building model
MASKING PRESENT
MASKING PRESENT
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       410
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 50)	       7200
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 50)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 50), (Non 10050
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 50)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 50)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 100)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 100)	       0
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       101
====================================================================================================
Total params: 17,761.0
Trainable params: 17,761.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.774442

Training -> Precision:	0.525967021113	 Recall:  0.71729500776		 F-Score:  0.60690909837
Testing	 -> Precision:	0.374019813032	 Recall:  0.622035550193	 F-Score:  0.467149977345

223666/223666 [==============================] - 457s - loss: 0.7743
Epoch 2/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.654520

Training -> Precision:	0.6259375	 Recall:  0.712396533885	 F-Score:  0.666374304379
Testing	 -> Precision:	0.467328285929	 Recall:  0.635958602126	 F-Score:  0.538756413533

223666/223666 [==============================] - 378s - loss: 0.6545
Epoch 3/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.615634

Training -> Precision:	0.625254263808	 Recall:  0.775219865494	 F-Score:  0.692207754713
Testing	 -> Precision:	0.465720307463	 Recall:  0.69735926115		 F-Score:  0.55847317463

223666/223666 [==============================] - 382s - loss: 0.6156
Epoch 4/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.588073

Training -> Precision:	0.663564949678	 Recall:  0.777030522504	 F-Score:  0.715829293539
Testing	 -> Precision:	0.507796610169	 Recall:  0.695224393187	 F-Score:  0.586910102455

223666/223666 [==============================] - 369s - loss: 0.5880
Epoch 5/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.563370

Training -> Precision:	0.696415356836	 Recall:  0.760702276255	 F-Score:  0.727140671601
Testing	 -> Precision:	0.541719436788	 Recall:  0.674943147538	 F-Score:  0.601037340111

223666/223666 [==============================] - 359s - loss: 0.5632
Epoch 6/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.539189

Training -> Precision:	0.709402207146	 Recall:  0.787732798758	 F-Score:  0.746518361907
Testing	 -> Precision:	0.54456291563	 Recall:  0.680280317446	 F-Score:  0.604902608121

223666/223666 [==============================] - 331s - loss: 0.5390
Epoch 7/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.518326

Training -> Precision:	0.706991566701	 Recall:  0.821310786342	 F-Score:  0.75987555529
Testing	 -> Precision:	0.541753428592	 Recall:  0.700329512229	 F-Score:  0.610918807312

223666/223666 [==============================] - 450s - loss: 0.5183
Epoch 8/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.493644

Training -> Precision:	0.744189133384	 Recall:  0.815749482669	 F-Score:  0.778327934598
Testing	 -> Precision:	0.578063815764	 Recall:  0.691975681069	 F-Score:  0.629911280101

223666/223666 [==============================] - 373s - loss: 0.4936
Epoch 9/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.471797

Training -> Precision:	0.7271937206	 Recall:  0.852221288153	 F-Score:  0.784758870686
Testing	 -> Precision:	0.544641013286	 Recall:  0.734394579292	 F-Score:  0.625442184937

223666/223666 [==============================] - 391s - loss: 0.4717
Epoch 10/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.452227

Training -> Precision:	0.721346319415	 Recall:  0.866884376617	 F-Score:  0.787447133459
Testing	 -> Precision:	0.534150200289	 Recall:  0.736436626909	 F-Score:  0.619190697311

223666/223666 [==============================] - 454s - loss: 0.4521
Epoch 11/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.435146

Training -> Precision:	0.741004621479	 Recall:  0.870958354889	 F-Score:  0.800743162901
Testing	 -> Precision:	0.553661331204	 Recall:  0.740056620411	 F-Score:  0.633431318027

223666/223666 [==============================] - 417s - loss: 0.4350
Epoch 12/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.420056

Training -> Precision:	0.765106322249	 Recall:  0.866706544232	 F-Score:  0.812743507724
Testing	 -> Precision:	0.566647390487	 Recall:  0.727618694018	 F-Score:  0.637122828406

223666/223666 [==============================] - 432s - loss: 0.4200
Epoch 13/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.404152

Training -> Precision:	0.749605785439	 Recall:  0.891489912054	 F-Score:  0.814414414414
Testing	 -> Precision:	0.547527361167	 Recall:  0.752262495939	 F-Score:  0.63377060077

223666/223666 [==============================] - 458s - loss: 0.4041
Epoch 14/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.390395

Training -> Precision:	0.77141664928	 Recall:  0.896614718055	 F-Score:  0.829317163984
Testing	 -> Precision:	0.562403365575	 Recall:  0.725901517613	 F-Score:  0.633777705742

223666/223666 [==============================] - 440s - loss: 0.3903
Epoch 15/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.376457

Training -> Precision:	0.808966283809	 Recall:  0.882452793585	 F-Score:  0.84411316699
Testing	 -> Precision:	0.592726982735	 Recall:  0.689887223279	 F-Score:  0.637627075023

223666/223666 [==============================] - 348s - loss: 0.3764
Epoch 16/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.368402

Training -> Precision:	0.812360244792	 Recall:  0.892734738748	 F-Score:  0.850653151765
Testing	 -> Precision:	0.597486011506	 Recall:  0.703717454866	 F-Score:  0.646265316995

223666/223666 [==============================] - 392s - loss: 0.3683
Epoch 17/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.356591

Training -> Precision:	0.811973225774	 Recall:  0.907995990688	 F-Score:  0.857304219741
Testing	 -> Precision:	0.57987555827	 Recall:  0.705016939713	 F-Score:  0.636352211796

223666/223666 [==============================] - 344s - loss: 0.3565
Epoch 18/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.348740

Training -> Precision:	0.825535830909	 Recall:  0.899152871185	 F-Score:  0.860773207045
Testing	 -> Precision:	0.597522372895	 Recall:  0.709611546851	 F-Score:  0.648761031908

223666/223666 [==============================] - 375s - loss: 0.3487
Epoch 19/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.340376

Training -> Precision:	0.798641652285	 Recall:  0.92770305225		 F-Score:  0.858348042002
Testing	 -> Precision:	0.559162856138	 Recall:  0.737782521929	 F-Score:  0.636172639414

223666/223666 [==============================] - 392s - loss: 0.3403
Epoch 20/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.333290

Training -> Precision:	0.824794783722	 Recall:  0.916160113813	 F-Score:  0.868080022058
Testing	 -> Precision:	0.587457600987	 Recall:  0.707337448369	 F-Score:  0.641847929081

223666/223666 [==============================] - 352s - loss: 0.3332
103092/103092 [==============================] - 67s: 0sss


Average Precision Score 0.708075047319
Training
	     precision	  recall  f1-score   support

	  0	 0.967	   0.926     0.946    161810
	  1	 0.825	   0.916     0.868     61856

avg / total	 0.927	   0.923     0.924    223666

Testing
	     precision	  recall  f1-score   support

	  0	 0.918	   0.869     0.893     81545
	  1	 0.587	   0.707     0.642     21547

avg / total	 0.849	   0.835     0.840    103092

Testing Accuracy
0.835011446087
