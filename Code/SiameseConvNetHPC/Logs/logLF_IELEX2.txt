32  CHARACTERS
['"', '3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z', '~']
52  LANGUAGES
['SWEDISH', 'DANISH', 'GUTNISH_LAU', 'OSSETIC_IRON', 'FRENCH', 'BIHARI', 'DUTCH', 'MARATHI', 'SORBIAN_UPPER', 'ORIYA', 'SLOVENIAN', 'MIDDLE_CORNISH', 'ANCIENT_GREEK', 'ARMENIAN_EASTERN', 'OLD_SWEDISH', 'ICELANDIC', 'SLOVAK', 'ENGLISH', 'ASSAMESE', 'BRETON', 'ITALIAN', 'ELFDALIAN', 'UKRAINIAN', 'CZECH', 'STAVANGERSK', 'NORWEGIAN_RIKSMAL', 'OLD_NORSE', 'SPANISH', 'MAGAHI', 'OLD_CHURCH_SLAVONIC', 'PORTUGUESE', 'OLD_IRISH', 'IRISH', 'MIDDLE_BRETON', 'GERMAN', 'DANISH_FJOLDE', 'OSSETIC', 'MACEDONIAN', 'LATIN', 'BELARUSIAN', 'FAROESE', 'POLISH', 'FRISIAN', 'BULGARIAN', 'GREEK', 'CLASSICAL_ARMENIAN', 'SORBIAN_LOWER', 'URDU', 'CATALAN', 'SERBO-CROATIAN', 'RUSSIAN', 'OSSETIC_DIGOR']
lstm_units 70
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Vocab Size :  35
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       350
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 140)       45360
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 140)       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 140), (No 78540
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 140)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 140)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 280)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 280)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       5620
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 129,891.0
Trainable params: 129,891.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.781249

Training -> Precision:	0.528529677291	 Recall:  0.674945286853	 F-Score:  0.592830969115
Testing	 -> Precision:	0.586155484558	 Recall:  0.696885287415	 F-Score:  0.636742248959

204233/204233 [==============================] - 272s - loss: 0.7812
Epoch 2/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.645671

Training -> Precision:	0.587361538706	 Recall:  0.723229638893	 F-Score:  0.648252911814
Testing	 -> Precision:	0.637687366167	 Recall:  0.754114965814	 F-Score:  0.691031442163

204233/204233 [==============================] - 264s - loss: 0.6456
Epoch 3/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.607752

Training -> Precision:	0.608089416029	 Recall:  0.747362044708	 F-Score:  0.670570599528
Testing	 -> Precision:	0.658260312032	 Recall:  0.779944289694	 F-Score:  0.713954566528

204233/204233 [==============================] - 264s - loss: 0.6077
Epoch 4/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.577015

Training -> Precision:	0.588772335962	 Recall:  0.795157886509	 F-Score:  0.67657596994
Testing	 -> Precision:	0.629615082482	 Recall:  0.811851101545	 F-Score:  0.709213582568

204233/204233 [==============================] - 274s - loss: 0.5770
Epoch 5/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.548539

Training -> Precision:	0.67732166302	 Recall:  0.756057526966	 F-Score:  0.714527105013
Testing	 -> Precision:	0.696085087124	 Recall:  0.778931375032	 F-Score:  0.735181644359

204233/204233 [==============================] - 272s - loss: 0.5485
Epoch 6/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.520682

Training -> Precision:	0.695251631923	 Recall:  0.774210567453	 F-Score:  0.732609740764
Testing	 -> Precision:	0.724696356275	 Recall:  0.770574829071	 F-Score:  0.746931762396

204233/204233 [==============================] - 263s - loss: 0.5205
Epoch 7/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.491623

Training -> Precision:	0.697335827309	 Recall:  0.808621228701	 F-Score:  0.748866710701
Testing	 -> Precision:	0.72556135178	 Recall:  0.810078500886	 F-Score:  0.765494137353

204233/204233 [==============================] - 264s - loss: 0.4916
Epoch 8/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.462090

Training -> Precision:	0.720879193413	 Recall:  0.853642332343	 F-Score:  0.7816634907
Testing	 -> Precision:	0.730296941282	 Recall:  0.828310964801	 F-Score:  0.776222116754

204233/204233 [==============================] - 270s - loss: 0.4620
Epoch 9/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.432165

Training -> Precision:	0.756918811195	 Recall:  0.853486009067	 F-Score:  0.802307105923
Testing	 -> Precision:	0.763102232667	 Recall:  0.82223347683		 F-Score:  0.7915650902

204233/204233 [==============================] - 274s - loss: 0.4321
Epoch 10/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.415524

Training -> Precision:	0.799977940771	 Recall:  0.850359543536	 F-Score:  0.824399715842
Testing	 -> Precision:	0.785660377358	 Recall:  0.790833122309	 F-Score:  0.788238263503

204233/204233 [==============================] - 263s - loss: 0.4155
Epoch 11/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.389762

Training -> Precision:	0.771763613542	 Recall:  0.877071283414	 F-Score:  0.821054557095
Testing	 -> Precision:	0.762884160757	 Recall:  0.81716890352		 F-Score:  0.789094021274

204233/204233 [==============================] - 264s - loss: 0.3897
Epoch 12/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.374771

Training -> Precision:	0.796214598363	 Recall:  0.899288729092	 F-Score:  0.844618589244
Testing	 -> Precision:	0.771455443217	 Recall:  0.830843251456	 F-Score:  0.800048768593

204233/204233 [==============================] - 264s - loss: 0.3747
Epoch 13/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.355868

Training -> Precision:	0.803942086664	 Recall:  0.915761294357	 F-Score:  0.856216314972
Testing	 -> Precision:	0.759478948593	 Recall:  0.826791592808	 F-Score:  0.791707080504

204233/204233 [==============================] - 271s - loss: 0.3558
Epoch 14/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.339545

Training -> Precision:	0.825626187137	 Recall:  0.90882444896		 F-Score:  0.86522988773
Testing	 -> Precision:	0.790385553929	 Recall:  0.820207647506	 F-Score:  0.805020504536

204233/204233 [==============================] - 267s - loss: 0.3395
Epoch 15/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.326087

Training -> Precision:	0.839034526854	 Recall:  0.923108488354	 F-Score:  0.879065872721
Testing	 -> Precision:	0.790182868142	 Recall:  0.831602937453	 F-Score:  0.810363972856

204233/204233 [==============================] - 263s - loss: 0.3261
Epoch 16/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.316496

Training -> Precision:	0.797668691512	 Recall:  0.949390339222	 F-Score:  0.866941455668
Testing	 -> Precision:	0.755188573979	 Recall:  0.856925804001	 F-Score:  0.802846975089

204233/204233 [==============================] - 264s - loss: 0.3164
Epoch 17/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.303040

Training -> Precision:	0.848896015789	 Recall:  0.94133969048		 F-Score:  0.892731063238
Testing	 -> Precision:	0.799313052012	 Recall:  0.82501899215		 F-Score:  0.811962616822

204233/204233 [==============================] - 266s - loss: 0.3030
Epoch 18/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.290476

Training -> Precision:	0.836857177152	 Recall:  0.953630608098	 F-Score:  0.891435982209
Testing	 -> Precision:	0.783930254477	 Recall:  0.842491770068	 F-Score:  0.81215671915

204233/204233 [==============================] - 270s - loss: 0.2904
Epoch 19/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.281482

Training -> Precision:	0.866384070103	 Recall:  0.950523682976	 F-Score:  0.906505655877
Testing	 -> Precision:	0.800591570126	 Recall:  0.822486705495	 F-Score:  0.811391456408

204233/204233 [==============================] - 264s - loss: 0.2815
Epoch 20/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.271507

Training -> Precision:	0.876998078945	 Recall:  0.945579959356	 F-Score:  0.909998683641
Testing	 -> Precision:	0.810961684852	 Recall:  0.80931881489		 F-Score:  0.810139416984

204233/204233 [==============================] - 263s - loss: 0.2715
13184/132063[============================>.].- ETA:A0s0sss

Average Precision Score 0.863452563836
Training
	     precision	  recall  f1-score   support

	  0	 0.981	   0.956     0.968    153057
	  1	 0.877	   0.946     0.910     51176

avg / total	 0.955	   0.953     0.954    204233

Testing
	     precision	  recall  f1-score   support

	  0	 0.919	   0.920     0.919	9257
	  1	 0.811	   0.809     0.810	3949

avg / total	 0.887	   0.887     0.887     13206

Testing Accuracy
0.886566712101
