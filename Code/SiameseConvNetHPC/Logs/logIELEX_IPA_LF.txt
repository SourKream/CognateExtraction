160  CHARACTERS
[u'o', u'k', u's', u'y', u'\u0301', u'\u02cc', u'\u031e', u'f', u't', u'e', u'\u02c8', u'r', u'w', u'u', u'\u027e', u'\u0268', u'\u0281', u'\u010d', u'i', u'j', u'g', u'\u0259', u'\u032a', u'z', u'd', u'\u02b0', u'a', u':', u'\u0282', u'\u0273', u'\u0254', u'\u028a', u'\u0306', u'\u0283', u'\u0258', u'\u031f', u'v', u'\u0266', u'\u026a', u'\u02d0', u'\u0280', u'\u030c', u'\u0263', u'b', u'p', u'x', u'\u02b7', u'\u0325', u'\u028f', u'\u0279', u'\u028b', u'h', u'\u0251', u'\u025b', u'\u03c7', u'\u0250', u'\u0261', u'l', u'\xf0', u'\u0303', u'\u028e', u'n', u'\u02b9', u'\u0278', u'\u03b2', u'm', u'\u025f', u'\u02e0', u'\xe9', u'\u032f', u'-', u'\xe6', u'c', u'\u0294', u'\u0302', u'\u0255', u'.', u'\u02b2', u'\u0291', u'\u031d', u'\u030a', u'\u0292', u'\u0300', u'\u0289', u'\u028c', u'\u01dd', u'\xf3', u'\u0142', u'\u026d', u'\u0329', u'\xfb', u'\u0264', u'\u026b', u'\u0290', u'\u027d', u'\u02c0', u'\xe7', u'\u02a3', u'\u0252', u'_', u'\u0272', u'\xf8', u'\xe3', u'\xe1', u'\u017e', u'\u014b', u'\u0267', u'\u0275', u'\u02a7', u'\u0288', u'\u027b', u'\u0256', u'\u0320', u'\u035c', u'\u03b8', u'\u02a8', u'\u0153', u'\xee', u'\u0270', u'\xed', u'\xe2', u'\u0169', u'\u01f0', u'\u02a4', u'\u031c', u'\u1e7d', u'\u0265', u'\u012d', u'\u02d1', u'\u029d', u'\u025c', u'\u0304', u'\u026f', u'\u011b', u'\u1ebd', u'\u0361', u'\u0161', u'\u02b1', u'\u01ce', u'\xea', u'\u0276', u'\u1e59', u'\u02a6', u'\u016d', u'\u0311', u'\u0129', u'\u028d', u'\u02a5', u'q', u'\xf9', u'\xf5', u'\u01d0', u'\xf4', u'\u0324', u'\xec', u'\u01d4', u'\xfa', u'\u033b', u'\u1d58', u'?']
52  LANGUAGES
[u'ANCIENT_GREEK', u'GREEK', u'CLASSICAL_ARMENIAN', u'ARMENIAN_EASTERN', u'OSSETIC', u'OSSETIC_IRON', u'OSSETIC_DIGOR', u'BIHARI', u'URDU', u'MARATHI', u'OLD_CHURCH_SLAVONIC', u'SERBO-CROATIAN', u'BULGARIAN', u'MACEDONIAN', u'RUSSIAN', u'POLISH', u'BELARUSIAN', u'UKRAINIAN', u'SLOVAK', u'CZECH', u'SORBIAN_UPPER', u'SORBIAN_LOWER', u'SLOVENIAN', u'OLD_NORSE', u'ICELANDIC', u'FAROESE', u'NORWEGIAN_RIKSMAL', u'STAVANGERSK', u'OLD_SWEDISH', u'SWEDISH', u'ELFDALIAN', u'DANISH', u'DANISH_FJOLDE', u'GUTNISH_LAU', u'ENGLISH', u'FRISIAN', u'DUTCH', u'GERMAN', u'LATIN', u'PORTUGUESE', u'SPANISH', u'FRENCH', u'ITALIAN', u'OLD_IRISH', u'MIDDLE_CORNISH', u'MIDDLE_BRETON', u'IRISH', u'ORIYA', u'MAGAHI', u'CATALAN', u'BRETON', u'ASSAMESE']
lstm_units 40
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 45
Tokenize Simple False
Using Concept Fold Data False
No. of concepts 207
No. of training concepts 144 testing concepts 63
Vocab Size :  527
Building model
MASKING PRESENT
MASKING PRESENT
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 45)	       23715
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 45)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 80)	       27520
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 80)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 80), (Non 25680
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 160)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 160)	       0
____________________________________________________________________________________________________
Input Lang Feat (InputLayer)	 (None, 52)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 212)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       4260
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 81,196.0
Trainable params: 81,196.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.773117

Training -> Precision:	0.605282963182	 Recall:  0.662622574756	 F-Score:  0.632656209029
Testing	 -> Precision:	0.419409153528	 Recall:  0.508655497285	 F-Score:  0.459741185847

223715/223715 [==============================] - 351s - loss: 0.7731
Epoch 2/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.601661

Training -> Precision:	0.682847670075	 Recall:  0.788549458006	 F-Score:  0.731901877287
Testing	 -> Precision:	0.505989320248	 Recall:  0.650856267694	 F-Score:  0.569352252197

223715/223715 [==============================] - 340s - loss: 0.6017
Epoch 3/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.519670

Training -> Precision:	0.713502149509	 Recall:  0.855301206766	 F-Score:  0.777993299242
Testing	 -> Precision:	0.500948766603	 Recall:  0.686127999257	 F-Score:  0.579094772714

223715/223715 [==============================] - 338s - loss: 0.5195
Epoch 4/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.455503

Training -> Precision:	0.7558912218	 Recall:  0.874719309866	 F-Score:  0.810975564093
Testing	 -> Precision:	0.529293357347	 Recall:  0.695595674572	 F-Score:  0.601155141986

223715/223715 [==============================] - 338s - loss: 0.4555
Epoch 5/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.405973

Training -> Precision:	0.809042350248	 Recall:  0.890664124974	 F-Score:  0.847893453905
Testing	 -> Precision:	0.562028301887	 Recall:  0.663572655126	 F-Score:  0.608593866389

223715/223715 [==============================] - 339s - loss: 0.4059
Epoch 6/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.366876

Training -> Precision:	0.81151825045	 Recall:  0.925574708001	 F-Score:  0.864802040724
Testing	 -> Precision:	0.556634182909	 Recall:  0.689237480856	 F-Score:  0.615879071889

223715/223715 [==============================] - 340s - loss: 0.3668
Epoch 7/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.331922

Training -> Precision:	0.860664135479	 Recall:  0.922828387264	 F-Score:  0.89066288307
Testing	 -> Precision:	0.5957987464	 Recall:  0.652898315311	 F-Score:  0.623043025753

223715/223715 [==============================] - 339s - loss: 0.3319
Epoch 8/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.306085

Training -> Precision:	0.87552882872	 Recall:  0.936107655773	 F-Score:  0.904805402662
Testing	 -> Precision:	0.583343460121	 Recall:  0.668352902956	 F-Score:  0.622961456936

223715/223715 [==============================] - 339s - loss: 0.3061
Epoch 9/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.284988

Training -> Precision:	0.830232266863	 Recall:  0.963764721087	 F-Score:  0.892028887992
Testing	 -> Precision:	0.540797363161	 Recall:  0.715784099875	 F-Score:  0.616106739104

223715/223715 [==============================] - 339s - loss: 0.2848
Epoch 10/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.265219

Training -> Precision:	0.895587208066	 Recall:  0.952779438135	 F-Score:  0.923298501037
Testing	 -> Precision:	0.598342284434	 Recall:  0.656657539333	 F-Score:  0.626145063504

223715/223715 [==============================] - 339s - loss: 0.2653
Epoch 11/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.247462

Training -> Precision:	0.901723086307	 Recall:  0.955315746111	 F-Score:  0.927746095497
Testing	 -> Precision:	0.595323964681	 Recall:  0.666496496032	 F-Score:  0.628902999781

223715/223715 [==============================] - 339s - loss: 0.2474
Epoch 12/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.237465

Training -> Precision:	0.912353654233	 Recall:  0.960549910341	 F-Score:  0.935831654495
Testing	 -> Precision:	0.60983451942	 Recall:  0.660184712489	 F-Score:  0.63401154369

223715/223715 [==============================] - 339s - loss: 0.2374
Epoch 13/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.223728

Training -> Precision:	0.900734302413	 Recall:  0.971002083973	 F-Score:  0.93454921442
Testing	 -> Precision:	0.564703654611	 Recall:  0.692022091242	 F-Score:  0.621913580247

223715/223715 [==============================] - 339s - loss: 0.2237
Epoch 14/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.215014

Training -> Precision:	0.922197882998	 Recall:  0.972552947448	 F-Score:  0.946706294916
Testing	 -> Precision:	0.601309121622	 Recall:  0.660834454913	 F-Score:  0.629668118602

223715/223715 [==============================] - 339s - loss: 0.2150
Epoch 15/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.206739

Training -> Precision:	0.91925191514	 Recall:  0.975089255424	 F-Score:  0.946347658394
Testing	 -> Precision:	0.595299724722	 Recall:  0.67243699819		 F-Score:  0.631521597001

223715/223715 [==============================] - 340s - loss: 0.2067
Epoch 16/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.200006

Training -> Precision:	0.924742991367	 Recall:  0.979434904121	 F-Score:  0.95130351553
Testing	 -> Precision:	0.595500626035	 Recall:  0.684271592333	 F-Score:  0.636807325185

223715/223715 [==============================] - 339s - loss: 0.2000
Epoch 17/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.193556

Training -> Precision:	0.937441846039	 Recall:  0.97655934476		 F-Score:  0.956600862444
Testing	 -> Precision:	0.612102045119	 Recall:  0.673690072864	 F-Score:  0.641421059609

223715/223715 [==============================] - 339s - loss: 0.1935
Epoch 18/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.187043

Training -> Precision:	0.924557515407	 Recall:  0.983958255925	 F-Score:  0.953333489854
Testing	 -> Precision:	0.590434369808	 Recall:  0.692671833666	 F-Score:  0.637479978644

223715/223715 [==============================] - 339s - loss: 0.1870
Epoch 19/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.180907

Training -> Precision:	0.945289939905	 Recall:  0.978336375826	 F-Score:  0.961529301558
Testing	 -> Precision:	0.628349884369	 Recall:  0.643105768785	 F-Score:  0.635642201835

223715/223715 [==============================] - 339s - loss: 0.1809
Epoch 20/20
223616/223715 [============================>.] - ETA: 0ss--loss::0.175058

Training -> Precision:	0.929288146983	 Recall:  0.982972811425	 F-Score:  0.95537690967
Testing	 -> Precision:	0.587350835322	 Recall:  0.685292616141	 F-Score:  0.632552959068

223715/223715 [==============================] - 339s - loss: 0.1750
103092/103092 [==============================] - 61s: 0sss


Average Precision Score 0.663428970885
Training
	     precision	  recall  f1-score   support

	  0	 0.993	   0.971     0.982    161814
	  1	 0.929	   0.983     0.955     61901

avg / total	 0.976	   0.975     0.975    223715

Testing
	     precision	  recall  f1-score   support

	  0	 0.913	   0.873     0.892     81545
	  1	 0.587	   0.685     0.633     21547

avg / total	 0.845	   0.834     0.838    103092

Testing Accuracy
0.833595235324
