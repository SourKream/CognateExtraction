38  CHARACTERS
[u'o', u'k', u's', u'i', u'f', u't', u'e', u'r', u'w', u'u', u'3', u'G', u'C', u'y', u'g', u'z', u'd', u'h', u'a', u'S', u'n', u'v', u'x', u'b', u'p', u'E', u'l', u'8', u'm', u'T', u'7', u'Z', u'L', u'c', u'5', u'N', u'j', u'q']
52  LANGUAGES
[u'ANCIENT_GREEK', u'GREEK', u'CLASSICAL_ARMENIAN', u'ARMENIAN_EASTERN', u'OSSETIC', u'OSSETIC_IRON', u'OSSETIC_DIGOR', u'BIHARI', u'URDU', u'MARATHI', u'OLD_CHURCH_SLAVONIC', u'SERBO-CROATIAN', u'BULGARIAN', u'MACEDONIAN', u'RUSSIAN', u'POLISH', u'BELARUSIAN', u'UKRAINIAN', u'SLOVAK', u'CZECH', u'SORBIAN_UPPER', u'SORBIAN_LOWER', u'SLOVENIAN', u'OLD_NORSE', u'ICELANDIC', u'FAROESE', u'NORWEGIAN_RIKSMAL', u'STAVANGERSK', u'OLD_SWEDISH', u'SWEDISH', u'ELFDALIAN', u'DANISH', u'DANISH_FJOLDE', u'GUTNISH_LAU', u'ENGLISH', u'FRISIAN', u'DUTCH', u'GERMAN', u'LATIN', u'PORTUGUESE', u'SPANISH', u'FRENCH', u'ITALIAN', u'OLD_IRISH', u'MIDDLE_CORNISH', u'MIDDLE_BRETON', u'IRISH', u'ORIYA', u'MAGAHI', u'CATALAN', u'BRETON', u'ASSAMESE']
lstm_units 30
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 12
Tokenize Simple False
Using Concept Fold Data False
No. of concepts 207
No. of training concepts 144 testing concepts 63
Vocab Size :  41
Building model
MASKING PRESENT
MASKING PRESENT
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 12)	       492
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 12)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 60)	       10320
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 60)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 60), (Non 14460
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 60)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 60)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 120)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 120)	       0
____________________________________________________________________________________________________
Input Lang Feat (InputLayer)	 (None, 52)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 172)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       3460
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 28,753.0
Trainable params: 28,753.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.803290

Training -> Precision:	0.568517723537	 Recall:  0.599472969477	 F-Score:  0.583585143217
Testing	 -> Precision:	0.401648852432	 Recall:  0.449946628301	 F-Score:  0.424428149283

223666/223666 [==============================] - 326s - loss: 0.8032
Epoch 2/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.668764

Training -> Precision:	0.579040126987	 Recall:  0.802040222452	 F-Score:  0.672536500061
Testing	 -> Precision:	0.43955327532	 Recall:  0.719682554416	 F-Score:  0.545771301869

223666/223666 [==============================] - 315s - loss: 0.6687
Epoch 3/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.604689

Training -> Precision:	0.662068676366	 Recall:  0.765859415416	 F-Score:  0.710191966059
Testing	 -> Precision:	0.531644668967	 Recall:  0.693553626955	 F-Score:  0.601901079426

223666/223666 [==============================] - 315s - loss: 0.6046
Epoch 4/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.564011

Training -> Precision:	0.654284356415	 Recall:  0.823493274703	 F-Score:  0.729201411505
Testing	 -> Precision:	0.49439784677	 Recall:  0.733141504618	 F-Score:  0.59055309445

223666/223666 [==============================] - 315s - loss: 0.5640
Epoch 5/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.537852

Training -> Precision:	0.710832447751	 Recall:  0.81102884118		 F-Score:  0.757632276431
Testing	 -> Precision:	0.538052592143	 Recall:  0.699865410498	 F-Score:  0.608383426796

223666/223666 [==============================] - 315s - loss: 0.5378
Epoch 6/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.515269

Training -> Precision:	0.729649967698	 Recall:  0.80339821521		 F-Score:  0.764750238528
Testing	 -> Precision:	0.56894852551	 Recall:  0.69661669838		 F-Score:  0.62634313255

223666/223666 [==============================] - 313s - loss: 0.5153
Epoch 7/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.498680

Training -> Precision:	0.709785632466	 Recall:  0.841470512157	 F-Score:  0.770038760837
Testing	 -> Precision:	0.536790157305	 Recall:  0.726922541421	 F-Score:  0.617553128573

223666/223666 [==============================] - 313s - loss: 0.4986
Epoch 8/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.482172

Training -> Precision:	0.756333554915	 Recall:  0.827728918779	 F-Score:  0.790422304729
Testing	 -> Precision:	0.563622754491	 Recall:  0.698937207036	 F-Score:  0.62402883958

223666/223666 [==============================] - 314s - loss: 0.4821
Epoch 9/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.469354

Training -> Precision:	0.749776915341	 Recall:  0.855777935851	 F-Score:  0.79927825634
Testing	 -> Precision:	0.534844668346	 Recall:  0.709518726505	 F-Score:  0.609922004349

223666/223666 [==============================] - 314s - loss: 0.4693
Epoch 10/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.455454

Training -> Precision:	0.783135800235	 Recall:  0.839627521987	 F-Score:  0.810398364723
Testing	 -> Precision:	0.570701577189	 Recall:  0.681811853158	 F-Score:  0.62132842733

223666/223666 [==============================] - 314s - loss: 0.4554
Epoch 11/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.443581

Training -> Precision:	0.768421202541	 Recall:  0.872300181066	 F-Score:  0.817072247376
Testing	 -> Precision:	0.553968659824	 Recall:  0.703856685385	 F-Score:  0.619982012918

223666/223666 [==============================] - 314s - loss: 0.4435
Epoch 12/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.431026

Training -> Precision:	0.759014951627	 Recall:  0.892912571133	 F-Score:  0.820537199905
Testing	 -> Precision:	0.538230064287	 Recall:  0.730496124751	 F-Score:  0.619794845544

223666/223666 [==============================] - 314s - loss: 0.4310
Epoch 13/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.421131

Training -> Precision:	0.783805187092	 Recall:  0.896048887739	 F-Score:  0.836177113978
Testing	 -> Precision:	0.544774815695	 Recall:  0.72362741913		 F-Score:  0.621591452719

223666/223666 [==============================] - 315s - loss: 0.4211
Epoch 14/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.409990

Training -> Precision:	0.77411338267	 Recall:  0.911487972064	 F-Score:  0.83720274113
Testing	 -> Precision:	0.557129603197	 Recall:  0.724602032766	 F-Score:  0.629924754393

223666/223666 [==============================] - 314s - loss: 0.4100
Epoch 15/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.400486

Training -> Precision:	0.782476206378	 Recall:  0.909127651319	 F-Score:  0.841060692172
Testing	 -> Precision:	0.538580618528	 Recall:  0.726597670209	 F-Score:  0.618618618619

223666/223666 [==============================] - 314s - loss: 0.4005
Epoch 16/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.391319

Training -> Precision:	0.805577883677	 Recall:  0.907316994309	 F-Score:  0.853425990694
Testing	 -> Precision:	0.558498573206	 Recall:  0.708497702696	 F-Score:  0.624618972607

223666/223666 [==============================] - 314s - loss: 0.3913
Epoch 17/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.382293

Training -> Precision:	0.789239704911	 Recall:  0.927040222452	 F-Score:  0.852607945759
Testing	 -> Precision:	0.543240916136	 Recall:  0.732027660463	 F-Score:  0.623660590724

223666/223666 [==============================] - 314s - loss: 0.3823
Epoch 18/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.375382

Training -> Precision:	0.830074273939	 Recall:  0.905183005691	 F-Score:  0.866003139766
Testing	 -> Precision:	0.582194713691	 Recall:  0.694110549032	 F-Score:  0.633245829452

223666/223666 [==============================] - 314s - loss: 0.3753
Epoch 19/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.367919

Training -> Precision:	0.826762455464	 Recall:  0.91535178479		 F-Score:  0.868804664723
Testing	 -> Precision:	0.578135323151	 Recall:  0.690397735184	 F-Score:  0.629299039722

223666/223666 [==============================] - 314s - loss: 0.3679
Epoch 20/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.360474

Training -> Precision:	0.800508364531	 Recall:  0.936821003621	 F-Score:  0.863317069537
Testing	 -> Precision:	0.543639002142	 Recall:  0.730217663712	 F-Score:  0.62326447345

223666/223666 [==============================] - 314s - loss: 0.3604
103040/103092 [============================>.] - ETA: 0sss

Average Precision Score 0.690732472696
Training
	     precision	  recall  f1-score   support

	  0	 0.974	   0.911     0.941    161810
	  1	 0.801	   0.937     0.863     61856

avg / total	 0.926	   0.918     0.920    223666

Testing
	     precision	  recall  f1-score   support

	  0	 0.922	   0.838     0.878     81545
	  1	 0.544	   0.730     0.623     21547

avg / total	 0.843	   0.815     0.825    103092

Testing Accuracy
0.815494897761
