33  CHARACTERS
[u'i', u'n', u'k', u'e', u'h', u'a', u'y', u't', u'7', u'r', u'o', u'5', u'w', u'C', u'S', u'v', u'N', u'q', u'x', u'u', u'l', u'c', u'd', u'm', u'T', u'b', u's', u'3', u'p', u'g', u'8', u'f', u'X']
30  LANGUAGES
[u'HUASTEC', u'TOJOLABAL', u'CHUJ', u'JACALTEC', u'QANJOBAL_SANTA_EULALIA', u'ACATECO_SAN_MIGUEL_ACATAN', u'IXIL_CHAJUL', u'AGUACATEC', u'TECO_TECTITAN', u'MAM_NORTHERN', u'SIPAKAPENSE', u'SACAPULTECO_SACAPULAS_CENTRO', u'CENTRAL_QUICHE', u'SOUTHERN_CAKCHIQUEL_SAN_ANDRES_ITZAPA', u'TZUTUJIL_SAN_JUAN_LA_LAGUNA', u'POQOMCHI_WESTERN', u'POCOMAM_EASTERN', u'USPANTEKO', u'EASTERN_KEKCHI_CAHABON', u'TZELTAL_BACHAJON', u'CHOL_TUMBALA', u'CHORTI', u'ITZAJ', u'MOPAN', u'MAYA_YUCATAN', u'ZINACANTAN_TZOTZIL', u'CHONTAL_TABASCO', u'LACANDON', u'MOCHO', u'CHICOMUCELTEC']
lstm_units 30
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 12
Tokenize Simple False
Using Concept Fold Data False
No. of concepts 100
No. of training concepts 70 testing concepts 30
Vocab Size :  36
Building model
MASKING PRESENT
MASKING PRESENT
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 12)	       432
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 12)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 60)	       10320
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 60)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 60), (Non 14460
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 60)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 60)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 120)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 120)	       0
____________________________________________________________________________________________________
Input Lang Feat (InputLayer)	 (None, 30)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 150)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       3020
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 28,253.0
Trainable params: 28,253.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
28160/28222 [============================>.] - ETA: 0ss--loss::1.08475

Training -> Precision:	0.490529767626	 Recall:  0.82770463652		 F-Score:  0.615996307998
Testing	 -> Precision:	0.454189602446	 Recall:  0.864091226437	 F-Score:  0.595413726748

28222/28222 [==============================] - 50s - loss: 1.0844
Epoch 2/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.84293

Training -> Precision:	0.529625681861	 Recall:  0.805857660752	 F-Score:  0.639173697552
Testing	 -> Precision:	0.496646132786	 Recall:  0.84430998371		 F-Score:  0.62540941217

28222/28222 [==============================] - 39s - loss: 0.8426
Epoch 3/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.81560

Training -> Precision:	0.690888119954	 Recall:  0.628601411944	 F-Score:  0.658274639093
Testing	 -> Precision:	0.654553137545	 Recall:  0.720968117291	 F-Score:  0.686157253599

28222/28222 [==============================] - 39s - loss: 0.8155
Epoch 4/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.79051

Training -> Precision:	0.735340909091	 Recall:  0.617344018317	 F-Score:  0.671195934032
Testing	 -> Precision:	0.688536953243	 Recall:  0.63742145683		 F-Score:  0.661993957704

28222/28222 [==============================] - 39s - loss: 0.7905
Epoch 5/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.76777

Training -> Precision:	0.770580474934	 Recall:  0.557240984545	 F-Score:  0.646772228989
Testing	 -> Precision:	0.722580645161	 Recall:  0.599488014894	 F-Score:  0.655303993895

28222/28222 [==============================] - 39s - loss: 0.7679
Epoch 6/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.75543

Training -> Precision:	0.787695288846	 Recall:  0.620492272467	 F-Score:  0.694167244784
Testing	 -> Precision:	0.70701146361	 Recall:  0.617174773098	 F-Score:  0.659045725646

28222/28222 [==============================] - 39s - loss: 0.7555
Epoch 7/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.74512

Training -> Precision:	0.786140979689	 Recall:  0.627742797176	 F-Score:  0.69806917038
Testing	 -> Precision:	0.707628294036	 Recall:  0.593670002327	 F-Score:  0.645659326753

28222/28222 [==============================] - 39s - loss: 0.7449
Epoch 8/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.72344

Training -> Precision:	0.761423332342	 Recall:  0.732875405457	 F-Score:  0.746876671042
Testing	 -> Precision:	0.6837485172	 Recall:  0.670700488713	 F-Score:  0.677161654135

28222/28222 [==============================] - 39s - loss: 0.7234
Epoch 9/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.71166

Training -> Precision:	0.765687053217	 Recall:  0.735737454684	 F-Score:  0.750413544809
Testing	 -> Precision:	0.661858974359	 Recall:  0.672794973237	 F-Score:  0.667282169648

28222/28222 [==============================] - 39s - loss: 0.7115
Epoch 10/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.69197

Training -> Precision:	0.703904005408	 Recall:  0.794695668766	 F-Score:  0.746549560853
Testing	 -> Precision:	0.63533988534	 Recall:  0.722131719805	 F-Score:  0.675961224268

28222/28222 [==============================] - 39s - loss: 0.6918
Epoch 11/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.66844

Training -> Precision:	0.762453183521	 Recall:  0.776855561916	 F-Score:  0.769586995558
Testing	 -> Precision:	0.663538873995	 Recall:  0.691179892949	 F-Score:  0.677077396558

28222/28222 [==============================] - 38s - loss: 0.6686
Epoch 12/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.66272

Training -> Precision:	0.706048663468	 Recall:  0.786204922725	 F-Score:  0.743974000181
Testing	 -> Precision:	0.60268752507	 Recall:  0.699325110542	 F-Score:  0.647420015081

28222/28222 [==============================] - 39s - loss: 0.6627
Epoch 13/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.66662

Training -> Precision:	0.734345020059	 Recall:  0.803281816447	 F-Score:  0.767268088208
Testing	 -> Precision:	0.603661044838	 Recall:  0.683034675355	 F-Score:  0.640899661535

28222/28222 [==============================] - 39s - loss: 0.6664
Epoch 14/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.67048

Training -> Precision:	0.771804615812	 Recall:  0.794409463843	 F-Score:  0.782943914249
Testing	 -> Precision:	0.669237749546	 Recall:  0.686525482895	 F-Score:  0.67777139575

28222/28222 [==============================] - 39s - loss: 0.6704
Epoch 15/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.65010

Training -> Precision:	0.804581097813	 Recall:  0.743941995802	 F-Score:  0.77307425399
Testing	 -> Precision:	0.684157921039	 Recall:  0.637188736328	 F-Score:  0.659838534763

28222/28222 [==============================] - 39s - loss: 0.6503
Epoch 16/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.64711

Training -> Precision:	0.736567553469	 Recall:  0.808242701774	 F-Score:  0.770742358079
Testing	 -> Precision:	0.604776739356	 Recall:  0.677682103793	 F-Score:  0.639157155399

28222/28222 [==============================] - 39s - loss: 0.6475
Epoch 17/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.64535

Training -> Precision:	0.753711631296	 Recall:  0.789448578516	 F-Score:  0.771166301663
Testing	 -> Precision:	0.599954514442	 Recall:  0.61391668606		 F-Score:  0.606855302507

28222/28222 [==============================] - 40s - loss: 0.6454
Epoch 18/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.66238

Training -> Precision:	0.685448577681	 Recall:  0.836767792406	 F-Score:  0.753587077928
Testing	 -> Precision:	0.559450171821	 Recall:  0.757737956714	 F-Score:  0.643669071859

28222/28222 [==============================] - 39s - loss: 0.6624
Epoch 19/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.71071

Training -> Precision:	0.763583874626	 Recall:  0.706544552566	 F-Score:  0.733957682969
Testing	 -> Precision:	0.584591758382	 Recall:  0.531533628113	 F-Score:  0.556801560215

28222/28222 [==============================] - 39s - loss: 0.7108
Epoch 20/20
28160/28222 [============================>.] - ETA: 0ss--loss::0.69157

Training -> Precision:	0.812753036437	 Recall:  0.689467658844	 F-Score:  0.746051409105
Testing	 -> Precision:	0.659237379162	 Recall:  0.57132883407		 F-Score:  0.612143124299

28222/28222 [==============================] - 39s - loss: 0.6918
28222/28222 [==============================] - 15s: 0ss
12320/12344 [============================>.] - ETA: 0s

Average Precision Score 0.72251601144
Training
	     precision	  recall  f1-score   support

	  0	 0.832	   0.906     0.867     17740
	  1	 0.813	   0.689     0.746     10482

avg / total	 0.825	   0.826     0.822     28222

Testing
	     precision	  recall  f1-score   support

	  0	 0.786	   0.842     0.813	8047
	  1	 0.659	   0.571     0.612	4297

avg / total	 0.742	   0.748     0.743     12344

Testing Accuracy
0.747974724563
