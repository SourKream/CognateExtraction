38  CHARACTERS
[u'o', u'k', u's', u'i', u'f', u't', u'e', u'r', u'w', u'u', u'3', u'G', u'C', u'y', u'g', u'z', u'd', u'h', u'a', u'S', u'n', u'v', u'x', u'b', u'p', u'E', u'l', u'8', u'm', u'T', u'7', u'Z', u'L', u'c', u'5', u'N', u'j', u'q']
52  LANGUAGES
[u'ANCIENT_GREEK', u'GREEK', u'CLASSICAL_ARMENIAN', u'ARMENIAN_EASTERN', u'OSSETIC', u'OSSETIC_IRON', u'OSSETIC_DIGOR', u'BIHARI', u'URDU', u'MARATHI', u'OLD_CHURCH_SLAVONIC', u'SERBO-CROATIAN', u'BULGARIAN', u'MACEDONIAN', u'RUSSIAN', u'POLISH', u'BELARUSIAN', u'UKRAINIAN', u'SLOVAK', u'CZECH', u'SORBIAN_UPPER', u'SORBIAN_LOWER', u'SLOVENIAN', u'OLD_NORSE', u'ICELANDIC', u'FAROESE', u'NORWEGIAN_RIKSMAL', u'STAVANGERSK', u'OLD_SWEDISH', u'SWEDISH', u'ELFDALIAN', u'DANISH', u'DANISH_FJOLDE', u'GUTNISH_LAU', u'ENGLISH', u'FRISIAN', u'DUTCH', u'GERMAN', u'LATIN', u'PORTUGUESE', u'SPANISH', u'FRENCH', u'ITALIAN', u'OLD_IRISH', u'MIDDLE_CORNISH', u'MIDDLE_BRETON', u'IRISH', u'ORIYA', u'MAGAHI', u'CATALAN', u'BRETON', u'ASSAMESE']
lstm_units 20
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.05
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
No. of concepts 207
No. of training concepts 144 testing concepts 63
Vocab Size :  41
Building model
MASKING PRESENT
MASKING PRESENT
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       410
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 40)	       4960
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 40)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 40), (Non 6440
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 40)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 40)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 80)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 80)	       0
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       81
====================================================================================================
Total params: 11,891.0
Trainable params: 11,891.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.786260

Training -> Precision:	0.586133233072	 Recall:  0.554465209519	 F-Score:  0.569859599568
Testing	 -> Precision:	0.411487629762	 Recall:  0.417598737643	 F-Score:  0.414520661538

223666/223666 [==============================] - 310s - loss: 0.7862
Epoch 2/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.650140

Training -> Precision:	0.629709784523	 Recall:  0.757339627522	 F-Score:  0.687652753415
Testing	 -> Precision:	0.478285373293	 Recall:  0.669559567457	 F-Score:  0.557985728375

223666/223666 [==============================] - 300s - loss: 0.6501
Epoch 3/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.588625

Training -> Precision:	0.58965552076	 Recall:  0.849278970512	 F-Score:  0.696045631911
Testing	 -> Precision:	0.433964245399	 Recall:  0.767206571681	 F-Score:  0.554359490275

223666/223666 [==============================] - 300s - loss: 0.5886
Epoch 4/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.560295

Training -> Precision:	0.62746585736	 Recall:  0.815555483704	 F-Score:  0.709252463903
Testing	 -> Precision:	0.470232643341	 Recall:  0.714809486239	 F-Score:  0.56728237049

223666/223666 [==============================] - 300s - loss: 0.5602
Epoch 5/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.541903

Training -> Precision:	0.663041085603	 Recall:  0.827825918262	 F-Score:  0.73632670669
Testing	 -> Precision:	0.485726819791	 Recall:  0.719404093377	 F-Score:  0.579910213244

223666/223666 [==============================] - 300s - loss: 0.5420
Epoch 6/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.530702

Training -> Precision:	0.699691853282	 Recall:  0.796575918262	 F-Score:  0.744997240639
Testing	 -> Precision:	0.53065222812	 Recall:  0.691372348819	 F-Score:  0.600443369609

223666/223666 [==============================] - 300s - loss: 0.5307
Epoch 7/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.517363

Training -> Precision:	0.696633995003	 Recall:  0.820405457838	 F-Score:  0.753470624044
Testing	 -> Precision:	0.528602061285	 Recall:  0.709333085812	 F-Score:  0.605774756743

223666/223666 [==============================] - 301s - loss: 0.5173
Epoch 8/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.507724

Training -> Precision:	0.707482052204	 Recall:  0.826855923435	 F-Score:  0.762525251772
Testing	 -> Precision:	0.526160979999	 Recall:  0.705666682137	 F-Score:  0.602834770542

223666/223666 [==============================] - 300s - loss: 0.5077
Epoch 9/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.499024

Training -> Precision:	0.683659618898	 Recall:  0.846837816865	 F-Score:  0.756549871458
Testing	 -> Precision:	0.500791062607	 Recall:  0.719821784935	 F-Score:  0.590654632697

223666/223666 [==============================] - 300s - loss: 0.4991
Epoch 10/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.489807

Training -> Precision:	0.684948598313	 Recall:  0.852011122607	 F-Score:  0.759400283864
Testing	 -> Precision:	0.506755458795	 Recall:  0.734580219984	 F-Score:  0.599761277733

223666/223666 [==============================] - 300s - loss: 0.4898
Epoch 11/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.479671

Training -> Precision:	0.716723362979	 Recall:  0.848131143301	 F-Score:  0.77690980578
Testing	 -> Precision:	0.52587826087	 Recall:  0.701675407249	 F-Score:  0.60118893771

223666/223666 [==============================] - 300s - loss: 0.4796
Epoch 12/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.471459

Training -> Precision:	0.722678268484	 Recall:  0.853951112261	 F-Score:  0.782849690251
Testing	 -> Precision:	0.523211452108	 Recall:  0.719218452685	 F-Score:  0.605753820897

223666/223666 [==============================] - 299s - loss: 0.4714
Epoch 13/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.463854

Training -> Precision:	0.724475846293	 Recall:  0.865316218314	 F-Score:  0.788657477327
Testing	 -> Precision:	0.523244618664	 Recall:  0.706223604214	 F-Score:  0.601117936361

223666/223666 [==============================] - 298s - loss: 0.4638
Epoch 14/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.452318

Training -> Precision:	0.737776492301	 Recall:  0.865995214692	 F-Score:  0.796760423019
Testing	 -> Precision:	0.53397260274	 Recall:  0.72362741913		 F-Score:  0.614499379274

223666/223666 [==============================] - 298s - loss: 0.4523
Epoch 15/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.444008

Training -> Precision:	0.737681041054	 Recall:  0.876115494051	 F-Score:  0.800960685782
Testing	 -> Precision:	0.528343805325	 Recall:  0.706362834733	 F-Score:  0.604519998411

223666/223666 [==============================] - 298s - loss: 0.4440
Epoch 16/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.438446

Training -> Precision:	0.731996110867	 Recall:  0.888499094671	 F-Score:  0.802690288235
Testing	 -> Precision:	0.516952754618	 Recall:  0.733791247041	 F-Score:  0.606575615745

223666/223666 [==============================] - 300s - loss: 0.4384
Epoch 17/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.429442

Training -> Precision:	0.774139548308	 Recall:  0.867240041386	 F-Score:  0.818049423946
Testing	 -> Precision:	0.558038531497	 Recall:  0.697684132362	 F-Score:  0.620096522708

223666/223666 [==============================] - 299s - loss: 0.4295
Epoch 18/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.425279

Training -> Precision:	0.79120682722	 Recall:  0.858833419555	 F-Score:  0.823634291739
Testing	 -> Precision:	0.559087794106	 Recall:  0.68153339212		 F-Score:  0.614268086085

223666/223666 [==============================] - 299s - loss: 0.4252
Epoch 19/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.417183

Training -> Precision:	0.768364995504	 Recall:  0.884037118469	 F-Score:  0.822152393553
Testing	 -> Precision:	0.5505371784	 Recall:  0.722977676707	 F-Score:  0.625082759866

223666/223666 [==============================] - 299s - loss: 0.4171
Epoch 20/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.413044

Training -> Precision:	0.787531402501	 Recall:  0.881822296948	 F-Score:  0.832013911133
Testing	 -> Precision:	0.566828790107	 Recall:  0.697730542535	 F-Score:  0.625504472644

223666/223666 [==============================] - 299s - loss: 0.4130
103040/103092 [============================>.] - ETA: 0sss

Average Precision Score 0.649178912857
Training
	     precision	  recall  f1-score   support

	  0	 0.953	   0.909     0.930    161810
	  1	 0.788	   0.882     0.832     61856

avg / total	 0.907	   0.902     0.903    223666

Testing
	     precision	  recall  f1-score   support

	  0	 0.915	   0.859     0.886     81545
	  1	 0.567	   0.698     0.626     21547

avg / total	 0.842	   0.825     0.832    103092

Testing Accuracy
0.825379272882
