32  CHARACTERS
[' ', '"', '%', '3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', '~']
30  LANGUAGES
['SIPAKAPENSE', 'TZUTUJIL_SAN_JUAN_LA_LAGUNA', 'MAM_NORTHERN', 'CHORTI', 'POQOMCHI_WESTERN', 'TZELTAL_BACHAJON', 'SOUTHERN_CAKCHIQUEL_SAN_ANDRES_ITZAPA', 'MAYA_YUCATAN', 'CHONTAL_TABASCO', 'CENTRAL_QUICHE', 'EASTERN_KEKCHI_CAHABON', 'TECO_TECTITAN', 'JACALTEC', 'QANJOBAL_SANTA_EULALIA', 'LACANDON', 'ZINACANTAN_TZOTZIL', 'POCOMAM_EASTERN', 'IXIL_CHAJUL', 'CHUJ', 'CHOL_TUMBALA', 'AGUACATEC', 'MOPAN', 'MOCHO', 'ITZAJ', 'HUASTEC', 'USPANTEKO', 'ACATECO_SAN_MIGUEL_ACATAN', 'SACAPULTECO_SACAPULAS_CENTRO', 'TOJOLABAL', 'CHICOMUCELTEC']
lstm_units 40
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Vocab Size :  34
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       340
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 80)	       16320
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 80)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 80), (Non 25680
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 160)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 160)	       0
____________________________________________________________________________________________________
Input Concept Feat (InputLayer)	 (None, 300)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 460)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       9220
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 51,581.0
Trainable params: 51,581.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
25472/25473 [============================>.] - ETA: 0ss--loss::1.04735

Training -> Precision:	0.662696649187	 Recall:  0.775535677138	 F-Score:  0.714689671699
Testing	 -> Precision:	0.52027027027	 Recall:  0.698412698413	 F-Score:  0.596321393998

25473/25473 [==============================] - 36s - loss: 1.0473
Epoch 2/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.77985

Training -> Precision:	0.704831828554	 Recall:  0.738922404826	 F-Score:  0.721474635657
Testing	 -> Precision:	0.562376237624	 Recall:  0.643990929705	 F-Score:  0.600422832981

25473/25473 [==============================] - 28s - loss: 0.7799
Epoch 3/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.76351

Training -> Precision:	0.677359711565	 Recall:  0.762117744955	 F-Score:  0.71724340463
Testing	 -> Precision:	0.537892791128	 Recall:  0.659863945578	 F-Score:  0.59266802444

25473/25473 [==============================] - 28s - loss: 0.7634
Epoch 4/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.72544

Training -> Precision:	0.693628386112	 Recall:  0.756396921157	 F-Score:  0.723654094935
Testing	 -> Precision:	0.57171314741	 Recall:  0.650793650794	 F-Score:  0.608695652174

25473/25473 [==============================] - 28s - loss: 0.7254
Epoch 5/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.70037

Training -> Precision:	0.781222652832	 Recall:  0.649989598502	 F-Score:  0.70958950775
Testing	 -> Precision:	0.695767195767	 Recall:  0.596371882086	 F-Score:  0.642246642247

25473/25473 [==============================] - 28s - loss: 0.7004
Epoch 6/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.71707

Training -> Precision:	0.818977591036	 Recall:  0.729873101727	 F-Score:  0.771862281377
Testing	 -> Precision:	0.66253101737	 Recall:  0.605442176871	 F-Score:  0.632701421801

25473/25473 [==============================] - 28s - loss: 0.7170
Epoch 7/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.67669

Training -> Precision:	0.785922229154	 Recall:  0.786249219888	 F-Score:  0.786085690516
Testing	 -> Precision:	0.674887892377	 Recall:  0.68253968254		 F-Score:  0.67869222097

25473/25473 [==============================] - 28s - loss: 0.6766
Epoch 8/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.64236

Training -> Precision:	0.826440600298	 Recall:  0.750364052424	 F-Score:  0.786567082811
Testing	 -> Precision:	0.739583333333	 Recall:  0.643990929705	 F-Score:  0.688484848485

25473/25473 [==============================] - 28s - loss: 0.6423
Epoch 9/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.63089

Training -> Precision:	0.780232787532	 Recall:  0.822758477221	 F-Score:  0.800931551235
Testing	 -> Precision:	0.662420382166	 Recall:  0.707482993197	 F-Score:  0.684210526316

25473/25473 [==============================] - 28s - loss: 0.6308
Epoch 10/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.60253

Training -> Precision:	0.812914081397	 Recall:  0.804035781152	 F-Score:  0.808450556921
Testing	 -> Precision:	0.716937354988	 Recall:  0.700680272109	 F-Score:  0.70871559633

25473/25473 [==============================] - 29s - loss: 0.6025
Epoch 11/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.58537

Training -> Precision:	0.842730635579	 Recall:  0.781984605783	 F-Score:  0.811222012409
Testing	 -> Precision:	0.770083102493	 Recall:  0.630385487528	 F-Score:  0.693266832918

25473/25473 [==============================] - 28s - loss: 0.5853
Epoch 12/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.57160

Training -> Precision:	0.598516671042	 Recall:  0.948512585812	 F-Score:  0.733923541247
Testing	 -> Precision:	0.490514905149	 Recall:  0.820861678005	 F-Score:  0.614079728584

25473/25473 [==============================] - 28s - loss: 0.5717
Epoch 13/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.65341

Training -> Precision:	0.806171548117	 Recall:  0.801643436655	 F-Score:  0.803901116095
Testing	 -> Precision:	0.716279069767	 Recall:  0.698412698413	 F-Score:  0.707233065442

25473/25473 [==============================] - 28s - loss: 0.6534
Epoch 14/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.56990

Training -> Precision:	0.834158676641	 Recall:  0.823486582068	 F-Score:  0.828788275321
Testing	 -> Precision:	0.75	 Recall:  0.646258503401	 F-Score:  0.694275274056

25473/25473 [==============================] - 28s - loss: 0.5698
Epoch 15/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.55141

Training -> Precision:	0.880704365079	 Recall:  0.73871437487		 F-Score:  0.803484557077
Testing	 -> Precision:	0.789156626506	 Recall:  0.59410430839		 F-Score:  0.67787839586

25473/25473 [==============================] - 28s - loss: 0.5514
Epoch 16/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.55639

Training -> Precision:	0.80409694172	 Recall:  0.869669232369	 F-Score:  0.835598640816
Testing	 -> Precision:	0.709677419355	 Recall:  0.698412698413	 F-Score:  0.704

25473/25473 [==============================] - 28s - loss: 0.5563
Epoch 17/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.52220

Training -> Precision:	0.835481579214	 Recall:  0.856251300187	 F-Score:  0.845738942826
Testing	 -> Precision:	0.7725	 Recall:  0.700680272109	 F-Score:  0.734839476813

25473/25473 [==============================] - 28s - loss: 0.5223
Epoch 18/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.55053

Training -> Precision:	0.87528370404	 Recall:  0.802267526524	 F-Score:  0.837186584175
Testing	 -> Precision:	0.779369627507	 Recall:  0.616780045351	 F-Score:  0.688607594937

25473/25473 [==============================] - 29s - loss: 0.5505
Epoch 19/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.52284

Training -> Precision:	0.809226696918	 Recall:  0.890368213023	 F-Score:  0.847860538827
Testing	 -> Precision:	0.726436781609	 Recall:  0.716553287982	 F-Score:  0.721461187215

25473/25473 [==============================] - 28s - loss: 0.5228
Epoch 20/20
25472/25473 [============================>.] - ETA: 0ss--loss::0.48919

Training -> Precision:	0.834668248789	 Recall:  0.877990430622	 F-Score:  0.855781416333
Testing	 -> Precision:	0.737089201878	 Recall:  0.71201814059		 F-Score:  0.724336793541

25473/25473 [==============================] - 28s - loss: 0.4891
25473/25473 [==============================] - 12s: 0ss
1440/1458 [============================>.] - ETA: 0s

Average Precision Score 0.778798818806
Training
	     precision	  recall  f1-score   support

	  0	 0.924	   0.895     0.909     15859
	  1	 0.835	   0.878     0.856	9614

avg / total	 0.890	   0.888     0.889     25473

Testing
	     precision	  recall  f1-score   support

	  0	 0.877	   0.890     0.883	1017
	  1	 0.737	   0.712     0.724	 441

avg / total	 0.835	   0.836     0.835	1458

Testing Accuracy
0.836076817558
