38  CHARACTERS
[u'3', u'5', u'7', u'8', u'C', u'E', u'G', u'L', u'N', u'S', u'T', u'Z', u'a', u'c', u'b', u'e', u'd', u'g', u'f', u'i', u'h', u'k', u'j', u'm', u'l', u'o', u'n', u'q', u'p', u's', u'r', u'u', u't', u'w', u'v', u'y', u'x', u'z']
52  LANGUAGES
[u'SWEDISH', u'DANISH', u'GUTNISH_LAU', u'OSSETIC_IRON', u'BIHARI', u'DUTCH', u'MARATHI', u'SORBIAN_UPPER', u'ORIYA', u'SLOVENIAN', u'BELARUSIAN', u'ANCIENT_GREEK', u'GREEK', u'OLD_SWEDISH', u'ICELANDIC', u'SLOVAK', u'ENGLISH', u'ASSAMESE', u'BRETON', u'ITALIAN', u'ELFDALIAN', u'FAROESE', u'UKRAINIAN', u'CZECH', u'STAVANGERSK', u'NORWEGIAN_RIKSMAL', u'OLD_NORSE', u'SPANISH', u'MAGAHI', u'OLD_CHURCH_SLAVONIC', u'PORTUGUESE', u'OLD_IRISH', u'IRISH', u'MIDDLE_BRETON', u'GERMAN', u'DANISH_FJOLDE', u'OSSETIC', u'MACEDONIAN', u'LATIN', u'FRENCH', u'URDU', u'POLISH', u'FRISIAN', u'BULGARIAN', u'CLASSICAL_ARMENIAN', u'ARMENIAN_EASTERN', u'SORBIAN_LOWER', u'CATALAN', u'SERBO-CROATIAN', u'RUSSIAN', u'OSSETIC_DIGOR', u'MIDDLE_CORNISH']
lstm_units 70
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Vocab Size :  41
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       410
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 140)       45360
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 140)       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 140), (No 78540
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 140)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 140)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 280)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 280)	       0
____________________________________________________________________________________________________
Input Concept Feat (InputLayer)	 (None, 300)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 580)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       11620
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 135,951.0
Trainable params: 135,951.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.716330

Training -> Precision:	0.645902052121	 Recall:  0.829410243145	 F-Score:  0.726243222966
Testing	 -> Precision:	0.496598216782	 Recall:  0.741866617162	 F-Score:  0.594945660265

223666/223666 [==============================] - 344s - loss: 0.7162
Epoch 2/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.549188

Training -> Precision:	0.686797972938	 Recall:  0.850103466115	 F-Score:  0.759774599046
Testing	 -> Precision:	0.517887450498	 Recall:  0.722235113937	 F-Score:  0.603225056206

223666/223666 [==============================] - 337s - loss: 0.5491
Epoch 3/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.516522

Training -> Precision:	0.704769074316	 Recall:  0.862697232281	 F-Score:  0.775777223728
Testing	 -> Precision:	0.523565190798	 Recall:  0.715087947278	 F-Score:  0.604519774011

223666/223666 [==============================] - 336s - loss: 0.5165
Epoch 4/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.491736

Training -> Precision:	0.742294604473	 Recall:  0.856958096223	 F-Score:  0.795515769095
Testing	 -> Precision:	0.572117223965	 Recall:  0.694017728686	 F-Score:  0.627199328929

223666/223666 [==============================] - 336s - loss: 0.4917
Epoch 5/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.468683

Training -> Precision:	0.755833750626	 Recall:  0.854064278324	 F-Score:  0.801952167346
Testing	 -> Precision:	0.570157909173	 Recall:  0.675314428923	 F-Score:  0.618296932098

223666/223666 [==============================] - 336s - loss: 0.4686
Epoch 6/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.442897

Training -> Precision:	0.741042256589	 Recall:  0.880011639938	 F-Score:  0.80457017855
Testing	 -> Precision:	0.536025606102	 Recall:  0.730588945097	 F-Score:  0.6183639399

223666/223666 [==============================] - 336s - loss: 0.4428
Epoch 7/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.418557

Training -> Precision:	0.817968609056	 Recall:  0.879591308846	 F-Score:  0.847661483813
Testing	 -> Precision:	0.614839014744	 Recall:  0.663804705992	 F-Score:  0.638384289221

223666/223666 [==============================] - 336s - loss: 0.4185
Epoch 8/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.393528

Training -> Precision:	0.784350321044	 Recall:  0.910404811174	 F-Score:  0.84268965156
Testing	 -> Precision:	0.562248273878	 Recall:  0.725623056574	 F-Score:  0.633573092898

223666/223666 [==============================] - 337s - loss: 0.3935
Epoch 9/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.370671

Training -> Precision:	0.820180570603	 Recall:  0.91788993792		 F-Score:  0.866288783271
Testing	 -> Precision:	0.582412396272	 Recall:  0.687288253585	 F-Score:  0.630519010516

223666/223666 [==============================] - 335s - loss: 0.3706
Epoch 10/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.349154

Training -> Precision:	0.825652621937	 Recall:  0.932650025867	 F-Score:  0.875895785254
Testing	 -> Precision:	0.575736407032	 Recall:  0.688494918086	 F-Score:  0.627087120091

223666/223666 [==============================] - 336s - loss: 0.3491
Epoch 11/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.329734

Training -> Precision:	0.841901659371	 Recall:  0.935883341956	 F-Score:  0.886408354196
Testing	 -> Precision:	0.581111154492	 Recall:  0.690769016568	 F-Score:  0.631212892282

223666/223666 [==============================] - 336s - loss: 0.3297
Epoch 12/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.310608

Training -> Precision:	0.854987069472	 Recall:  0.940684816348	 F-Score:  0.895790996983
Testing	 -> Precision:	0.591674648787	 Recall:  0.688030816355	 F-Score:  0.636225135721

223666/223666 [==============================] - 336s - loss: 0.3106
Epoch 13/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.295703

Training -> Precision:	0.830958141616	 Recall:  0.960553543714	 F-Score:  0.89106846932
Testing	 -> Precision:	0.561778228288	 Recall:  0.72019306632		 F-Score:  0.631197884889

223666/223666 [==============================] - 336s - loss: 0.2957
Epoch 14/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.279915

Training -> Precision:	0.893138632614	 Recall:  0.945292291774	 F-Score:  0.91847569979
Testing	 -> Precision:	0.635555954411	 Recall:  0.657353691929	 F-Score:  0.646271074305

223666/223666 [==============================] - 336s - loss: 0.2799
Epoch 15/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.269276

Training -> Precision:	0.891160062289	 Recall:  0.952922917744	 F-Score:  0.921007195369
Testing	 -> Precision:	0.632629626358	 Recall:  0.664779319627	 F-Score:  0.648306139537

223666/223666 [==============================] - 335s - loss: 0.2692
Epoch 16/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.256113

Training -> Precision:	0.895681334119	 Recall:  0.958597387481	 F-Score:  0.92607198357
Testing	 -> Precision:	0.605674821102	 Recall:  0.675639300135	 F-Score:  0.638746901257

223666/223666 [==============================] - 337s - loss: 0.2561
Epoch 17/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.247433

Training -> Precision:	0.891952143866	 Recall:  0.970237325401	 F-Score:  0.929449206681
Testing	 -> Precision:	0.596003087047	 Recall:  0.680976470042	 F-Score:  0.635662608846

223666/223666 [==============================] - 336s - loss: 0.2474
Epoch 18/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.237153

Training -> Precision:	0.896277151991	 Recall:  0.969913993792	 F-Score:  0.93164277839
Testing	 -> Precision:	0.590940315998	 Recall:  0.67870237156		 F-Score:  0.631788136692

223666/223666 [==============================] - 336s - loss: 0.2371
Epoch 19/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.229982

Training -> Precision:	0.905031956072	 Recall:  0.975232798758	 F-Score:  0.938821881566
Testing	 -> Precision:	0.602285808255	 Recall:  0.679909036061	 F-Score:  0.638747792723

223666/223666 [==============================] - 336s - loss: 0.2299
Epoch 20/20
223616/223666 [============================>.] - ETA: 0ss--loss::0.223615

Training -> Precision:	0.917380267906	 Recall:  0.969881660631	 F-Score:  0.942900700971
Testing	 -> Precision:	0.631688611074	 Recall:  0.661298556644	 F-Score:  0.646154543806

223666/223666 [==============================] - 336s - loss: 0.2236
103040/103092 [============================>.] - ETA: 0sss

Average Precision Score 0.684679773774
Training
	     precision	  recall  f1-score   support

	  0	 0.988	   0.967     0.977    161810
	  1	 0.917	   0.970     0.943     61856

avg / total	 0.969	   0.968     0.968    223666

Testing
	     precision	  recall  f1-score   support

	  0	 0.909	   0.898     0.904     81545
	  1	 0.632	   0.661     0.646     21547

avg / total	 0.851	   0.849     0.850    103092

Testing Accuracy
0.848620649517
