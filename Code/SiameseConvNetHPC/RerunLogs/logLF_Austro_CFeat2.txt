lstm_units 40
epochs 40
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Language Features False
Concept Features True
30  CHARACTERS
['3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z', '~']
100  LANGUAGES
['Teanu', 'Banjarese Malay', 'Lampung', 'Patpatar', 'Tabar', 'Tontemboan', 'Ambrym, South-East', 'Magori (South East Papua)', 'Futuna-Aniwa', 'Wuna', 'Tikopia', 'Cheke Holo', 'Windesi Wandamen', 'Gapapaiwa', 'Bunun, Southern', 'Tunjung', 'Tigak', 'Manam', 'Roti (Termanu Dialect)', 'Tetum', 'Sekar', 'Vitu', 'Alune', 'Tongan', 'Dobuan', 'Savu', 'Makassar', 'Watubela', 'Carolinian', 'Katingan', 'Soboyo', 'Kisar', 'Mambai', 'Tboli (Tagabili)', 'Sasak', 'Wogeo', 'Lenakel', 'Toambaita', 'Western Bukidnon Manobo', 'Baree', 'Molima', 'Wolio', 'Anejom (Aneityum)', 'Sengseng', 'Dehu', 'Ubir', 'Marshallese (E. Dialect)', 'Nakanai (Bileki Dialect)', 'Paiwan (Kulalao)', 'Rotuman', 'Singhi', 'Ujir (N.Aru)', 'Tsou', 'Futuna, East', 'Jawe', 'Bonfia', 'Samoan', 'Waropen', 'Santa Ana', 'Kapingamarangi', 'Kanakanabu', 'Melayu Ambon', 'Tuvalu', 'Lahanan', 'Kwaraae (Solomon Islands)', 'Maanyan', 'Roviana', 'Cebuano', 'Rejang Rejang', 'Ririo', 'Bukat', 'Teop', 'Wuvulu', 'Punan Kelai', 'Kilivila', 'Itbayaten', 'Sangir', 'Chuukese', 'Varisi', 'Seimat', 'Dayak Ngaju', 'Rurutuan', 'Tae (S.Toraja)', 'Ponapean', 'Taiof', 'Yakan', 'Vaghua', 'Raga', 'Toba Batak', 'Tahitian (Modern)', 'Elat, Kei Besar', 'Belait', 'Rennellese', 'Lio, Flores Tongah', 'Koiwai (Irian Jaya)', 'Woleai', 'As', 'Sika', 'Minangkabau', 'Selaru']
Vocab Size :  32
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       320
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 80)	       16320
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 80)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 80), (Non 25680
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 160)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 160)	       0
____________________________________________________________________________________________________
Input Concept Feat (InputLayer)	 (None, 300)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 460)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       9220
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 51,561.0
Trainable params: 51,561.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.780662

Training -> Precision:	0.660070271367	 Recall:  0.641444227656	 F-Score:  0.650623970357	 AUC:  0.713610670868
Testing	 -> Precision:	0.572785388128	 Recall:  0.592145015106	 F-Score:  0.582304335716	 AUC:  0.643172231978

333626/333626 [==============================] - 392s - loss: 0.7806
Epoch 2/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.681984

Training -> Precision:	0.567680577191	 Recall:  0.790443771016	 F-Score:  0.660793066202	 AUC:  0.741428403745
Testing	 -> Precision:	0.495290034705	 Recall:  0.754531722054	 F-Score:  0.59802454355	 AUC:  0.680043914463

333626/333626 [==============================] - 384s - loss: 0.6819
Epoch 3/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.642505

Training -> Precision:	0.661875058188	 Recall:  0.737805637428	 F-Score:  0.697780787766	 AUC:  0.772308402874
Testing	 -> Precision:	0.575533919598	 Recall:  0.692031722054	 F-Score:  0.628429355281	 AUC:  0.697727326796

333626/333626 [==============================] - 384s - loss: 0.6425
Epoch 4/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.612398

Training -> Precision:	0.657560583792	 Recall:  0.798632155756	 F-Score:  0.72126307502	 AUC:  0.805038174389
Testing	 -> Precision:	0.554610126935	 Recall:  0.750755287009	 F-Score:  0.637946249499	 AUC:  0.71326416242

333626/333626 [==============================] - 384s - loss: 0.6124
Epoch 5/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.581221

Training -> Precision:	0.658424645746	 Recall:  0.833772676325	 F-Score:  0.735796092008	 AUC:  0.828661276781
Testing	 -> Precision:	0.554901423877	 Recall:  0.765294561934	 F-Score:  0.643333333333	 AUC:  0.731595810734

333626/333626 [==============================] - 384s - loss: 0.5812
Epoch 6/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.553341

Training -> Precision:	0.708292770062	 Recall:  0.823031259081	 F-Score:  0.761363472718	 AUC:  0.850212893053
Testing	 -> Precision:	0.590289225236	 Recall:  0.743768882175	 F-Score:  0.658200350907	 AUC:  0.748816123803

333626/333626 [==============================] - 385s - loss: 0.5533
Epoch 7/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.528069

Training -> Precision:	0.70611915573	 Recall:  0.853761052763	 F-Score:  0.772952987658	 AUC:  0.866550715393
Testing	 -> Precision:	0.574604531851	 Recall:  0.761329305136	 F-Score:  0.654917566799	 AUC:  0.747231855009

333626/333626 [==============================] - 384s - loss: 0.5280
Epoch 8/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.506308

Training -> Precision:	0.773678392739	 Recall:  0.828085433185	 F-Score:  0.799957892204	 AUC:  0.881485911563
Testing	 -> Precision:	0.627155901251	 Recall:  0.700339879154	 F-Score:  0.661730597681	 AUC:  0.745205557273

333626/333626 [==============================] - 384s - loss: 0.5063
Epoch 9/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.486811

Training -> Precision:	0.74089740327	 Recall:  0.876188301714	 F-Score:  0.802883403786	 AUC:  0.893862128432
Testing	 -> Precision:	0.59219858156	 Recall:  0.756797583082	 F-Score:  0.664456233422	 AUC:  0.757054988312

333626/333626 [==============================] - 387s - loss: 0.4868
Epoch 10/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.470862

Training -> Precision:	0.78248705055	 Recall:  0.859147328656	 F-Score:  0.819027266611	 AUC:  0.90080531996
Testing	 -> Precision:	0.629045242312	 Recall:  0.737726586103	 F-Score:  0.679064917007	 AUC:  0.758089839233

333626/333626 [==============================] - 390s - loss: 0.4708
Epoch 11/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.454930

Training -> Precision:	0.779517539006	 Recall:  0.877309145253	 F-Score:  0.82552734375	 AUC:  0.909764705488
Testing	 -> Precision:	0.622460588331	 Recall:  0.723187311178	 F-Score:  0.669054065857	 AUC:  0.758936376393

333626/333626 [==============================] - 389s - loss: 0.4549
Epoch 12/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.442794

Training -> Precision:	0.77202016951	 Recall:  0.896176678152	 F-Score:  0.829478214094	 AUC:  0.91674380718
Testing	 -> Precision:	0.613785557987	 Recall:  0.741503021148	 F-Score:  0.671626475115	 AUC:  0.759457680918

333626/333626 [==============================] - 391s - loss: 0.4427
Epoch 13/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.431254

Training -> Precision:	0.780474838942	 Recall:  0.898968408817	 F-Score:  0.83554145104	 AUC:  0.921307004312
Testing	 -> Precision:	0.620408815075	 Recall:  0.733572507553	 F-Score:  0.672261636961	 AUC:  0.755737696593

333626/333626 [==============================] - 389s - loss: 0.4312
Epoch 14/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.418657

Training -> Precision:	0.806617971101	 Recall:  0.892783012993	 F-Score:  0.847516071033	 AUC:  0.925784230006
Testing	 -> Precision:	0.63476690742	 Recall:  0.730173716012	 F-Score:  0.679135932561	 AUC:  0.763457291153

333626/333626 [==============================] - 390s - loss: 0.4186
Epoch 15/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.412468

Training -> Precision:	0.815978261892	 Recall:  0.900670430487	 F-Score:  0.85623516992	 AUC:  0.931270913355
Testing	 -> Precision:	0.641120241489	 Recall:  0.721865558912	 F-Score:  0.679101163514	 AUC:  0.76378590269

333626/333626 [==============================] - 389s - loss: 0.4124
Epoch 16/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.402519

Training -> Precision:	0.76416281284	 Recall:  0.93289468222		 F-Score:  0.84014056863	 AUC:  0.934761809591
Testing	 -> Precision:	0.589062724272	 Recall:  0.774924471299	 F-Score:  0.669330506401	 AUC:  0.763701904907

333626/333626 [==============================] - 390s - loss: 0.4025
Epoch 17/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.394778

Training -> Precision:	0.844847211277	 Recall:  0.901251608618	 F-Score:  0.872138391624	 AUC:  0.940766013002
Testing	 -> Precision:	0.656583318762	 Recall:  0.709025679758	 F-Score:  0.681797548797	 AUC:  0.766427326012

333626/333626 [==============================] - 390s - loss: 0.3947
Epoch 18/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.387364

Training -> Precision:	0.829994888203	 Recall:  0.909948524223	 F-Score:  0.86813469707	 AUC:  0.939459523718
Testing	 -> Precision:	0.647904191617	 Recall:  0.715067975831	 F-Score:  0.679831253927	 AUC:  0.770300378468

333626/333626 [==============================] - 391s - loss: 0.3872
Epoch 19/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.380483

Training -> Precision:	0.823356533746	 Recall:  0.915864087343	 F-Score:  0.867150114475	 AUC:  0.941681139501
Testing	 -> Precision:	0.649241146712	 Recall:  0.726963746224	 F-Score:  0.685907714235	 AUC:  0.772579701112

333626/333626 [==============================] - 391s - loss: 0.3804
Epoch 20/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.374922

Training -> Precision:	0.843780300006	 Recall:  0.921208850513	 F-Score:  0.880796213422	 AUC:  0.948807521733
Testing	 -> Precision:	0.657023353085	 Recall:  0.711858006042	 F-Score:  0.68334239623	 AUC:  0.772273049707

333626/333626 [==============================] - 392s - loss: 0.3749
Epoch 21/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.367487

Training -> Precision:	0.845567061426	 Recall:  0.920316326954	 F-Score:  0.881359638225	 AUC:  0.948512756701
Testing	 -> Precision:	0.650664824728	 Recall:  0.711480362538	 F-Score:  0.67971498151	 AUC:  0.772064345428

333626/333626 [==============================] - 391s - loss: 0.3674
Epoch 22/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.363067

Training -> Precision:	0.846378682053	 Recall:  0.92560919922		 F-Score:  0.884222632007	 AUC:  0.952325304505
Testing	 -> Precision:	0.659118834474	 Recall:  0.709025679758	 F-Score:  0.68316201219	 AUC:  0.773977537396

333626/333626 [==============================] - 391s - loss: 0.3630
Epoch 23/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.357360

Training -> Precision:	0.850402574952	 Recall:  0.924052472083	 F-Score:  0.88569908036	 AUC:  0.953633055237
Testing	 -> Precision:	0.657292576419	 Recall:  0.710536253776	 F-Score:  0.682878141729	 AUC:  0.777078885687

333626/333626 [==============================] - 391s - loss: 0.3573
Epoch 24/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.351914

Training -> Precision:	0.836860597007	 Recall:  0.941819917805	 F-Score:  0.886243450832	 AUC:  0.956774247175
Testing	 -> Precision:	0.630004902762	 Recall:  0.727907854985	 F-Score:  0.675427069645	 AUC:  0.77603665352

333626/333626 [==============================] - 391s - loss: 0.3519
Epoch 25/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.347609

Training -> Precision:	0.828988880504	 Recall:  0.946261779235	 F-Score:  0.883751811304	 AUC:  0.95836895953
Testing	 -> Precision:	0.628022417934	 Recall:  0.740558912387	 F-Score:  0.679663807296	 AUC:  0.780582198444

333626/333626 [==============================] - 391s - loss: 0.3476
Epoch 26/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.343764

Training -> Precision:	0.863183815364	 Recall:  0.927674457221	 F-Score:  0.894267949237	 AUC:  0.95773531359
Testing	 -> Precision:	0.654107796965	 Recall:  0.708081570997	 F-Score:  0.680025387614	 AUC:  0.774458956844

333626/333626 [==============================] - 391s - loss: 0.3437
Epoch 27/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.339122

Training -> Precision:	0.877504208547	 Recall:  0.925069533812	 F-Score:  0.900659307348	 AUC:  0.960277352411
Testing	 -> Precision:	0.677106227106	 Recall:  0.698074018127	 F-Score:  0.687430271476	 AUC:  0.776092409913

333626/333626 [==============================] - 391s - loss: 0.3391
Epoch 28/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.335638

Training -> Precision:	0.859365666335	 Recall:  0.940605670638	 F-Score:  0.898152323098	 AUC:  0.961713402368
Testing	 -> Precision:	0.655274629468	 Recall:  0.709592145015	 F-Score:  0.681352551899	 AUC:  0.769450218123

333626/333626 [==============================] - 391s - loss: 0.3356
Epoch 29/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.331913

Training -> Precision:	0.83758968579	 Recall:  0.948638382664	 F-Score:  0.889662119745	 AUC:  0.960064581168
Testing	 -> Precision:	0.628818820454	 Recall:  0.726774924471	 F-Score:  0.674257685907	 AUC:  0.769745325562

333626/333626 [==============================] - 390s - loss: 0.3319
Epoch 30/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.329200

Training -> Precision:	0.863263445761	 Recall:  0.943501183113	 F-Score:  0.901600650574	 AUC:  0.964470654882
Testing	 -> Precision:	0.652866793695	 Recall:  0.71166918429		 F-Score:  0.681000993766	 AUC:  0.772067991547

333626/333626 [==============================] - 392s - loss: 0.3292
Epoch 31/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.326369

Training -> Precision:	0.884005517026	 Recall:  0.937886587239	 F-Score:  0.910149306342	 AUC:  0.966336398118
Testing	 -> Precision:	0.686737947852	 Recall:  0.691276435045	 F-Score:  0.6889997177		 AUC:  0.777784711037

333626/333626 [==============================] - 390s - loss: 0.3263
Epoch 32/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.322622

Training -> Precision:	0.863531742288	 Recall:  0.950049815268	 F-Score:  0.904727078659	 AUC:  0.96636012086
Testing	 -> Precision:	0.64908412483	 Recall:  0.722620845921	 F-Score:  0.683881343817	 AUC:  0.770363487887

333626/333626 [==============================] - 391s - loss: 0.3226
Epoch 33/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.320249

Training -> Precision:	0.85409117095	 Recall:  0.953952011291	 F-Score:  0.901263861789	 AUC:  0.966970548619
Testing	 -> Precision:	0.635575192276	 Recall:  0.733383685801	 F-Score:  0.680985359867	 AUC:  0.778998528534

333626/333626 [==============================] - 390s - loss: 0.3202
Epoch 34/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.316299

Training -> Precision:	0.880860473687	 Recall:  0.942567146831	 F-Score:  0.910669701497	 AUC:  0.967522886682
Testing	 -> Precision:	0.681877202745	 Recall:  0.694108761329	 F-Score:  0.687938617011	 AUC:  0.778531519609

333626/333626 [==============================] - 390s - loss: 0.3161
Epoch 35/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.313109

Training -> Precision:	0.863394030411	 Recall:  0.954647349413	 F-Score:  0.906730541755	 AUC:  0.968819666536
Testing	 -> Precision:	0.645307769929	 Recall:  0.724509063444	 F-Score:  0.682618751112	 AUC:  0.770640059466

333626/333626 [==============================] - 390s - loss: 0.3131
Epoch 36/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.311179

Training -> Precision:	0.846880786082	 Recall:  0.958871269044	 F-Score:  0.899403272752	 AUC:  0.968532025833
Testing	 -> Precision:	0.627504407758	 Recall:  0.739237160121	 F-Score:  0.678803641092	 AUC:  0.773779257401

333626/333626 [==============================] - 390s - loss: 0.3112
Epoch 37/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.309232

Training -> Precision:	0.852488637726	 Recall:  0.959691145336	 F-Score:  0.902919020256	 AUC:  0.969292914294
Testing	 -> Precision:	0.632491091675	 Recall:  0.737348942598	 F-Score:  0.680906713165	 AUC:  0.774403030957

333626/333626 [==============================] - 390s - loss: 0.3092
Epoch 38/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.306137

Training -> Precision:	0.867079275336	 Recall:  0.958155174561	 F-Score:  0.910344963591	 AUC:  0.97085307789
Testing	 -> Precision:	0.643631436314	 Recall:  0.71752265861		 F-Score:  0.678571428571	 AUC:  0.773400047419

333626/333626 [==============================] - 390s - loss: 0.3061
Epoch 39/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.303337

Training -> Precision:	0.905753879048	 Recall:  0.940844368799	 F-Score:  0.922965715595	 AUC:  0.971691887093
Testing	 -> Precision:	0.696222050887	 Recall:  0.682024169184	 F-Score:  0.689049980923	 AUC:  0.778846288854

333626/333626 [==============================] - 390s - loss: 0.3033
Epoch 40/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.301755

Training -> Precision:	0.88167158101	 Recall:  0.95268587322		 F-Score:  0.915804123249	 AUC:  0.971754493676
Testing	 -> Precision:	0.662257495591	 Recall:  0.709025679758	 F-Score:  0.684844063469	 AUC:  0.77932309532

333626/333626 [==============================] - 390s - loss: 0.3017
20799/207992[==============================].- 10s:A0sssss


Average Precision Score 0.77932309532
Training
	     precision	  recall  f1-score   support

	  0	 0.980	   0.948     0.964    237270
	  1	 0.882	   0.953     0.916     96356

avg / total	 0.952	   0.949     0.950    333626

Testing
	     precision	  recall  f1-score   support

	  0	 0.898	   0.876     0.887     15503
	  1	 0.662	   0.709     0.685	5296

avg / total	 0.838	   0.834     0.836     20799

Testing Accuracy
0.833838165296
