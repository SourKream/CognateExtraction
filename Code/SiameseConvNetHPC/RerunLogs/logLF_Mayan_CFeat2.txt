lstm_units 30
epochs 40
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Language Features False
Concept Features True
32  CHARACTERS
[' ', '"', '%', '3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', '~']
30  LANGUAGES
['SIPAKAPENSE', 'TZUTUJIL_SAN_JUAN_LA_LAGUNA', 'MAM_NORTHERN', 'CHORTI', 'POQOMCHI_WESTERN', 'TZELTAL_BACHAJON', 'SOUTHERN_CAKCHIQUEL_SAN_ANDRES_ITZAPA', 'MAYA_YUCATAN', 'CHONTAL_TABASCO', 'CENTRAL_QUICHE', 'EASTERN_KEKCHI_CAHABON', 'TECO_TECTITAN', 'JACALTEC', 'QANJOBAL_SANTA_EULALIA', 'LACANDON', 'ZINACANTAN_TZOTZIL', 'POCOMAM_EASTERN', 'IXIL_CHAJUL', 'CHUJ', 'CHOL_TUMBALA', 'AGUACATEC', 'MOPAN', 'MOCHO', 'ITZAJ', 'HUASTEC', 'USPANTEKO', 'ACATECO_SAN_MIGUEL_ACATAN', 'SACAPULTECO_SACAPULAS_CENTRO', 'TOJOLABAL', 'CHICOMUCELTEC']
Vocab Size :  34
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       340
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 60)	       9840
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 60)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 60), (Non 14460
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 60)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 60)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 120)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 120)	       0
____________________________________________________________________________________________________
Input Concept Feat (InputLayer)	 (None, 300)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 420)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       8420
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 33,081.0
Trainable params: 33,081.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/40
25472/25473 [============================>.] - ETA: 0ss--loss::1.004895

Training -> Precision:	0.577836600372	 Recall:  0.840128978573	 F-Score:  0.684723635131	 AUC:  0.829774404419
Testing	 -> Precision:	0.47074829932	 Recall:  0.784580498866	 F-Score:  0.58843537415	 AUC:  0.693707681794

25473/25473 [==============================] - 36s - loss: 1.0047
Epoch 2/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.74694

Training -> Precision:	0.749040102389	 Recall:  0.730497191596	 F-Score:  0.739652448657	 AUC:  0.836249467118
Testing	 -> Precision:	0.605206073753	 Recall:  0.632653061224	 F-Score:  0.618625277162	 AUC:  0.691781429296

25473/25473 [==============================] - 27s - loss: 0.7469
Epoch 3/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.72552

Training -> Precision:	0.715329889874	 Recall:  0.763469939671	 F-Score:  0.738616352201	 AUC:  0.841608080344
Testing	 -> Precision:	0.580078125	 Recall:  0.673469387755	 F-Score:  0.623294858342	 AUC:  0.709727111057

25473/25473 [==============================] - 27s - loss: 0.7255
Epoch 4/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.71340

Training -> Precision:	0.732802672956	 Recall:  0.775639692116	 F-Score:  0.753612935826	 AUC:  0.857316585213
Testing	 -> Precision:	0.579150579151	 Recall:  0.680272108844	 F-Score:  0.625651720542	 AUC:  0.724692029933

25473/25473 [==============================] - 27s - loss: 0.7134
Epoch 5/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.68225

Training -> Precision:	0.687489404984	 Recall:  0.84366548783		 F-Score:  0.757612553708	 AUC:  0.872135311697
Testing	 -> Precision:	0.587931034483	 Recall:  0.773242630385	 F-Score:  0.667972575906	 AUC:  0.760549011357

25473/25473 [==============================] - 27s - loss: 0.6822
Epoch 6/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.64299

Training -> Precision:	0.763597304951	 Recall:  0.813397129187	 F-Score:  0.787710904054	 AUC:  0.879896808829
Testing	 -> Precision:	0.670190274841	 Recall:  0.718820861678	 F-Score:  0.693654266958	 AUC:  0.802485144377

25473/25473 [==============================] - 27s - loss: 0.6429
Epoch 7/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.61034

Training -> Precision:	0.740934480007	 Recall:  0.869253172457	 F-Score:  0.799980854832	 AUC:  0.897210515751
Testing	 -> Precision:	0.632653061224	 Recall:  0.773242630385	 F-Score:  0.695918367347	 AUC:  0.82091218718

25473/25473 [==============================] - 27s - loss: 0.6103
Epoch 8/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.58477

Training -> Precision:	0.788673902784	 Recall:  0.869149157479	 F-Score:  0.826958285912	 AUC:  0.909910891902
Testing	 -> Precision:	0.665346534653	 Recall:  0.761904761905	 F-Score:  0.710359408034	 AUC:  0.827282524227

25473/25473 [==============================] - 27s - loss: 0.5847
Epoch 9/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.56216

Training -> Precision:	0.708694940233	 Recall:  0.900353650926	 F-Score:  0.793109767271	 AUC:  0.902631241886
Testing	 -> Precision:	0.604026845638	 Recall:  0.816326530612	 F-Score:  0.69431051109	 AUC:  0.80758402762

25473/25473 [==============================] - 27s - loss: 0.5621
Epoch 10/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.56676

Training -> Precision:	0.808434808435	 Recall:  0.849386311629	 F-Score:  0.828404767943	 AUC:  0.91688964979
Testing	 -> Precision:	0.697872340426	 Recall:  0.743764172336	 F-Score:  0.720087815587	 AUC:  0.821069767006

25473/25473 [==============================] - 27s - loss: 0.5667
Epoch 11/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.54362

Training -> Precision:	0.884006192688	 Recall:  0.772103182858	 F-Score:  0.824274054744	 AUC:  0.914417734822
Testing	 -> Precision:	0.781333333333	 Recall:  0.664399092971	 F-Score:  0.718137254902	 AUC:  0.816802054365

25473/25473 [==============================] - 27s - loss: 0.5436
Epoch 12/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.53552

Training -> Precision:	0.699398484493	 Recall:  0.931246099438	 F-Score:  0.798840062458	 AUC:  0.924336238716
Testing	 -> Precision:	0.56891025641	 Recall:  0.804988662132	 F-Score:  0.666666666667	 AUC:  0.818160337032

25473/25473 [==============================] - 27s - loss: 0.5355
Epoch 13/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.54901

Training -> Precision:	0.851942004445	 Recall:  0.837320574163	 F-Score:  0.844568011331	 AUC:  0.931163060531
Testing	 -> Precision:	0.727053140097	 Recall:  0.68253968254		 F-Score:  0.704093567251	 AUC:  0.816148448684

25473/25473 [==============================] - 27s - loss: 0.5490
Epoch 14/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.52515

Training -> Precision:	0.828069129917	 Recall:  0.867172872894	 F-Score:  0.847170003048	 AUC:  0.929589590344
Testing	 -> Precision:	0.733944954128	 Recall:  0.725623582766	 F-Score:  0.72976054732	 AUC:  0.819629449834

25473/25473 [==============================] - 27s - loss: 0.5251
Epoch 15/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.51044

Training -> Precision:	0.728789756299	 Recall:  0.9176201373	 F-Score:  0.812376260417	 AUC:  0.921178944358
Testing	 -> Precision:	0.590509666081	 Recall:  0.761904761905	 F-Score:  0.665346534653	 AUC:  0.800458555903

25473/25473 [==============================] - 27s - loss: 0.5105
Epoch 16/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.59963

Training -> Precision:	0.849303413804	 Recall:  0.830663615561	 F-Score:  0.839880107272	 AUC:  0.926524097844
Testing	 -> Precision:	0.765151515152	 Recall:  0.687074829932	 F-Score:  0.724014336918	 AUC:  0.824438967664

25473/25473 [==============================] - 28s - loss: 0.5996
Epoch 17/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.52047

Training -> Precision:	0.777499104264	 Recall:  0.902850010401	 F-Score:  0.835499085571	 AUC:  0.929787491849
Testing	 -> Precision:	0.691511387164	 Recall:  0.757369614512	 F-Score:  0.722943722944	 AUC:  0.831294705658

25473/25473 [==============================] - 27s - loss: 0.5204
Epoch 18/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.50599

Training -> Precision:	0.762999311295	 Recall:  0.921884751404	 F-Score:  0.834950541686	 AUC:  0.936751861605
Testing	 -> Precision:	0.68431372549	 Recall:  0.791383219955	 F-Score:  0.73396424816	 AUC:  0.842754843573

25473/25473 [==============================] - 27s - loss: 0.5059
Epoch 19/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.48571

Training -> Precision:	0.798525345622	 Recall:  0.901185770751	 F-Score:  0.846755277561	 AUC:  0.935463142959
Testing	 -> Precision:	0.728260869565	 Recall:  0.759637188209	 F-Score:  0.743618201998	 AUC:  0.836649286888

25473/25473 [==============================] - 27s - loss: 0.4857
Epoch 20/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.49595

Training -> Precision:	0.807361509294	 Recall:  0.908050759309	 F-Score:  0.854751064767	 AUC:  0.939435224067
Testing	 -> Precision:	0.744343891403	 Recall:  0.746031746032	 F-Score:  0.745186862967	 AUC:  0.836471810248

25473/25473 [==============================] - 27s - loss: 0.4959
Epoch 21/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.47359

Training -> Precision:	0.828692145189	 Recall:  0.897649261494	 F-Score:  0.861793489115	 AUC:  0.944294374882
Testing	 -> Precision:	0.751789976134	 Recall:  0.714285714286	 F-Score:  0.732558139535	 AUC:  0.834329120341

25473/25473 [==============================] - 27s - loss: 0.4735
Epoch 22/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.46706

Training -> Precision:	0.836915662651	 Recall:  0.903162055336	 F-Score:  0.868777827805	 AUC:  0.944853846952
Testing	 -> Precision:	0.735498839907	 Recall:  0.718820861678	 F-Score:  0.727064220183	 AUC:  0.83489675406

25473/25473 [==============================] - 27s - loss: 0.4669
Epoch 23/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.45383

Training -> Precision:	0.862030343142	 Recall:  0.880590805076	 F-Score:  0.871211731412	 AUC:  0.943434137065
Testing	 -> Precision:	0.785536159601	 Recall:  0.714285714286	 F-Score:  0.748218527316	 AUC:  0.833442533158

25473/25473 [==============================] - 27s - loss: 0.4539
Epoch 24/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.48070

Training -> Precision:	0.833573833574	 Recall:  0.901289785729	 F-Score:  0.866110250387	 AUC:  0.941818581986
Testing	 -> Precision:	0.758700696056	 Recall:  0.741496598639	 F-Score:  0.75		 AUC:  0.826938473435

25473/25473 [==============================] - 27s - loss: 0.4807
Epoch 25/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.44569

Training -> Precision:	0.812983702085	 Recall:  0.928749739963	 F-Score:  0.867019468855	 AUC:  0.94572746186
Testing	 -> Precision:	0.724731182796	 Recall:  0.764172335601	 F-Score:  0.743929359823	 AUC:  0.833401446992

25473/25473 [==============================] - 27s - loss: 0.4456
Epoch 26/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.44619

Training -> Precision:	0.884525578433	 Recall:  0.866860827959	 F-Score:  0.875604118512	 AUC:  0.944970986553
Testing	 -> Precision:	0.809018567639	 Recall:  0.691609977324	 F-Score:  0.745721271394	 AUC:  0.836824056584

25473/25473 [==============================] - 27s - loss: 0.4461
Epoch 27/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.45424

Training -> Precision:	0.81501731365	 Recall:  0.930309964635	 F-Score:  0.868855644065	 AUC:  0.948370829859
Testing	 -> Precision:	0.733188720174	 Recall:  0.766439909297	 F-Score:  0.749445676275	 AUC:  0.847289940175

25473/25473 [==============================] - 27s - loss: 0.4542
Epoch 28/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.42526

Training -> Precision:	0.806178510313	 Recall:  0.931038069482	 F-Score:  0.864121253077	 AUC:  0.949405451047
Testing	 -> Precision:	0.70325203252	 Recall:  0.784580498866	 F-Score:  0.741693461951	 AUC:  0.839387132049

25473/25473 [==============================] - 27s - loss: 0.4252
Epoch 29/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.45223

Training -> Precision:	0.805241108833	 Recall:  0.939671312669	 F-Score:  0.867277876446	 AUC:  0.951915989358
Testing	 -> Precision:	0.68875502008	 Recall:  0.777777777778	 F-Score:  0.730564430245	 AUC:  0.841871167923

25473/25473 [==============================] - 27s - loss: 0.4522
Epoch 30/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.42023

Training -> Precision:	0.83908153702	 Recall:  0.931246099438	 F-Score:  0.882764740682	 AUC:  0.957338929755
Testing	 -> Precision:	0.736017897092	 Recall:  0.746031746032	 F-Score:  0.740990990991	 AUC:  0.841168017488

25473/25473 [==============================] - 27s - loss: 0.4203
Epoch 31/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.41590

Training -> Precision:	0.858630665381	 Recall:  0.926149365509	 F-Score:  0.891112890312	 AUC:  0.958340665558
Testing	 -> Precision:	0.764705882353	 Recall:  0.766439909297	 F-Score:  0.76557191393	 AUC:  0.840333147568

25473/25473 [==============================] - 27s - loss: 0.4159
Epoch 32/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.40835

Training -> Precision:	0.869372037915	 Recall:  0.915851882671	 F-Score:  0.892006888866	 AUC:  0.960364610549
Testing	 -> Precision:	0.77304964539	 Recall:  0.741496598639	 F-Score:  0.756944444444	 AUC:  0.837299702633

25473/25473 [==============================] - 27s - loss: 0.4084
Epoch 33/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.41140

Training -> Precision:	0.870422810272	 Recall:  0.92718951529		 F-Score:  0.897909846386	 AUC:  0.962389822015
Testing	 -> Precision:	0.768321513002	 Recall:  0.736961451247	 F-Score:  0.752314814815	 AUC:  0.845313541753

25473/25473 [==============================] - 27s - loss: 0.4114
Epoch 34/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.39063

Training -> Precision:	0.854328471301	 Recall:  0.938215102975	 F-Score:  0.894308943089	 AUC:  0.96149908724
Testing	 -> Precision:	0.751152073733	 Recall:  0.739229024943	 F-Score:  0.745142857143	 AUC:  0.843176483162

25473/25473 [==============================] - 27s - loss: 0.3906
Epoch 35/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.39455

Training -> Precision:	0.846455223881	 Recall:  0.943831911795	 F-Score:  0.892495328022	 AUC:  0.961405233968
Testing	 -> Precision:	0.733188720174	 Recall:  0.766439909297	 F-Score:  0.749445676275	 AUC:  0.846592584323

25473/25473 [==============================] - 27s - loss: 0.3944
Epoch 36/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.38157

Training -> Precision:	0.862300105334	 Recall:  0.936654878302	 F-Score:  0.897940868525	 AUC:  0.964835960186
Testing	 -> Precision:	0.766743648961	 Recall:  0.75283446712		 F-Score:  0.759725400458	 AUC:  0.845073657387

25473/25473 [==============================] - 27s - loss: 0.3816
Epoch 37/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.37664

Training -> Precision:	0.838417975886	 Recall:  0.954753484502	 F-Score:  0.89281198327	 AUC:  0.964036411805
Testing	 -> Precision:	0.751101321586	 Recall:  0.773242630385	 F-Score:  0.762011173184	 AUC:  0.846528670532

25473/25473 [==============================] - 27s - loss: 0.3766
Epoch 38/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.37717

Training -> Precision:	0.859727644986	 Recall:  0.9390472228	 F-Score:  0.897638578175	 AUC:  0.966061718948
Testing	 -> Precision:	0.761467889908	 Recall:  0.75283446712		 F-Score:  0.757126567845	 AUC:  0.849911279

25473/25473 [==============================] - 27s - loss: 0.3771
Epoch 39/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.37090

Training -> Precision:	0.869253560164	 Recall:  0.946016226337	 F-Score:  0.906011854361	 AUC:  0.969864988475
Testing	 -> Precision:	0.75283446712	 Recall:  0.75283446712		 F-Score:  0.75283446712	 AUC:  0.84831595265

25473/25473 [==============================] - 27s - loss: 0.3709
Epoch 40/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.36593

Training -> Precision:	0.884073566817	 Recall:  0.939983357603	 F-Score:  0.911171607179	 AUC:  0.97108534593
Testing	 -> Precision:	0.776470588235	 Recall:  0.748299319728	 F-Score:  0.762124711316	 AUC:  0.842111004556

25473/25473 [==============================] - 27s - loss: 0.3659
25473/25473 [==============================] - 12s: 0ss
1440/1458 [============================>.] - ETA: 0s

Average Precision Score 0.842111004556
Training
	     precision	  recall  f1-score   support

	  0	 0.962	   0.925     0.943     15859
	  1	 0.884	   0.940     0.911	9614

avg / total	 0.933	   0.931     0.931     25473

Testing
	     precision	  recall  f1-score   support

	  0	 0.893	   0.907     0.900	1017
	  1	 0.776	   0.748     0.762	 441

avg / total	 0.857	   0.859     0.858	1458

Testing Accuracy
0.858710562414
