lstm_units 70
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Language Features False
Concept Features False
32  CHARACTERS
['"', '3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z', '~']
52  LANGUAGES
['SWEDISH', 'DANISH', 'GUTNISH_LAU', 'OSSETIC_IRON', 'FRENCH', 'BIHARI', 'DUTCH', 'MARATHI', 'SORBIAN_UPPER', 'ORIYA', 'SLOVENIAN', 'MIDDLE_CORNISH', 'ANCIENT_GREEK', 'ARMENIAN_EASTERN', 'OLD_SWEDISH', 'ICELANDIC', 'SLOVAK', 'ENGLISH', 'ASSAMESE', 'BRETON', 'ITALIAN', 'ELFDALIAN', 'UKRAINIAN', 'CZECH', 'STAVANGERSK', 'NORWEGIAN_RIKSMAL', 'OLD_NORSE', 'SPANISH', 'MAGAHI', 'OLD_CHURCH_SLAVONIC', 'PORTUGUESE', 'OLD_IRISH', 'IRISH', 'MIDDLE_BRETON', 'GERMAN', 'DANISH_FJOLDE', 'OSSETIC', 'MACEDONIAN', 'LATIN', 'BELARUSIAN', 'FAROESE', 'POLISH', 'FRISIAN', 'BULGARIAN', 'GREEK', 'CLASSICAL_ARMENIAN', 'SORBIAN_LOWER', 'URDU', 'CATALAN', 'SERBO-CROATIAN', 'RUSSIAN', 'OSSETIC_DIGOR']
Vocab Size :  35
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       350
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 140)       45360
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 140)       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 140), (No 78540
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 140)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 140)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 280)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 280)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       5620
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 129,891.0
Trainable params: 129,891.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.773603

Training -> Precision:	0.525068722362	 Recall:  0.686767234641	 F-Score:  0.595130046058	 AUC:  0.607252945957
Testing	 -> Precision:	0.588763575606	 Recall:  0.713851608002	 F-Score:  0.645301590935	 AUC:  0.657647277861

204233/204233 [==============================] - 283s - loss: 0.7735
Epoch 2/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.621925

Training -> Precision:	0.590793755037	 Recall:  0.77344849148		 F-Score:  0.669893546804	 AUC:  0.701650851303
Testing	 -> Precision:	0.648301574151	 Recall:  0.792605722968	 F-Score:  0.713227754358	 AUC:  0.738549979224

204233/204233 [==============================] - 273s - loss: 0.6219
Epoch 3/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.584107

Training -> Precision:	0.625241250643	 Recall:  0.759633421917	 F-Score:  0.685916437293	 AUC:  0.715200409691
Testing	 -> Precision:	0.690502064769	 Recall:  0.804507470246	 F-Score:  0.743157894737	 AUC:  0.763689929789

204233/204233 [==============================] - 273s - loss: 0.5841
Epoch 4/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.575712

Training -> Precision:	0.60798068253	 Recall:  0.777356573394	 F-Score:  0.682314401118	 AUC:  0.728318257656
Testing	 -> Precision:	0.668561802485	 Recall:  0.804001012915	 F-Score:  0.730052885721	 AUC:  0.771490600893

204233/204233 [==============================] - 273s - loss: 0.5758
Epoch 5/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.552739

Training -> Precision:	0.632398513745	 Recall:  0.801508519619	 F-Score:  0.706981393866	 AUC:  0.773523631143
Testing	 -> Precision:	0.688071443759	 Recall:  0.819447961509	 F-Score:  0.748035136385	 AUC:  0.796861353079

204233/204233 [==============================] - 273s - loss: 0.5526
Epoch 6/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.522899

Training -> Precision:	0.652990373994	 Recall:  0.808582147882	 F-Score:  0.72250449601	 AUC:  0.771682895692
Testing	 -> Precision:	0.688350340136	 Recall:  0.81995441884		 F-Score:  0.748410955738	 AUC:  0.793572953123

204233/204233 [==============================] - 273s - loss: 0.5227
Epoch 7/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.513789

Training -> Precision:	0.68883264685	 Recall:  0.813701735188	 F-Score:  0.746078527981	 AUC:  0.798607663234
Testing	 -> Precision:	0.706509906379	 Recall:  0.821727019499	 F-Score:  0.759775228284	 AUC:  0.815340143078

204233/204233 [==============================] - 273s - loss: 0.5137
Epoch 8/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.482145

Training -> Precision:	0.705223335336	 Recall:  0.848718149132	 F-Score:  0.770345408593	 AUC:  0.830016896314
Testing	 -> Precision:	0.717904308292	 Recall:  0.839706254748	 F-Score:  0.774042950514	 AUC:  0.828887592165

204233/204233 [==============================] - 275s - loss: 0.4821
Epoch 9/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.455794

Training -> Precision:	0.745290444456	 Recall:  0.83259731124		 F-Score:  0.786528468716	 AUC:  0.838926429711
Testing	 -> Precision:	0.751985053713	 Recall:  0.815396302861	 F-Score:  0.78240796987	 AUC:  0.836374005906

204233/204233 [==============================] - 274s - loss: 0.4556
Epoch 10/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.433156

Training -> Precision:	0.728802055558	 Recall:  0.881252931061	 F-Score:  0.797809954271	 AUC:  0.865406161871
Testing	 -> Precision:	0.731799070591	 Recall:  0.837427196759	 F-Score:  0.781058101086	 AUC:  0.845688249204

204233/204233 [==============================] - 274s - loss: 0.4330
Epoch 11/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.410429

Training -> Precision:	0.749293026179	 Recall:  0.885356417071	 F-Score:  0.811661964262	 AUC:  0.879681549825
Testing	 -> Precision:	0.756917447976	 Recall:  0.838186882755	 F-Score:  0.795481855323	 AUC:  0.854315192945

204233/204233 [==============================] - 274s - loss: 0.4104
Epoch 12/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.393201

Training -> Precision:	0.783663271857	 Recall:  0.882601219322	 F-Score:  0.830194921563	 AUC:  0.887062648212
Testing	 -> Precision:	0.765912305516	 Recall:  0.822739934161	 F-Score:  0.793309730192	 AUC:  0.849973968449

204233/204233 [==============================] - 274s - loss: 0.3932
Epoch 13/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.374265

Training -> Precision:	0.771704552986	 Recall:  0.910133656401	 F-Score:  0.835222178388	 AUC:  0.900792697243
Testing	 -> Precision:	0.752829334541	 Recall:  0.842238541403	 F-Score:  0.79502808653	 AUC:  0.861198082992

204233/204233 [==============================] - 273s - loss: 0.3743
Epoch 14/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.358276

Training -> Precision:	0.802182716727	 Recall:  0.913475066437	 F-Score:  0.854219201111	 AUC:  0.912351279646
Testing	 -> Precision:	0.774567842766	 Recall:  0.828310964801	 F-Score:  0.800538423886	 AUC:  0.860835667742

204233/204233 [==============================] - 273s - loss: 0.3582
Epoch 15/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.343839

Training -> Precision:	0.815836021226	 Recall:  0.919298108488	 F-Score:  0.864482460815	 AUC:  0.91962066496
Testing	 -> Precision:	0.782296650718	 Recall:  0.828057736136	 F-Score:  0.804527002091	 AUC:  0.864986118548

204233/204233 [==============================] - 273s - loss: 0.3438
Epoch 16/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.328657

Training -> Precision:	0.803199919075	 Recall:  0.930924652181	 F-Score:  0.862358584487	 AUC:  0.915861315769
Testing	 -> Precision:	0.763200744359	 Recall:  0.830843251456	 F-Score:  0.795586808923	 AUC:  0.854532552939

204233/204233 [==============================] - 273s - loss: 0.3286
Epoch 17/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.317731

Training -> Precision:	0.861536488863	 Recall:  0.919044083164	 F-Score:  0.889361621663	 AUC:  0.937947886505
Testing	 -> Precision:	0.805764411028	 Recall:  0.814130159534	 F-Score:  0.809925683335	 AUC:  0.866654787386

204233/204233 [==============================] - 318s - loss: 0.3177
Epoch 18/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.311015

Training -> Precision:	0.835895919574	 Recall:  0.93909254338		 F-Score:  0.884494340664	 AUC:  0.939654461328
Testing	 -> Precision:	0.788414929714	 Recall:  0.823752848822	 F-Score:  0.805696594427	 AUC:  0.862198038009

204233/204233 [==============================] - 273s - loss: 0.3110
Epoch 19/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.295895

Training -> Precision:	0.861832240348	 Recall:  0.932175238393	 F-Score:  0.895624665584	 AUC:  0.946211513551
Testing	 -> Precision:	0.80467571644	 Recall:  0.810584958217	 F-Score:  0.807619528195	 AUC:  0.871417315438

204233/204233 [==============================] - 271s - loss: 0.2959
Epoch 20/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.288252

Training -> Precision:	0.844106530107	 Recall:  0.946947788026	 F-Score:  0.892574617588	 AUC:  0.943783912449
Testing	 -> Precision:	0.789435600579	 Recall:  0.828817422132	 F-Score:  0.808647313156	 AUC:  0.869911861651

204233/204233 [==============================] - 268s - loss: 0.2882
13184/132063[============================>.].- ETA:A0s0sss

Average Precision Score 0.869911861651
Training
	     precision	  recall  f1-score   support

	  0	 0.982	   0.942     0.961    153057
	  1	 0.844	   0.947     0.893     51176

avg / total	 0.947	   0.943     0.944    204233

Testing
	     precision	  recall  f1-score   support

	  0	 0.925	   0.906     0.915	9257
	  1	 0.789	   0.829     0.809	3949

avg / total	 0.885	   0.883     0.884     13206

Testing Accuracy
0.882704831137
