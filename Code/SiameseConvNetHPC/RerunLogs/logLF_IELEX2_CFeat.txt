lstm_units 75
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Language Features False
Concept Features True
32  CHARACTERS
['"', '3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z', '~']
52  LANGUAGES
['SWEDISH', 'DANISH', 'GUTNISH_LAU', 'OSSETIC_IRON', 'FRENCH', 'BIHARI', 'DUTCH', 'MARATHI', 'SORBIAN_UPPER', 'ORIYA', 'SLOVENIAN', 'MIDDLE_CORNISH', 'ANCIENT_GREEK', 'ARMENIAN_EASTERN', 'OLD_SWEDISH', 'ICELANDIC', 'SLOVAK', 'ENGLISH', 'ASSAMESE', 'BRETON', 'ITALIAN', 'ELFDALIAN', 'UKRAINIAN', 'CZECH', 'STAVANGERSK', 'NORWEGIAN_RIKSMAL', 'OLD_NORSE', 'SPANISH', 'MAGAHI', 'OLD_CHURCH_SLAVONIC', 'PORTUGUESE', 'OLD_IRISH', 'IRISH', 'MIDDLE_BRETON', 'GERMAN', 'DANISH_FJOLDE', 'OSSETIC', 'MACEDONIAN', 'LATIN', 'BELARUSIAN', 'FAROESE', 'POLISH', 'FRISIAN', 'BULGARIAN', 'GREEK', 'CLASSICAL_ARMENIAN', 'SORBIAN_LOWER', 'URDU', 'CATALAN', 'SERBO-CROATIAN', 'RUSSIAN', 'OSSETIC_DIGOR']
Vocab Size :  35
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       350
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 150)       51600
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 150)       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 150), (No 90150
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 150)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 150)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 300)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 300)	       0
____________________________________________________________________________________________________
Input Concept Feat (InputLayer)	 (None, 300)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 600)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       12020
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 154,141.0
Trainable params: 154,141.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.718733

Training -> Precision:	0.622060737885	 Recall:  0.737670001563	 F-Score:  0.674950609227	 AUC:  0.723933158696
Testing	 -> Precision:	0.693513898788	 Recall:  0.739174474551	 F-Score:  0.715616572689	 AUC:  0.733944780145

204233/204233 [==============================] - 274s - loss: 0.7187
Epoch 2/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.597643

Training -> Precision:	0.651305939112	 Recall:  0.765007034547	 F-Score:  0.703592545334	 AUC:  0.764309464129
Testing	 -> Precision:	0.71875		 Recall:  0.7571537098	 F-Score:  0.73745221359	 AUC:  0.778918027997

204233/204233 [==============================] - 269s - loss: 0.5975
Epoch 3/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.556427

Training -> Precision:	0.683483212388	 Recall:  0.769305924652	 F-Score:  0.723859603964	 AUC:  0.792476646376
Testing	 -> Precision:	0.746012566457	 Recall:  0.781716890352	 F-Score:  0.763447508347	 AUC:  0.810668962594

204233/204233 [==============================] - 268s - loss: 0.5564
Epoch 4/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.526640

Training -> Precision:	0.676387935823	 Recall:  0.808953415664	 F-Score:  0.736754996352	 AUC:  0.807179724373
Testing	 -> Precision:	0.726217569413	 Recall:  0.808052671562	 F-Score:  0.76495265492	 AUC:  0.815773962487

204233/204233 [==============================] - 268s - loss: 0.5266
Epoch 5/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.502578

Training -> Precision:	0.748514889309	 Recall:  0.765730029701	 F-Score:  0.757024601802	 AUC:  0.828160065683
Testing	 -> Precision:	0.774110366168	 Recall:  0.760192453786	 F-Score:  0.767088284145	 AUC:  0.824805878323

204233/204233 [==============================] - 268s - loss: 0.5024
Epoch 6/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.476601

Training -> Precision:	0.751828650058	 Recall:  0.811415507269	 F-Score:  0.780486429592	 AUC:  0.852869551497
Testing	 -> Precision:	0.780255575044	 Recall:  0.78855406432		 F-Score:  0.784382871537	 AUC:  0.846411792265

204233/204233 [==============================] - 268s - loss: 0.4765
Epoch 7/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.452093

Training -> Precision:	0.774630289242	 Recall:  0.811669532593	 F-Score:  0.792717487762	 AUC:  0.865216883785
Testing	 -> Precision:	0.773272124458	 Recall:  0.76778931375		 F-Score:  0.770520965693	 AUC:  0.841264028754

204233/204233 [==============================] - 268s - loss: 0.4520
Epoch 8/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.428915

Training -> Precision:	0.716946316596	 Recall:  0.895888697827	 F-Score:  0.796490770901	 AUC:  0.88187167726
Testing	 -> Precision:	0.726454445664	 Recall:  0.83793365409		 F-Score:  0.77822201317	 AUC:  0.857143556513

204233/204233 [==============================] - 268s - loss: 0.4289
Epoch 9/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.406539

Training -> Precision:	0.774515007791	 Recall:  0.883890886353	 F-Score:  0.825596145247	 AUC:  0.898705114777
Testing	 -> Precision:	0.767548076923	 Recall:  0.808559128893	 F-Score:  0.787520039462	 AUC:  0.855639613757

204233/204233 [==============================] - 268s - loss: 0.4064
Epoch 10/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.387160

Training -> Precision:	0.801546391753	 Recall:  0.869020634673	 F-Score:  0.833920870054	 AUC:  0.9057102119
Testing	 -> Precision:	0.78217575305	 Recall:  0.795644466954	 F-Score:  0.788852623651	 AUC:  0.859908628562

204233/204233 [==============================] - 269s - loss: 0.3871
Epoch 11/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.370588

Training -> Precision:	0.768614878751	 Recall:  0.913533687666	 F-Score:  0.834831831859	 AUC:  0.909511130351
Testing	 -> Precision:	0.754682503426	 Recall:  0.836667510762	 F-Score:  0.793563107962	 AUC:  0.865291220906

204233/204233 [==============================] - 268s - loss: 0.3705
Epoch 12/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.355499

Training -> Precision:	0.810211467499	 Recall:  0.892410504924	 F-Score:  0.849326787175	 AUC:  0.918800764408
Testing	 -> Precision:	0.792491121258	 Recall:  0.791086350975	 F-Score:  0.79178811304	 AUC:  0.867695146914

204233/204233 [==============================] - 268s - loss: 0.3553
Epoch 13/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.343550

Training -> Precision:	0.810381429665	 Recall:  0.910016413944	 F-Score:  0.857313795516	 AUC:  0.92502265721
Testing	 -> Precision:	0.791893227879	 Recall:  0.811344644214	 F-Score:  0.801500938086	 AUC:  0.874216828075

204233/204233 [==============================] - 268s - loss: 0.3435
Epoch 14/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.329610

Training -> Precision:	0.824344983921	 Recall:  0.916660153197	 F-Score:  0.868055105798	 AUC:  0.929520813437
Testing	 -> Precision:	0.804735234216	 Recall:  0.800455811598	 F-Score:  0.802589818459	 AUC:  0.873002179086

204233/204233 [==============================] - 268s - loss: 0.3296
Epoch 15/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.316131

Training -> Precision:	0.809446911587	 Recall:  0.940284508363	 F-Score:  0.869973965866	 AUC:  0.938354260313
Testing	 -> Precision:	0.771247951299	 Recall:  0.834135224107	 F-Score:  0.801459854015	 AUC:  0.877868581162

204233/204233 [==============================] - 268s - loss: 0.3161
Epoch 16/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.308178

Training -> Precision:	0.81334299973	 Recall:  0.942648897921	 F-Score:  0.873235102455	 AUC:  0.943965549166
Testing	 -> Precision:	0.782649917042	 Recall:  0.836161053431	 F-Score:  0.808521057786	 AUC:  0.88114971416

204233/204233 [==============================] - 268s - loss: 0.3081
Epoch 17/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.295997

Training -> Precision:	0.77542199085	 Recall:  0.960489291856	 F-Score:  0.858090532968	 AUC:  0.944292775616
Testing	 -> Precision:	0.738913043478	 Recall:  0.860724233983	 F-Score:  0.795180722892	 AUC:  0.881113706038

204233/204233 [==============================] - 268s - loss: 0.2958
Epoch 18/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.286833

Training -> Precision:	0.870291522476	 Recall:  0.938604033141	 F-Score:  0.903157874945	 AUC:  0.956945145182
Testing	 -> Precision:	0.8098663926	 Recall:  0.798176753609	 F-Score:  0.8039790843		 AUC:  0.880939026676

204233/204233 [==============================] - 268s - loss: 0.2868
Epoch 19/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.276552

Training -> Precision:	0.873865895536	 Recall:  0.944798342973	 F-Score:  0.907948847952	 AUC:  0.959516124341
Testing	 -> Precision:	0.812129032258	 Recall:  0.796910610281	 F-Score:  0.804447852761	 AUC:  0.883059860415

204233/204233 [==============================] - 269s - loss: 0.2765
Epoch 20/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.269145

Training -> Precision:	0.866441538022	 Recall:  0.947573081132	 F-Score:  0.905193011275	 AUC:  0.960002492326
Testing	 -> Precision:	0.801317790167	 Recall:  0.800709040263	 F-Score:  0.801013299557	 AUC:  0.886330875179

204233/204233 [==============================] - 268s - loss: 0.2691
13184/132063[============================>.].- ETA:A0s0sss

Average Precision Score 0.886330875179
Training
	     precision	  recall  f1-score   support

	  0	 0.982	   0.951     0.966    153057
	  1	 0.866	   0.948     0.905     51176

avg / total	 0.953	   0.950     0.951    204233

Testing
	     precision	  recall  f1-score   support

	  0	 0.915	   0.915     0.915	9257
	  1	 0.801	   0.801     0.801	3949

avg / total	 0.881	   0.881     0.881     13206

Testing Accuracy
0.881038921702
