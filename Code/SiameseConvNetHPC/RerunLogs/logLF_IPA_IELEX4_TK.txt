lstm_units 110
epochs 50
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 15
Tokenize Simple True
Using Concept Fold Data False
Language Features False
Concept Features False
160  CHARACTERS
[u'\u0283', u'\u0302', u'\u0306', u'\u028b', u'\u030a', u'\u028f', u'\u1d58', u'\u01f0', u'\u031e', u'\u02a3', u'\u02a7', u'\u032a', u'\u02b7', u'\u0142', u'\u0250', u'\u0254', u'\u0258', u'\u01dd', u'\u025c', u'd', u'\xe3', u'\u0264', u'\xe7', u'\u0268', u'\u0266', u'l', u'p', u'\xf3', u't', u'h', u'x', u'\xfb', u'\u017e', u'\u0301', u'\u0280', u'\u026a', u'\u0288', u'\u010d', u'\u028c', u'\u0311', u'\u0290', u'\u0294', u'\u031d', u'\u0325', u'\u02a4', u'\u0270', u'\u0329', u'\u02a8', u'\u012d', u'\u02b0', u'\u03b2', u'?', u'\u02c0', u'\u02c8', u'\u0276', u'\u02cc', u'\u01ce', u'\u02d0', u'\u0278', u'\u025b', u'r', u'_', u'\u0361', u'\u02e0', u'\u0263', u'g', u'\u01d0', u'\u0169', u'\u026b', u'\u016d', u'\xec', u'o', u'\xf0', u'\u0273', u'\xf4', u'w', u'\xf8', u'\u027b', u'\u0281', u'\u0300', u'\u0304', u'\u0289', u'\u028d', u'\u030c', u'\u0291', u'\u1e59', u'\u0275', u'\u029d', u'\u031c', u'\u0320', u'\u02a5', u'\u0324', u'.', u'\u02b1', u'\u025f', u'\u02b9', u':', u'\u1ebd', u'a', u'\u03c7', u'c', u'\u02d1', u'\u0252', u'\u0256', u'\u0265', u'\u035c', u'\xe1', u'b', u'\u0267', u'f', u'\xe9', u'j', u'\xed', u'n', u'\u0272', u'\xf5', u'v', u'\xf9', u'z', u'k', u'\u027e', u'\u0303', u'\u0282', u'\u026d', u'\u028a', u'\u028e', u'\u0292', u'\u026f', u'\u011b', u'\u031f', u'\u02a6', u'-', u's', u'\u032f', u'\u02b2', u'\u03b8', u'\u033b', u'\u014b', u'\u0161', u'\u0251', u'\u0279', u'\u0153', u'\u0255', u'\u01d4', u'\u0259', u'\u0261', u'\xe2', u'e', u'\xe6', u'i', u'\u027d', u'\xea', u'm', u'\xee', u'q', u'\u0129', u'u', u'y', u'\xfa', u'\u1e7d']
52  LANGUAGES
['SWEDISH', 'DANISH', 'GUTNISH_LAU', 'OSSETIC_IRON', 'BIHARI', 'MARATHI', 'SORBIAN_UPPER', 'ORIYA', 'SLOVENIAN', 'MIDDLE_CORNISH', 'ANCIENT_GREEK', 'GREEK', 'OLD_SWEDISH', 'ICELANDIC', 'SLOVAK', 'DUTCH', 'ASSAMESE', 'FRENCH', 'ITALIAN', 'LATIN', 'FAROESE', 'UKRAINIAN', 'CZECH', 'STAVANGERSK', 'NORWEGIAN_RIKSMAL', 'BRETON', 'OLD_NORSE', 'SPANISH', 'MAGAHI', 'OLD_CHURCH_SLAVONIC', 'PORTUGUESE', 'OLD_IRISH', 'MIDDLE_BRETON', 'GERMAN', 'DANISH_FJOLDE', 'IRISH', 'OSSETIC', 'MACEDONIAN', 'ELFDALIAN', 'BELARUSIAN', 'ARMENIAN_EASTERN', 'POLISH', 'ENGLISH', 'FRISIAN', 'BULGARIAN', 'SERBO-CROATIAN', 'SORBIAN_LOWER', 'URDU', 'CATALAN', 'CLASSICAL_ARMENIAN', 'RUSSIAN', 'OSSETIC_DIGOR']
Vocab Size :  161
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 15)	       2415
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 15)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 220)       110880
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 220)       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 220), (No 193820
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 220)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 220)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 440)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 440)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       8820
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 315,956.0
Trainable params: 315,956.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/50
204160/204233 [============================>.] - ETA: 0ss--loss::0.7830728

Training -> Precision:	0.597423170345	 Recall:  0.442160387682	 F-Score:  0.508197457665	 AUC:  0.534846984745
Testing	 -> Precision:	0.629064632678	 Recall:  0.396809318815	 F-Score:  0.486645962733	 AUC:  0.545272391677

Saving To :  ./Models/RE_IPA_IELEX_DF1_CoAtt_Model_110_15_161_0.001_0.02_12_0.weights
204233/204233 [==============================] - 321s - loss: 0.7830
Epoch 2/50
204160/204233 [============================>.] - ETA: 0ss--loss::0.694474

Training -> Precision:	0.634165511821	 Recall:  0.599108957324	 F-Score:  0.616138982949	 AUC:  0.646185600091
Testing	 -> Precision:	0.6766687079	 Recall:  0.559635350722	 F-Score:  0.612612612613	 AUC:  0.664226946098

Saving To :  ./Models/RE_IPA_IELEX_DF1_CoAtt_Model_110_15_161_0.001_0.02_12_1.weights
204233/204233 [==============================] - 313s - loss: 0.6943
Epoch 3/50
204160/204233 [============================>.] - ETA: 0ss--loss::0.747934

Training -> Precision:	0.527491874323	 Recall:  0.304439581054	 F-Score:  0.386064030132	 AUC:  0.472842746633
Testing	 -> Precision:	0.544238239102	 Recall:  0.319321347177	 F-Score:  0.402489626556	 AUC:  0.494372197672

Saving To :  ./Models/RE_IPA_IELEX_DF1_CoAtt_Model_110_15_161_0.001_0.02_12_2.weights
204233/204233 [==============================] - 318s - loss: 0.7479
Epoch 4/50
204160/204233 [============================>.] - ETA: 0ss--loss::0.8024911

Training -> Precision:	0.50674414659	 Recall:  0.233449273097	 F-Score:  0.319643621575	 AUC:  0.428675406437
Testing	 -> Precision:	0.530552291422	 Recall:  0.228665484933	 F-Score:  0.319589453194	 AUC:  0.445361220218

Saving To :  ./Models/RE_IPA_IELEX_DF1_CoAtt_Model_110_15_161_0.001_0.02_12_3.weights
204233/204233 [==============================] - 315s - loss: 0.8024
Epoch 5/50
204160/204233 [============================>.] - ETA: 0ss--loss::0.798488

Training -> Precision:	0.453950966637	 Recall:  0.373026418634	 F-Score:  0.409529223739	 AUC:  0.435382073806
Testing	 -> Precision:	0.472564389698	 Recall:  0.320587490504	 F-Score:  0.382015691008	 AUC:  0.442718443952

Saving To :  ./Models/RE_IPA_IELEX_DF1_CoAtt_Model_110_15_161_0.001_0.02_12_4.weights
204233/204233 [==============================] - 313s - loss: 0.7984
Epoch 6/50
204160/204233 [============================>.] - ETA: 0ss--loss::0.798263

Training -> Precision:	0.499074365154	 Recall:  0.279193371893	 F-Score:  0.358072802456	 AUC:  0.434891536571
Testing	 -> Precision:	0.540194572453	 Recall:  0.267156242087	 F-Score:  0.357505930193	 AUC:  0.4581819567

Saving To :  ./Models/RE_IPA_IELEX_DF1_CoAtt_Model_110_15_161_0.001_0.02_12_5.weights
204233/204233 [==============================] - 313s - loss: 0.7982
Epoch 7/50
204160/204233 [============================>.] - ETA: 0ss--loss::0.798278

Training -> Precision:	0.504117436448	 Recall:  0.247616070033	 F-Score:  0.332105932148	 AUC:  0.422920749504
Testing	 -> Precision:	0.546198830409	 Recall:  0.236515573563	 F-Score:  0.330093656123	 AUC:  0.447530395363

Saving To :  ./Models/RE_IPA_IELEX_DF1_CoAtt_Model_110_15_161_0.001_0.02_12_6.weights
204233/204233 [==============================] - 313s - loss: 0.7981
Epoch 8/50
204160/204233 [============================>.] - ETA: 0ss--loss::0.811176

Training -> Precision:	0.591879075282	 Recall:  0.0390221979053	 F-Score:  0.0732172318973	 AUC:  0.341503012664
Testing	 -> Precision:	0.643776824034	 Recall:  0.0379842998227	 F-Score:  0.0717360114778	 AUC:  0.390065811411

Saving To :  ./Models/RE_IPA_IELEX_DF1_CoAtt_Model_110_15_161_0.001_0.02_12_7.weights
204233/204233 [==============================] - 319s - loss: 0.8110
Epoch 9/50
156544/204233 [=====================>........] - ETA: 40ss--loss::0.81512
