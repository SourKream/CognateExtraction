lstm_units 100
epochs 40
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 20
Tokenize Simple False
Using Concept Fold Data False
Language Features False
Concept Features True
160  CHARACTERS
[u'\u0283', u'\u0302', u'\u0306', u'\u028b', u'\u030a', u'\u028f', u'\u1d58', u'\u01f0', u'\u031e', u'\u02a3', u'\u02a7', u'\u032a', u'\u02b7', u'\u0142', u'\u0250', u'\u0254', u'\u0258', u'\u01dd', u'\u025c', u'd', u'\xe3', u'\u0264', u'\xe7', u'\u0268', u'\u0266', u'l', u'p', u'\xf3', u't', u'h', u'x', u'\xfb', u'\u017e', u'\u0301', u'\u0280', u'\u026a', u'\u0288', u'\u010d', u'\u028c', u'\u0311', u'\u0290', u'\u0294', u'\u031d', u'\u0325', u'\u02a4', u'\u0270', u'\u0329', u'\u02a8', u'\u012d', u'\u02b0', u'\u03b2', u'?', u'\u02c0', u'\u02c8', u'\u0276', u'\u02cc', u'\u01ce', u'\u02d0', u'\u0278', u'\u025b', u'r', u'_', u'\u0361', u'\u02e0', u'\u0263', u'g', u'\u01d0', u'\u0169', u'\u026b', u'\u016d', u'\xec', u'o', u'\xf0', u'\u0273', u'\xf4', u'w', u'\xf8', u'\u027b', u'\u0281', u'\u0300', u'\u0304', u'\u0289', u'\u028d', u'\u030c', u'\u0291', u'\u1e59', u'\u0275', u'\u029d', u'\u031c', u'\u0320', u'\u02a5', u'\u0324', u'.', u'\u02b1', u'\u025f', u'\u02b9', u':', u'\u1ebd', u'a', u'\u03c7', u'c', u'\u02d1', u'\u0252', u'\u0256', u'\u0265', u'\u035c', u'\xe1', u'b', u'\u0267', u'f', u'\xe9', u'j', u'\xed', u'n', u'\u0272', u'\xf5', u'v', u'\xf9', u'z', u'k', u'\u027e', u'\u0303', u'\u0282', u'\u026d', u'\u028a', u'\u028e', u'\u0292', u'\u026f', u'\u011b', u'\u031f', u'\u02a6', u'-', u's', u'\u032f', u'\u02b2', u'\u03b8', u'\u033b', u'\u014b', u'\u0161', u'\u0251', u'\u0279', u'\u0153', u'\u0255', u'\u01d4', u'\u0259', u'\u0261', u'\xe2', u'e', u'\xe6', u'i', u'\u027d', u'\xea', u'm', u'\xee', u'q', u'\u0129', u'u', u'y', u'\xfa', u'\u1e7d']
52  LANGUAGES
['SWEDISH', 'DANISH', 'GUTNISH_LAU', 'OSSETIC_IRON', 'BIHARI', 'MARATHI', 'SORBIAN_UPPER', 'ORIYA', 'SLOVENIAN', 'MIDDLE_CORNISH', 'ANCIENT_GREEK', 'GREEK', 'OLD_SWEDISH', 'ICELANDIC', 'SLOVAK', 'DUTCH', 'ASSAMESE', 'FRENCH', 'ITALIAN', 'LATIN', 'FAROESE', 'UKRAINIAN', 'CZECH', 'STAVANGERSK', 'NORWEGIAN_RIKSMAL', 'BRETON', 'OLD_NORSE', 'SPANISH', 'MAGAHI', 'OLD_CHURCH_SLAVONIC', 'PORTUGUESE', 'OLD_IRISH', 'MIDDLE_BRETON', 'GERMAN', 'DANISH_FJOLDE', 'IRISH', 'OSSETIC', 'MACEDONIAN', 'ELFDALIAN', 'BELARUSIAN', 'ARMENIAN_EASTERN', 'POLISH', 'ENGLISH', 'FRISIAN', 'BULGARIAN', 'SERBO-CROATIAN', 'SORBIAN_LOWER', 'URDU', 'CATALAN', 'CLASSICAL_ARMENIAN', 'RUSSIAN', 'OSSETIC_DIGOR']
Vocab Size :  521
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 20)	       10420
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 20)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 200)       96800
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 200)       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 200), (No 160200
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 200)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 200)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 400)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 400)	       0
____________________________________________________________________________________________________
Input Concept Feat (InputLayer)	 (None, 300)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 700)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       14020
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 281,461.0
Trainable params: 281,461.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.703335

Training -> Precision:	0.592395813389	 Recall:  0.725515866813	 F-Score:  0.652232723184	 AUC:  0.718501414714
Testing	 -> Precision:	0.64794714488	 Recall:  0.695365915422	 F-Score:  0.670819592036	 AUC:  0.720857498892

204233/204233 [==============================] - 310s - loss: 0.7033
Epoch 2/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.580107

Training -> Precision:	0.656752655539	 Recall:  0.803423479756	 F-Score:  0.722721719795	 AUC:  0.791050589841
Testing	 -> Precision:	0.712511715089	 Recall:  0.77006837174		 F-Score:  0.740172812462	 AUC:  0.778300406204

204233/204233 [==============================] - 303s - loss: 0.5802
Epoch 3/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.551000

Training -> Precision:	0.673509379099	 Recall:  0.832792715335	 F-Score:  0.744729369621	 AUC:  0.823590730904
Testing	 -> Precision:	0.715976331361	 Recall:  0.796657381616	 F-Score:  0.754165168405	 AUC:  0.81579188141

204233/204233 [==============================] - 303s - loss: 0.5510
Epoch 4/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.493339

Training -> Precision:	0.769814076279	 Recall:  0.803403939347	 F-Score:  0.78625041832	 AUC:  0.859066116789
Testing	 -> Precision:	0.781109047493	 Recall:  0.745505191188	 F-Score:  0.762891940917	 AUC:  0.833267905038

204233/204233 [==============================] - 303s - loss: 0.4933
Epoch 5/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.442991

Training -> Precision:	0.780151118861	 Recall:  0.839299671721	 F-Score:  0.808645229309	 AUC:  0.875282979907
Testing	 -> Precision:	0.769017632242	 Recall:  0.773107115726	 F-Score:  0.771056951635	 AUC:  0.838742038852

204233/204233 [==============================] - 302s - loss: 0.4429
Epoch 6/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.399397

Training -> Precision:	0.812611289582	 Recall:  0.864995310302	 F-Score:  0.837985442637	 AUC:  0.906880379049
Testing	 -> Precision:	0.797866805411	 Recall:  0.776652317042	 F-Score:  0.787116643141	 AUC:  0.863455485194

204233/204233 [==============================] - 301s - loss: 0.3993
Epoch 7/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.364180

Training -> Precision:	0.78637295082	 Recall:  0.929830389245	 F-Score:  0.852105866342	 AUC:  0.927999104801
Testing	 -> Precision:	0.752560521415	 Recall:  0.818688275513	 F-Score:  0.784232868405	 AUC:  0.858269520988

204233/204233 [==============================] - 301s - loss: 0.3641
Epoch 8/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.332089

Training -> Precision:	0.794968782003	 Recall:  0.940460372049	 F-Score:  0.861615854204	 AUC:  0.938534527722
Testing	 -> Precision:	0.744938329067	 Recall:  0.810584958217	 F-Score:  0.776376424933	 AUC:  0.85108533252

204233/204233 [==============================] - 302s - loss: 0.3320
Epoch 9/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.306394

Training -> Precision:	0.86158560911	 Recall:  0.928423479756	 F-Score:  0.893756701341	 AUC:  0.951111231375
Testing	 -> Precision:	0.797417271994	 Recall:  0.750569764497	 F-Score:  0.773284633446	 AUC:  0.855156014803

204233/204233 [==============================] - 301s - loss: 0.3064
Epoch 10/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.282740

Training -> Precision:	0.82880974002	 Recall:  0.963068625918	 F-Score:  0.890909419569	 AUC:  0.959272393127
Testing	 -> Precision:	0.755015341043	 Recall:  0.810078500886	 F-Score:  0.781578304422	 AUC:  0.859334488352

204233/204233 [==============================] - 301s - loss: 0.2827
Epoch 11/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.262644

Training -> Precision:	0.842998682387	 Recall:  0.962638736908	 F-Score:  0.898855083702	 AUC:  0.964080938271
Testing	 -> Precision:	0.767625899281	 Recall:  0.810584958217	 F-Score:  0.788520753787	 AUC:  0.857388768863

204233/204233 [==============================] - 301s - loss: 0.2626
Epoch 12/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.246888

Training -> Precision:	0.861476063369	 Recall:  0.971197436298	 F-Score:  0.913052264168	 AUC:  0.970370916953
Testing	 -> Precision:	0.772971652004	 Recall:  0.800962268929	 F-Score:  0.786718069892	 AUC:  0.862961218371

204233/204233 [==============================] - 302s - loss: 0.2468
Epoch 13/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.230699

Training -> Precision:	0.911563356899	 Recall:  0.954900734719	 F-Score:  0.932728921124	 AUC:  0.974606574959
Testing	 -> Precision:	0.830898876404	 Recall:  0.749050392504	 F-Score:  0.787854574511	 AUC:  0.867774858065

204233/204233 [==============================] - 301s - loss: 0.2307
Epoch 14/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.216970

Training -> Precision:	0.905080311069	 Recall:  0.973346881351	 F-Score:  0.937973110383	 AUC:  0.979807060516
Testing	 -> Precision:	0.815623356128	 Recall:  0.785262091669	 F-Score:  0.800154818733	 AUC:  0.86978689598

204233/204233 [==============================] - 301s - loss: 0.2169
Epoch 15/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.205481

Training -> Precision:	0.917715877437	 Recall:  0.965667500391	 F-Score:  0.94108125607	 AUC:  0.980916320124
Testing	 -> Precision:	0.821840622485	 Recall:  0.77563940238		 F-Score:  0.798071912454	 AUC:  0.87171096427

204233/204233 [==============================] - 301s - loss: 0.2054
Epoch 16/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.196983

Training -> Precision:	0.916836149835	 Recall:  0.968969829608	 F-Score:  0.942182364006	 AUC:  0.983022282225
Testing	 -> Precision:	0.820015927794	 Recall:  0.782223347683	 F-Score:  0.800673924313	 AUC:  0.875226162675

204233/204233 [==============================] - 301s - loss: 0.1969
Epoch 17/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.185669

Training -> Precision:	0.919928955945	 Recall:  0.981729717055	 F-Score:  0.949825125248	 AUC:  0.986809257697
Testing	 -> Precision:	0.8129590766	 Recall:  0.784755634338	 F-Score:  0.798608426749	 AUC:  0.875485563017

204233/204233 [==============================] - 303s - loss: 0.1856
Epoch 18/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.178836

Training -> Precision:	0.935933616162	 Recall:  0.978564170705	 F-Score:  0.956774261341	 AUC:  0.988022601782
Testing	 -> Precision:	0.826063397453	 Recall:  0.772094201064	 F-Score:  0.798167539267	 AUC:  0.879783242033

204233/204233 [==============================] - 301s - loss: 0.1787
Epoch 19/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.170645

Training -> Precision:	0.923124816877	 Recall:  0.985032046272	 F-Score:  0.953074188913	 AUC:  0.989305005704
Testing	 -> Precision:	0.815445026178	 Recall:  0.788807292986	 F-Score:  0.801905007079	 AUC:  0.882784926005

204233/204233 [==============================] - 301s - loss: 0.1706
Epoch 20/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.165202

Training -> Precision:	0.933420630383	 Recall:  0.988959668595	 F-Score:  0.960387866827	 AUC:  0.991673732862
Testing	 -> Precision:	0.810201967892	 Recall:  0.792352494302	 F-Score:  0.801177826143	 AUC:  0.875712718166

204233/204233 [==============================] - 301s - loss: 0.1652
Epoch 21/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.157430

Training -> Precision:	0.958974358974	 Recall:  0.979287165859	 F-Score:  0.96902432422	 AUC:  0.992786718154
Testing	 -> Precision:	0.844259948468	 Recall:  0.746771334515	 F-Score:  0.792528890083	 AUC:  0.88118601747

204233/204233 [==============================] - 301s - loss: 0.1574
Epoch 22/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.151320

Training -> Precision:	0.951853180522	 Recall:  0.9850906675	 F-Score:  0.968186750401	 AUC:  0.993576569911
Testing	 -> Precision:	0.842295904152	 Recall:  0.765510255761	 F-Score:  0.80206951446	 AUC:  0.881250354861

204233/204233 [==============================] - 301s - loss: 0.1514
Epoch 23/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.147867

Training -> Precision:	0.940288263555	 Recall:  0.99050336095		 F-Score:  0.964742827235	 AUC:  0.993859759902
Testing	 -> Precision:	0.809009009009	 Recall:  0.795897695619	 F-Score:  0.802399795762	 AUC:  0.880987005453

204233/204233 [==============================] - 301s - loss: 0.1478
Epoch 24/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.144466

Training -> Precision:	0.942139555605	 Recall:  0.991753947163	 F-Score:  0.966310318239	 AUC:  0.994169361013
Testing	 -> Precision:	0.813917122752	 Recall:  0.790833122309	 F-Score:  0.802209093244	 AUC:  0.883156076

204233/204233 [==============================] - 301s - loss: 0.1444
Epoch 25/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.138581

Training -> Precision:	0.956638125795	 Recall:  0.984621697671	 F-Score:  0.970428217893	 AUC:  0.992713358975
Testing	 -> Precision:	0.830962800875	 Recall:  0.769308685743	 F-Score:  0.798948060487	 AUC:  0.882065639568

204233/204233 [==============================] - 301s - loss: 0.1385
Epoch 26/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.136382

Training -> Precision:	0.972919610538	 Recall:  0.982140065656	 F-Score:  0.977508095335	 AUC:  0.994866240574
Testing	 -> Precision:	0.869200838072	 Recall:  0.735376044568	 F-Score:  0.79670781893	 AUC:  0.878809174779

204233/204233 [==============================] - 301s - loss: 0.1363
Epoch 27/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.132055

Training -> Precision:	0.967400661935	 Recall:  0.988099890574	 F-Score:  0.977640724236	 AUC:  0.995261712386
Testing	 -> Precision:	0.845355037889	 Recall:  0.762724740441	 F-Score:  0.801916932907	 AUC:  0.882405159974

204233/204233 [==============================] - 301s - loss: 0.1319
Epoch 28/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.128460

Training -> Precision:	0.965146225605	 Recall:  0.988588400813	 F-Score:  0.976726675998	 AUC:  0.995422285916
Testing	 -> Precision:	0.852269442035	 Recall:  0.74651810585		 F-Score:  0.795896328294	 AUC:  0.882467682885

204233/204233 [==============================] - 301s - loss: 0.1284
Epoch 29/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.126576

Training -> Precision:	0.964773831989	 Recall:  0.988998749414	 F-Score:  0.976736107761	 AUC:  0.995444603154
Testing	 -> Precision:	0.84070058382	 Recall:  0.765763484426	 F-Score:  0.801484230056	 AUC:  0.882346813743

204233/204233 [==============================] - 303s - loss: 0.1264
Epoch 30/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.124142

Training -> Precision:	0.963669927302	 Recall:  0.989467719243	 F-Score:  0.976398449702	 AUC:  0.996273220861
Testing	 -> Precision:	0.840366463076	 Recall:  0.766523170423	 F-Score:  0.801748112833	 AUC:  0.88290205657

204233/204233 [==============================] - 301s - loss: 0.1240
Epoch 31/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.122099

Training -> Precision:	0.971485118075	 Recall:  0.987943567297	 F-Score:  0.979645220357	 AUC:  0.996143078309
Testing	 -> Precision:	0.850245735762	 Recall:  0.744745505191	 F-Score:  0.794006479482	 AUC:  0.881957109994

204233/204233 [==============================] - 301s - loss: 0.1220
Epoch 32/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.120076

Training -> Precision:	0.963111801949	 Recall:  0.992809129279	 F-Score:  0.977735013952	 AUC:  0.996692630294
Testing	 -> Precision:	0.83560523446	 Recall:  0.776145859711	 F-Score:  0.804778784298	 AUC:  0.882909637936

204233/204233 [==============================] - 301s - loss: 0.1200
Epoch 33/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.116971

Training -> Precision:	0.974763770454	 Recall:  0.991753947163	 F-Score:  0.983185463562	 AUC:  0.997130220313
Testing	 -> Precision:	0.862433862434	 Recall:  0.742972904533	 F-Score:  0.798258740307	 AUC:  0.887034399235

204233/204233 [==============================] - 301s - loss: 0.1169
Epoch 34/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.114066

Training -> Precision:	0.964725293482	 Recall:  0.994001094263	 F-Score:  0.97914441076	 AUC:  0.997225368103
Testing	 -> Precision:	0.844596443228	 Recall:  0.781716890352	 F-Score:  0.81194108364	 AUC:  0.884629502767

204233/204233 [==============================] - 301s - loss: 0.1140
Epoch 35/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.113960

Training -> Precision:	0.981219568746	 Recall:  0.99234015945		 F-Score:  0.986748533012	 AUC:  0.997416905637
Testing	 -> Precision:	0.864256075874	 Recall:  0.738414788554	 F-Score:  0.796394920115	 AUC:  0.887127117205

204233/204233 [==============================] - 302s - loss: 0.1139
Epoch 36/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.109645

Training -> Precision:	0.9772250755	 Recall:  0.992711427232	 F-Score:  0.984907379584	 AUC:  0.997267176022
Testing	 -> Precision:	0.854566275408	 Recall:  0.755887566473	 F-Score:  0.80220370868	 AUC:  0.880195952488

204233/204233 [==============================] - 302s - loss: 0.1096
Epoch 37/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.109652

Training -> Precision:	0.971753358595	 Recall:  0.992222916992	 F-Score:  0.981881465726	 AUC:  0.997231395417
Testing	 -> Precision:	0.8460049765	 Recall:  0.774879716384	 F-Score:  0.80888183981	 AUC:  0.890477817553

204233/204233 [==============================] - 302s - loss: 0.1096
Epoch 38/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.105974

Training -> Precision:	0.979338524401	 Recall:  0.992887290918	 F-Score:  0.986066369105	 AUC:  0.997697481617
Testing	 -> Precision:	0.855411255411	 Recall:  0.750569764497	 F-Score:  0.799568384138	 AUC:  0.883383516451

204233/204233 [==============================] - 301s - loss: 0.1059
Epoch 39/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.105608

Training -> Precision:	0.982896215085	 Recall:  0.991539002657	 F-Score:  0.987198692632	 AUC:  0.997993823323
Testing	 -> Precision:	0.861736334405	 Recall:  0.74651810585		 F-Score:  0.8	 AUC:  0.881951832499

204233/204233 [==============================] - 301s - loss: 0.1056
Epoch 40/40
204160/204233 [============================>.] - ETA: 0ss--loss::0.103346

Training -> Precision:	0.978743086203	 Recall:  0.992379240269	 F-Score:  0.985513996022	 AUC:  0.997497422556
Testing	 -> Precision:	0.857673621035	 Recall:  0.75993922512		 F-Score:  0.805853920516	 AUC:  0.88038939232

204233/204233 [==============================] - 301s - loss: 0.1033
13184/132063[============================>.].- ETA:A0s0sss

Average Precision Score 0.88038939232
Training
	     precision	  recall  f1-score   support

	  0	 0.997	   0.993     0.995    153057
	  1	 0.979	   0.992     0.986     51176

avg / total	 0.993	   0.993     0.993    204233

Testing
	     precision	  recall  f1-score   support

	  0	 0.902	   0.946     0.924	9257
	  1	 0.858	   0.760     0.806	3949

avg / total	 0.889	   0.891     0.888     13206

Testing Accuracy
0.89050431622
