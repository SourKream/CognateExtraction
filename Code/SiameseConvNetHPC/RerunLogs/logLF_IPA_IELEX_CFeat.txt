lstm_units 75
epochs 30
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 50
Tokenize Simple False
Using Concept Fold Data False
Language Features False
Concept Features True
160  CHARACTERS
[u'\u0283', u'\u0302', u'\u0306', u'\u028b', u'\u030a', u'\u028f', u'\u1d58', u'\u01f0', u'\u031e', u'\u02a3', u'\u02a7', u'\u032a', u'\u02b7', u'\u0142', u'\u0250', u'\u0254', u'\u0258', u'\u01dd', u'\u025c', u'd', u'\xe3', u'\u0264', u'\xe7', u'\u0268', u'\u0266', u'l', u'p', u'\xf3', u't', u'h', u'x', u'\xfb', u'\u017e', u'\u0301', u'\u0280', u'\u026a', u'\u0288', u'\u010d', u'\u028c', u'\u0311', u'\u0290', u'\u0294', u'\u031d', u'\u0325', u'\u02a4', u'\u0270', u'\u0329', u'\u02a8', u'\u012d', u'\u02b0', u'\u03b2', u'?', u'\u02c0', u'\u02c8', u'\u0276', u'\u02cc', u'\u01ce', u'\u02d0', u'\u0278', u'\u025b', u'r', u'_', u'\u0361', u'\u02e0', u'\u0263', u'g', u'\u01d0', u'\u0169', u'\u026b', u'\u016d', u'\xec', u'o', u'\xf0', u'\u0273', u'\xf4', u'w', u'\xf8', u'\u027b', u'\u0281', u'\u0300', u'\u0304', u'\u0289', u'\u028d', u'\u030c', u'\u0291', u'\u1e59', u'\u0275', u'\u029d', u'\u031c', u'\u0320', u'\u02a5', u'\u0324', u'.', u'\u02b1', u'\u025f', u'\u02b9', u':', u'\u1ebd', u'a', u'\u03c7', u'c', u'\u02d1', u'\u0252', u'\u0256', u'\u0265', u'\u035c', u'\xe1', u'b', u'\u0267', u'f', u'\xe9', u'j', u'\xed', u'n', u'\u0272', u'\xf5', u'v', u'\xf9', u'z', u'k', u'\u027e', u'\u0303', u'\u0282', u'\u026d', u'\u028a', u'\u028e', u'\u0292', u'\u026f', u'\u011b', u'\u031f', u'\u02a6', u'-', u's', u'\u032f', u'\u02b2', u'\u03b8', u'\u033b', u'\u014b', u'\u0161', u'\u0251', u'\u0279', u'\u0153', u'\u0255', u'\u01d4', u'\u0259', u'\u0261', u'\xe2', u'e', u'\xe6', u'i', u'\u027d', u'\xea', u'm', u'\xee', u'q', u'\u0129', u'u', u'y', u'\xfa', u'\u1e7d']
52  LANGUAGES
['SWEDISH', 'DANISH', 'GUTNISH_LAU', 'OSSETIC_IRON', 'BIHARI', 'MARATHI', 'SORBIAN_UPPER', 'ORIYA', 'SLOVENIAN', 'MIDDLE_CORNISH', 'ANCIENT_GREEK', 'GREEK', 'OLD_SWEDISH', 'ICELANDIC', 'SLOVAK', 'DUTCH', 'ASSAMESE', 'FRENCH', 'ITALIAN', 'LATIN', 'FAROESE', 'UKRAINIAN', 'CZECH', 'STAVANGERSK', 'NORWEGIAN_RIKSMAL', 'BRETON', 'OLD_NORSE', 'SPANISH', 'MAGAHI', 'OLD_CHURCH_SLAVONIC', 'PORTUGUESE', 'OLD_IRISH', 'MIDDLE_BRETON', 'GERMAN', 'DANISH_FJOLDE', 'IRISH', 'OSSETIC', 'MACEDONIAN', 'ELFDALIAN', 'BELARUSIAN', 'ARMENIAN_EASTERN', 'POLISH', 'ENGLISH', 'FRISIAN', 'BULGARIAN', 'SERBO-CROATIAN', 'SORBIAN_LOWER', 'URDU', 'CATALAN', 'CLASSICAL_ARMENIAN', 'RUSSIAN', 'OSSETIC_DIGOR']
Vocab Size :  521
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 50)	       26050
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 50)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 150)       75600
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 150)       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 150), (No 90150
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 150)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 150)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 300)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 300)	       0
____________________________________________________________________________________________________
Input Concept Feat (InputLayer)	 (None, 300)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 600)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       12020
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 203,841.0
Trainable params: 203,841.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.705303

Training -> Precision:	0.699711321228	 Recall:  0.653607159606	 F-Score:  0.675873913922	 AUC:  0.751652813
Testing	 -> Precision:	0.730955259976	 Recall:  0.612306913143	 F-Score:  0.66639107069	 AUC:  0.741649029908

204233/204233 [==============================] - 279s - loss: 0.7053
Epoch 2/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.547124

Training -> Precision:	0.63643076224	 Recall:  0.875801156792	 F-Score:  0.737171052632	 AUC:  0.828288744891
Testing	 -> Precision:	0.660418743769	 Recall:  0.838693340086	 F-Score:  0.738955823293	 AUC:  0.800848095583

204233/204233 [==============================] - 271s - loss: 0.5471
Epoch 3/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.470443

Training -> Precision:	0.776335093897	 Recall:  0.82718461779		 F-Score:  0.800953606297	 AUC:  0.87168598085
Testing	 -> Precision:	0.758136094675	 Recall:  0.778678146366	 F-Score:  0.768269831355	 AUC:  0.835834610177

204233/204233 [==============================] - 271s - loss: 0.4704
Epoch 4/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.407929

Training -> Precision:	0.821077176819	 Recall:  0.846314678756	 F-Score:  0.833504931441	 AUC:  0.899748472987
Testing	 -> Precision:	0.775462962963	 Recall:  0.763484426437	 F-Score:  0.769427076688	 AUC:  0.843263985761

204233/204233 [==============================] - 271s - loss: 0.4079
Epoch 5/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.360403

Training -> Precision:	0.828483976169	 Recall:  0.888561044239	 F-Score:  0.857471502786	 AUC:  0.921148464439
Testing	 -> Precision:	0.789539854161	 Recall:  0.795138009623	 F-Score:  0.792329043654	 AUC:  0.855227403714

204233/204233 [==============================] - 271s - loss: 0.3603
Epoch 6/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.320699

Training -> Precision:	0.810220093744	 Recall:  0.932253400031	 F-Score:  0.866963474468	 AUC:  0.938432347228
Testing	 -> Precision:	0.742665742666	 Recall:  0.814130159534	 F-Score:  0.776757670935	 AUC:  0.849832475702

204233/204233 [==============================] - 271s - loss: 0.3206
Epoch 7/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.288167

Training -> Precision:	0.852354897166	 Recall:  0.946674222292	 F-Score:  0.897042077489	 AUC:  0.95647434607
Testing	 -> Precision:	0.762834417932	 Recall:  0.80146872626		 F-Score:  0.781674487528	 AUC:  0.865802495859

204233/204233 [==============================] - 271s - loss: 0.2881
Epoch 8/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.260936

Training -> Precision:	0.889555933205	 Recall:  0.941007503517	 F-Score:  0.914558644789	 AUC:  0.962795383476
Testing	 -> Precision:	0.794094794095	 Recall:  0.776399088377	 F-Score:  0.785147247119	 AUC:  0.862053747765

204233/204233 [==============================] - 272s - loss: 0.2609
Epoch 9/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.238677

Training -> Precision:	0.877310326425	 Recall:  0.963693919025	 F-Score:  0.918475477461	 AUC:  0.971933880133
Testing	 -> Precision:	0.783349561831	 Recall:  0.814889845531	 F-Score:  0.798808489512	 AUC:  0.878588387408

204233/204233 [==============================] - 271s - loss: 0.2386
Epoch 10/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.220071

Training -> Precision:	0.913912673608	 Recall:  0.965647959981	 F-Score:  0.939068304687	 AUC:  0.978408750186
Testing	 -> Precision:	0.817564035546	 Recall:  0.792099265637	 F-Score:  0.80463022508	 AUC:  0.883535414212

204233/204233 [==============================] - 271s - loss: 0.2200
Epoch 11/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.203913

Training -> Precision:	0.904480810796	 Recall:  0.973073315617	 F-Score:  0.937524121506	 AUC:  0.979694883865
Testing	 -> Precision:	0.7986339489	 Recall:  0.799442896936	 F-Score:  0.799038218173	 AUC:  0.879488247764

204233/204233 [==============================] - 269s - loss: 0.2039
Epoch 12/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.189183

Training -> Precision:	0.921341485874	 Recall:  0.977548069408	 F-Score:  0.948612928305	 AUC:  0.985245882414
Testing	 -> Precision:	0.808422147128	 Recall:  0.787541149658	 F-Score:  0.797845048743	 AUC:  0.879718417663

204233/204233 [==============================] - 269s - loss: 0.1890
Epoch 13/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.177792

Training -> Precision:	0.937261432528	 Recall:  0.97879865562		 F-Score:  0.957579812655	 AUC:  0.987427061731
Testing	 -> Precision:	0.811678064177	 Recall:  0.781463661687	 F-Score:  0.796284350406	 AUC:  0.881648797204

204233/204233 [==============================] - 269s - loss: 0.1777
Epoch 14/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.168485

Training -> Precision:	0.913498012596	 Recall:  0.983488353916	 F-Score:  0.947202017446	 AUC:  0.98658699129
Testing	 -> Precision:	0.787066633882	 Recall:  0.810584958217	 F-Score:  0.798652694611	 AUC:  0.881449428828

204233/204233 [==============================] - 269s - loss: 0.1684
Epoch 15/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.159836

Training -> Precision:	0.944918992998	 Recall:  0.983527434735	 F-Score:  0.963836733912	 AUC:  0.989212902031
Testing	 -> Precision:	0.817266949153	 Recall:  0.781463661687	 F-Score:  0.798964401294	 AUC:  0.88138001033

204233/204233 [==============================] - 269s - loss: 0.1598
Epoch 16/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.155259

Training -> Precision:	0.955440927346	 Recall:  0.980850398624	 F-Score:  0.967978941888	 AUC:  0.990426694473
Testing	 -> Precision:	0.843497632971	 Recall:  0.767029627754	 F-Score:  0.803448275862	 AUC:  0.884078865389

204233/204233 [==============================] - 269s - loss: 0.1552
Epoch 17/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.147875

Training -> Precision:	0.9602712071	 Recall:  0.985227450367	 F-Score:  0.972589263324	 AUC:  0.991960605831
Testing	 -> Precision:	0.847091412742	 Recall:  0.774373259053	 F-Score:  0.809101733033	 AUC:  0.887001296074

204233/204233 [==============================] - 270s - loss: 0.1478
Epoch 18/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.142340

Training -> Precision:	0.940784713848	 Recall:  0.99095279037		 F-Score:  0.965217308552	 AUC:  0.992666594364
Testing	 -> Precision:	0.810139416984	 Recall:  0.80931881489		 F-Score:  0.809728908031	 AUC:  0.886347706984

204233/204233 [==============================] - 269s - loss: 0.1423
Epoch 19/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.137664

Training -> Precision:	0.960296493395	 Recall:  0.987298733781	 F-Score:  0.97361042865	 AUC:  0.994352253641
Testing	 -> Precision:	0.829241680306	 Recall:  0.769815143074	 F-Score:  0.798424162837	 AUC:  0.881337340303

204233/204233 [==============================] - 269s - loss: 0.1376
Epoch 20/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.132320

Training -> Precision:	0.963531450553	 Recall:  0.988666562451	 F-Score:  0.975937195598	 AUC:  0.994136025841
Testing	 -> Precision:	0.845074298294	 Recall:  0.777665231704	 F-Score:  0.809969668996	 AUC:  0.890973229244

204233/204233 [==============================] - 269s - loss: 0.1323
Epoch 21/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.129651

Training -> Precision:	0.956035669174	 Recall:  0.990913709551	 F-Score:  0.973162283269	 AUC:  0.994542308857
Testing	 -> Precision:	0.814727463312	 Recall:  0.787287920993	 F-Score:  0.800772698004	 AUC:  0.880533005083

204233/204233 [==============================] - 269s - loss: 0.1296
Epoch 22/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.124608

Training -> Precision:	0.966288059559	 Recall:  0.989115991871	 F-Score:  0.977568775891	 AUC:  0.994582636054
Testing	 -> Precision:	0.836604921205	 Recall:  0.766269941757	 F-Score:  0.799894263812	 AUC:  0.882622017534

204233/204233 [==============================] - 269s - loss: 0.1246
Epoch 23/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.121563

Training -> Precision:	0.960668093245	 Recall:  0.991284977333	 F-Score:  0.975736418453	 AUC:  0.995590246814
Testing	 -> Precision:	0.830183657173	 Recall:  0.789820207648	 F-Score:  0.809499091617	 AUC:  0.886333567009

204233/204233 [==============================] - 269s - loss: 0.1215
Epoch 24/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.119634

Training -> Precision:	0.968991803748	 Recall:  0.991050492418	 F-Score:  0.979897021745	 AUC:  0.995052938062
Testing	 -> Precision:	0.842441054092	 Recall:  0.769055457078	 F-Score:  0.804077310034	 AUC:  0.884259740141

204233/204233 [==============================] - 269s - loss: 0.1196
Epoch 25/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.116098

Training -> Precision:	0.961883110732	 Recall:  0.992125214945	 F-Score:  0.976770134954	 AUC:  0.996153233013
Testing	 -> Precision:	0.8307022319	 Recall:  0.77285388706		 F-Score:  0.800734618916	 AUC:  0.886393971082

204233/204233 [==============================] - 269s - loss: 0.1160
Epoch 26/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.112410

Training -> Precision:	0.979243097123	 Recall:  0.99099187119		 F-Score:  0.985082454402	 AUC:  0.996265585538
Testing	 -> Precision:	0.858386535113	 Recall:  0.749050392504	 F-Score:  0.8	 AUC:  0.888621379991

204233/204233 [==============================] - 269s - loss: 0.1124
Epoch 27/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.111514

Training -> Precision:	0.97864493831	 Recall:  0.990405658903	 F-Score:  0.984490176464	 AUC:  0.996614655671
Testing	 -> Precision:	0.855401190814	 Recall:  0.763990883768	 F-Score:  0.807116104869	 AUC:  0.887618123062

204233/204233 [==============================] - 269s - loss: 0.1114
Epoch 28/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.109128

Training -> Precision:	0.980076672862	 Recall:  0.989115991871	 F-Score:  0.984575585466	 AUC:  0.996063100167
Testing	 -> Precision:	0.863262910798	 Recall:  0.744998733857	 F-Score:  0.799782520049	 AUC:  0.887508215341

204233/204233 [==============================] - 269s - loss: 0.1091
Epoch 29/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.106365

Training -> Precision:	0.967546911538	 Recall:  0.994450523683	 F-Score:  0.980814261624	 AUC:  0.997159927814
Testing	 -> Precision:	0.825463083746	 Recall:  0.801215497594	 F-Score:  0.813158571061	 AUC:  0.89082671937

204233/204233 [==============================] - 270s - loss: 0.1063
Epoch 30/30
204160/204233 [============================>.] - ETA: 0ss--loss::0.105857

Training -> Precision:	0.968221064243	 Recall:  0.994821791465	 F-Score:  0.981341197787	 AUC:  0.996698790343
Testing	 -> Precision:	0.824714929727	 Recall:  0.787541149658	 F-Score:  0.805699481865	 AUC:  0.890308346321

204233/204233 [==============================] - 269s - loss: 0.1058
13184/132063[============================>.].- ETA:A0s0sss

Average Precision Score 0.890308346321
Training
	     precision	  recall  f1-score   support

	  0	 0.998	   0.989     0.994    153057
	  1	 0.968	   0.995     0.981     51176

avg / total	 0.991	   0.991     0.991    204233

Testing
	     precision	  recall  f1-score   support

	  0	 0.911	   0.929     0.920	9257
	  1	 0.825	   0.788     0.806	3949

avg / total	 0.885	   0.886     0.886     13206

Testing Accuracy
0.886415265788
