lstm_units 75
epochs 20
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Language Features False
Concept Features True
32  CHARACTERS
['"', '3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z', '~']
52  LANGUAGES
['SWEDISH', 'DANISH', 'GUTNISH_LAU', 'OSSETIC_IRON', 'FRENCH', 'BIHARI', 'DUTCH', 'MARATHI', 'SORBIAN_UPPER', 'ORIYA', 'SLOVENIAN', 'MIDDLE_CORNISH', 'ANCIENT_GREEK', 'ARMENIAN_EASTERN', 'OLD_SWEDISH', 'ICELANDIC', 'SLOVAK', 'ENGLISH', 'ASSAMESE', 'BRETON', 'ITALIAN', 'ELFDALIAN', 'UKRAINIAN', 'CZECH', 'STAVANGERSK', 'NORWEGIAN_RIKSMAL', 'OLD_NORSE', 'SPANISH', 'MAGAHI', 'OLD_CHURCH_SLAVONIC', 'PORTUGUESE', 'OLD_IRISH', 'IRISH', 'MIDDLE_BRETON', 'GERMAN', 'DANISH_FJOLDE', 'OSSETIC', 'MACEDONIAN', 'LATIN', 'BELARUSIAN', 'FAROESE', 'POLISH', 'FRISIAN', 'BULGARIAN', 'GREEK', 'CLASSICAL_ARMENIAN', 'SORBIAN_LOWER', 'URDU', 'CATALAN', 'SERBO-CROATIAN', 'RUSSIAN', 'OSSETIC_DIGOR']
Vocab Size :  35
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       350
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 150)       51600
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 150)       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 150), (No 90150
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 150)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 150)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 300)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 300)	       0
____________________________________________________________________________________________________
Input Concept Feat (InputLayer)	 (None, 300)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 600)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       12020
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 154,141.0
Trainable params: 154,141.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.715609

Training -> Precision:	0.6451520161	 Recall:  0.701578865093	 F-Score:  0.672183322724	 AUC:  0.747493736245
Testing	 -> Precision:	0.71186440678	 Recall:  0.701949860724	 F-Score:  0.706872370266	 AUC:  0.768938908759

204233/204233 [==============================] - 277s - loss: 0.7155
Epoch 2/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.601705

Training -> Precision:	0.646718210232	 Recall:  0.768211661716	 F-Score:  0.702248896987	 AUC:  0.768977205986
Testing	 -> Precision:	0.713735867212	 Recall:  0.751329450494	 F-Score:  0.732050333087	 AUC:  0.796121099741

204233/204233 [==============================] - 269s - loss: 0.6016
Epoch 3/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.557878

Training -> Precision:	0.696765498652	 Recall:  0.787986556198	 F-Score:  0.739573781315	 AUC:  0.812576161877
Testing	 -> Precision:	0.760566821402	 Recall:  0.788300835655	 F-Score:  0.774185525989	 AUC:  0.825563809442

204233/204233 [==============================] - 269s - loss: 0.5578
Epoch 4/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.527022

Training -> Precision:	0.700586299631	 Recall:  0.819563858058	 F-Score:  0.755419071891	 AUC:  0.832269579095
Testing	 -> Precision:	0.747142523909	 Recall:  0.811091415548	 F-Score:  0.777804759592	 AUC:  0.844248117611

204233/204233 [==============================] - 268s - loss: 0.5270
Epoch 5/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.496707

Training -> Precision:	0.754714198817	 Recall:  0.800062529311	 F-Score:  0.776727024387	 AUC:  0.8489131634
Testing	 -> Precision:	0.788365095286	 Recall:  0.796150924285	 F-Score:  0.792238881189	 AUC:  0.860071270091

204233/204233 [==============================] - 268s - loss: 0.4966
Epoch 6/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.469772

Training -> Precision:	0.771885209385	 Recall:  0.812548851024	 F-Score:  0.79169522504	 AUC:  0.865074349091
Testing	 -> Precision:	0.793439261917	 Recall:  0.783995948341	 F-Score:  0.788689338938	 AUC:  0.864739338374

204233/204233 [==============================] - 269s - loss: 0.4696
Epoch 7/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.445779

Training -> Precision:	0.788718611521	 Recall:  0.834707675473	 F-Score:  0.811061745272	 AUC:  0.877868611481
Testing	 -> Precision:	0.792317541613	 Recall:  0.78348949101		 F-Score:  0.787878787879	 AUC:  0.858707087406

204233/204233 [==============================] - 268s - loss: 0.4457
Epoch 8/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.423383

Training -> Precision:	0.706218706037	 Recall:  0.912263561044	 F-Score:  0.796125610702	 AUC:  0.889416712251
Testing	 -> Precision:	0.731907539425	 Recall:  0.857938718663	 F-Score:  0.78992772208	 AUC:  0.869426593022

204233/204233 [==============================] - 268s - loss: 0.4233
Epoch 9/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.403649

Training -> Precision:	0.770387205387	 Recall:  0.894188682195	 F-Score:  0.827684126754	 AUC:  0.901824637813
Testing	 -> Precision:	0.766713747646	 Recall:  0.824765763484	 F-Score:  0.794680980847	 AUC:  0.869996622081

204233/204233 [==============================] - 268s - loss: 0.4036
Epoch 10/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.388599

Training -> Precision:	0.814436369597	 Recall:  0.873749413788	 F-Score:  0.843050933738	 AUC:  0.907195824921
Testing	 -> Precision:	0.797850562948	 Recall:  0.789566978982	 F-Score:  0.793687157948	 AUC:  0.872847658824

204233/204233 [==============================] - 268s - loss: 0.3884
Epoch 11/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.372126

Training -> Precision:	0.76363284775	 Recall:  0.92598092856		 F-Score:  0.837007206443	 AUC:  0.921491641053
Testing	 -> Precision:	0.741340530814	 Recall:  0.834641681438	 F-Score:  0.785229303157	 AUC:  0.868714601021

204233/204233 [==============================] - 268s - loss: 0.3721
Epoch 12/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.356040

Training -> Precision:	0.809818924627	 Recall:  0.914100359544	 F-Score:  0.858805602981	 AUC:  0.926120246014
Testing	 -> Precision:	0.790086741016	 Recall:  0.807292985566	 F-Score:  0.798597194389	 AUC:  0.875710503158

204233/204233 [==============================] - 268s - loss: 0.3560
Epoch 13/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.341664

Training -> Precision:	0.834342560554	 Recall:  0.904642801313	 F-Score:  0.868071701793	 AUC:  0.930874955845
Testing	 -> Precision:	0.808411214953	 Recall:  0.78855406432		 F-Score:  0.79835918472	 AUC:  0.867204727942

204233/204233 [==============================] - 268s - loss: 0.3416
Epoch 14/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.330164

Training -> Precision:	0.804869851619	 Recall:  0.93592699703		 F-Score:  0.865465058499	 AUC:  0.936783427571
Testing	 -> Precision:	0.793053545586	 Recall:  0.832615852114	 F-Score:  0.812353304509	 AUC:  0.882339044368

204233/204233 [==============================] - 268s - loss: 0.3301
Epoch 15/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.319621

Training -> Precision:	0.854613538864	 Recall:  0.918672815382	 F-Score:  0.885486118959	 AUC:  0.944914273888
Testing	 -> Precision:	0.816136539953	 Recall:  0.79918966827		 F-Score:  0.807574206755	 AUC:  0.876762428015

204233/204233 [==============================] - 269s - loss: 0.3196
Epoch 16/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.308510

Training -> Precision:	0.812070525928	 Recall:  0.946791464749	 F-Score:  0.874271485538	 AUC:  0.947601040407
Testing	 -> Precision:	0.781264859724	 Recall:  0.832109394783	 F-Score:  0.805885959534	 AUC:  0.884499161789

204233/204233 [==============================] - 268s - loss: 0.3085
Epoch 17/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.298201

Training -> Precision:	0.817502398626	 Recall:  0.94901907144		 F-Score:  0.878365058552	 AUC:  0.949122699034
Testing	 -> Precision:	0.771455223881	 Recall:  0.837680425424	 F-Score:  0.803205050382	 AUC:  0.879709484101

204233/204233 [==============================] - 269s - loss: 0.2981
Epoch 18/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.288986

Training -> Precision:	0.832256953414	 Recall:  0.944290292325	 F-Score:  0.884741077068	 AUC:  0.954120425918
Testing	 -> Precision:	0.785784313725	 Recall:  0.811851101545	 F-Score:  0.79860505667	 AUC:  0.869053089649

204233/204233 [==============================] - 272s - loss: 0.2889
Epoch 19/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.283291

Training -> Precision:	0.8442830398	 Recall:  0.95171564796		 F-Score:  0.894786155203	 AUC:  0.959632767035
Testing	 -> Precision:	0.79063561378	 Recall:  0.825272220815	 F-Score:  0.807582703506	 AUC:  0.883544546327

204233/204233 [==============================] - 271s - loss: 0.2832
Epoch 20/20
204160/204233 [============================>.] - ETA: 0ss--loss::0.271697

Training -> Precision:	0.848605163237	 Recall:  0.956405346256	 F-Score:  0.899286193307	 AUC:  0.963698535153
Testing	 -> Precision:	0.784700505172	 Recall:  0.826031906812	 F-Score:  0.804835924007	 AUC:  0.880479763982

204233/204233 [==============================] - 272s - loss: 0.2716
13184/132063[============================>.].- ETA:A0s0sss

Average Precision Score 0.880479763982
Training
	     precision	  recall  f1-score   support

	  0	 0.985	   0.943     0.963    153057
	  1	 0.849	   0.956     0.899     51176

avg / total	 0.951	   0.946     0.947    204233

Testing
	     precision	  recall  f1-score   support

	  0	 0.924	   0.903     0.914	9257
	  1	 0.785	   0.826     0.805	3949

avg / total	 0.882	   0.880     0.881     13206

Testing Accuracy
0.880205966985
