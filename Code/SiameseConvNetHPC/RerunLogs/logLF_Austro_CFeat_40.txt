lstm_units 40
epochs 40
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Language Features False
Concept Features True
30  CHARACTERS
['3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z', '~']
100  LANGUAGES
['Teanu', 'Banjarese Malay', 'Lampung', 'Patpatar', 'Tabar', 'Tontemboan', 'Ambrym, South-East', 'Magori (South East Papua)', 'Futuna-Aniwa', 'Wuna', 'Tikopia', 'Cheke Holo', 'Windesi Wandamen', 'Gapapaiwa', 'Bunun, Southern', 'Tunjung', 'Tigak', 'Manam', 'Roti (Termanu Dialect)', 'Tetum', 'Sekar', 'Vitu', 'Alune', 'Tongan', 'Dobuan', 'Savu', 'Makassar', 'Watubela', 'Carolinian', 'Katingan', 'Soboyo', 'Kisar', 'Mambai', 'Tboli (Tagabili)', 'Sasak', 'Wogeo', 'Lenakel', 'Toambaita', 'Western Bukidnon Manobo', 'Baree', 'Molima', 'Wolio', 'Anejom (Aneityum)', 'Sengseng', 'Dehu', 'Ubir', 'Marshallese (E. Dialect)', 'Nakanai (Bileki Dialect)', 'Paiwan (Kulalao)', 'Rotuman', 'Singhi', 'Ujir (N.Aru)', 'Tsou', 'Futuna, East', 'Jawe', 'Bonfia', 'Samoan', 'Waropen', 'Santa Ana', 'Kapingamarangi', 'Kanakanabu', 'Melayu Ambon', 'Tuvalu', 'Lahanan', 'Kwaraae (Solomon Islands)', 'Maanyan', 'Roviana', 'Cebuano', 'Rejang Rejang', 'Ririo', 'Bukat', 'Teop', 'Wuvulu', 'Punan Kelai', 'Kilivila', 'Itbayaten', 'Sangir', 'Chuukese', 'Varisi', 'Seimat', 'Dayak Ngaju', 'Rurutuan', 'Tae (S.Toraja)', 'Ponapean', 'Taiof', 'Yakan', 'Vaghua', 'Raga', 'Toba Batak', 'Tahitian (Modern)', 'Elat, Kei Besar', 'Belait', 'Rennellese', 'Lio, Flores Tongah', 'Koiwai (Irian Jaya)', 'Woleai', 'As', 'Sika', 'Minangkabau', 'Selaru']
Vocab Size :  32
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       320
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 80)	       16320
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 80)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 80), (Non 25680
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 80)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 160)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 160)	       0
____________________________________________________________________________________________________
Input Concept Feat (InputLayer)	 (None, 300)	       0
____________________________________________________________________________________________________
concatenate_2 (Concatenate)	 (None, 460)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       9220
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 51,561.0
Trainable params: 51,561.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.7954421

Training -> Precision:	0.625910226009	 Recall:  0.61908962597		 F-Score:  0.622481243022	 AUC:  0.669800758978
Testing	 -> Precision:	0.547139547318	 Recall:  0.579682779456	 F-Score:  0.562941230402	 AUC:  0.60923735662

333626/333626 [==============================] - 384s - loss: 0.7954
Epoch 2/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.693354

Training -> Precision:	0.574290998767	 Recall:  0.773382041596	 F-Score:  0.65913071167	 AUC:  0.727679405449
Testing	 -> Precision:	0.50959186301	 Recall:  0.747356495468	 F-Score:  0.605986373727	 AUC:  0.669198741134

333626/333626 [==============================] - 376s - loss: 0.6933
Epoch 3/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.649947

Training -> Precision:	0.625514403292	 Recall:  0.777699364855	 F-Score:  0.693354305938	 AUC:  0.764168710189
Testing	 -> Precision:	0.543098669623	 Recall:  0.73999244713		 F-Score:  0.626438618926	 AUC:  0.703644112003

333626/333626 [==============================] - 385s - loss: 0.6499
Epoch 4/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.623695

Training -> Precision:	0.681303143031	 Recall:  0.745080742247	 F-Score:  0.711766105526	 AUC:  0.788111388625
Testing	 -> Precision:	0.588920817369	 Recall:  0.696563444109	 F-Score:  0.638235294118	 AUC:  0.711119172274

333626/333626 [==============================] - 390s - loss: 0.6235
Epoch 5/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.600519

Training -> Precision:	0.650632333933	 Recall:  0.799285981153	 F-Score:  0.717338760379	 AUC:  0.804152671194
Testing	 -> Precision:	0.555936562366	 Recall:  0.734705438066	 F-Score:  0.632940219601	 AUC:  0.712934152071

333626/333626 [==============================] - 386s - loss: 0.6004
Epoch 6/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.576960

Training -> Precision:	0.669387961217	 Recall:  0.825418240691	 F-Score:  0.739259754987	 AUC:  0.831780648261
Testing	 -> Precision:	0.564062276818	 Recall:  0.745657099698	 F-Score:  0.642270472473	 AUC:  0.735061432542

333626/333626 [==============================] - 375s - loss: 0.5769
Epoch 7/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.555150

Training -> Precision:	0.717219647143	 Recall:  0.812570052721	 F-Score:  0.761923297749	 AUC:  0.846949499258
Testing	 -> Precision:	0.607408580022	 Recall:  0.724509063444	 F-Score:  0.660811159907	 AUC:  0.746520424628

333626/333626 [==============================] - 375s - loss: 0.5551
Epoch 8/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.532746

Training -> Precision:	0.72689756283	 Recall:  0.833575490888	 F-Score:  0.776590138891	 AUC:  0.860537234451
Testing	 -> Precision:	0.594123048669	 Recall:  0.733006042296	 F-Score:  0.656297548605	 AUC:  0.744196702219

333626/333626 [==============================] - 375s - loss: 0.5326
Epoch 9/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.512930

Training -> Precision:	0.709868028948	 Recall:  0.865270455395	 F-Score:  0.779903276802	 AUC:  0.874103205881
Testing	 -> Precision:	0.579450072359	 Recall:  0.756042296073	 F-Score:  0.65607078486	 AUC:  0.749882336126

333626/333626 [==============================] - 375s - loss: 0.5129
Epoch 10/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.496778

Training -> Precision:	0.773942467145	 Recall:  0.837934326871	 F-Score:  0.804668151625	 AUC:  0.884116639803
Testing	 -> Precision:	0.637609179654	 Recall:  0.702983383686	 F-Score:  0.668702290076	 AUC:  0.754868323232

333626/333626 [==============================] - 376s - loss: 0.4967
Epoch 11/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.481613

Training -> Precision:	0.772783454575	 Recall:  0.850024907634	 F-Score:  0.809565935071	 AUC:  0.891450698819
Testing	 -> Precision:	0.621162099703	 Recall:  0.710536253776	 F-Score:  0.662850096882	 AUC:  0.74397188831

333626/333626 [==============================] - 376s - loss: 0.4815
Epoch 12/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.467975

Training -> Precision:	0.771108699483	 Recall:  0.862779691976	 F-Score:  0.814372547963	 AUC:  0.897446308852
Testing	 -> Precision:	0.624815845474	 Recall:  0.720732628399	 F-Score:  0.669355545813	 AUC:  0.750661566377

333626/333626 [==============================] - 376s - loss: 0.4679
Epoch 13/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.455001

Training -> Precision:	0.751635756903	 Recall:  0.892959442069	 F-Score:  0.816225471828	 AUC:  0.907827721077
Testing	 -> Precision:	0.597336525512	 Recall:  0.753776435045	 F-Score:  0.666499707822	 AUC:  0.756500094521

333626/333626 [==============================] - 375s - loss: 0.4550
Epoch 14/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.444091

Training -> Precision:	0.811341942729	 Recall:  0.869795342272	 F-Score:  0.839552425696	 AUC:  0.916864421665
Testing	 -> Precision:	0.645818815331	 Recall:  0.69996223565		 F-Score:  0.671801377311	 AUC:  0.758228270479

333626/333626 [==============================] - 376s - loss: 0.4441
Epoch 15/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.433676

Training -> Precision:	0.792594838994	 Recall:  0.895086969156	 F-Score:  0.840728754411	 AUC:  0.922704646445
Testing	 -> Precision:	0.625697407286	 Recall:  0.71997734139		 F-Score:  0.669534679543	 AUC:  0.755155931193

333626/333626 [==============================] - 376s - loss: 0.4336
Epoch 16/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.425710

Training -> Precision:	0.758157537231	 Recall:  0.920897505085	 F-Score:  0.831640853816	 AUC:  0.926033399263
Testing	 -> Precision:	0.592886537331	 Recall:  0.76170694864		 F-Score:  0.666776859504	 AUC:  0.763490149627

333626/333626 [==============================] - 376s - loss: 0.4256
Epoch 17/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.416380

Training -> Precision:	0.79704797048	 Recall:  0.905641579144	 F-Score:  0.847881849981	 AUC:  0.92858820265
Testing	 -> Precision:	0.623284353302	 Recall:  0.728851963746	 F-Score:  0.671947079815	 AUC:  0.75932038568

333626/333626 [==============================] - 375s - loss: 0.4163
Epoch 18/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.409766

Training -> Precision:	0.834300013579	 Recall:  0.892710365727	 F-Score:  0.862517422214	 AUC:  0.933562863237
Testing	 -> Precision:	0.660941926346	 Recall:  0.704871601208	 F-Score:  0.682200292398	 AUC:  0.766592829431

333626/333626 [==============================] - 377s - loss: 0.4097
Epoch 19/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.402822

Training -> Precision:	0.785278076848	 Recall:  0.923481672133	 F-Score:  0.848790957218	 AUC:  0.935377732487
Testing	 -> Precision:	0.608774859572	 Recall:  0.757175226586	 F-Score:  0.674913742321	 AUC:  0.773378531234

333626/333626 [==============================] - 375s - loss: 0.4028
Epoch 20/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.395459

Training -> Precision:	0.827876546722	 Recall:  0.906139731828	 F-Score:  0.865241971846	 AUC:  0.938302298052
Testing	 -> Precision:	0.638888888889	 Recall:  0.703549848943	 F-Score:  0.669662113587	 AUC:  0.756168462803

333626/333626 [==============================] - 378s - loss: 0.3955
Epoch 21/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.389108

Training -> Precision:	0.853365003959	 Recall:  0.894848270995	 F-Score:  0.873614460273	 AUC:  0.941161658651
Testing	 -> Precision:	0.672530694521	 Recall:  0.692975830816	 F-Score:  0.682600204594	 AUC:  0.767065919413

333626/333626 [==============================] - 380s - loss: 0.3891
Epoch 22/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.382262

Training -> Precision:	0.826063442926	 Recall:  0.919423803396	 F-Score:  0.870246854157	 AUC:  0.944037282418
Testing	 -> Precision:	0.637986192962	 Recall:  0.715445619335	 F-Score:  0.674499332443	 AUC:  0.762961575416

333626/333626 [==============================] - 380s - loss: 0.3822
Epoch 23/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.376291

Training -> Precision:	0.822320022834	 Recall:  0.926906471834	 F-Score:  0.871486629555	 AUC:  0.946932975957
Testing	 -> Precision:	0.630221932115	 Recall:  0.729229607251	 F-Score:  0.676120448179	 AUC:  0.769565121293

333626/333626 [==============================] - 380s - loss: 0.3762
Epoch 24/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.370898

Training -> Precision:	0.825237137108	 Recall:  0.923668479389	 F-Score:  0.871682867706	 AUC:  0.947149664017
Testing	 -> Precision:	0.635878626209	 Recall:  0.720166163142	 F-Score:  0.67540286878	 AUC:  0.76404304826

333626/333626 [==============================] - 379s - loss: 0.3708
Epoch 25/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.366821

Training -> Precision:	0.837746325633	 Recall:  0.926958362738	 F-Score:  0.88009735285	 AUC:  0.951471596462
Testing	 -> Precision:	0.644719025051	 Recall:  0.719222054381	 F-Score:  0.679935737237	 AUC:  0.766540616887

333626/333626 [==============================] - 376s - loss: 0.3668
Epoch 26/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.361801

Training -> Precision:	0.847874294525	 Recall:  0.924561002947	 F-Score:  0.884558673862	 AUC:  0.952147582574
Testing	 -> Precision:	0.640334413923	 Recall:  0.708648036254	 F-Score:  0.672761495026	 AUC:  0.760061037354

333626/333626 [==============================] - 376s - loss: 0.3618
Epoch 27/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.355340

Training -> Precision:	0.848015534716	 Recall:  0.929106646187	 F-Score:  0.886710973327	 AUC:  0.955496550884
Testing	 -> Precision:	0.65485495918	 Recall:  0.711858006042	 F-Score:  0.682167737266	 AUC:  0.768253821866

333626/333626 [==============================] - 376s - loss: 0.3553
Epoch 28/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.354617

Training -> Precision:	0.843109328736	 Recall:  0.933828718502	 F-Score:  0.886153240102	 AUC:  0.955400842553
Testing	 -> Precision:	0.638763575606	 Recall:  0.721865558912	 F-Score:  0.677776792838	 AUC:  0.7650484848

333626/333626 [==============================] - 387s - loss: 0.3546
Epoch 29/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.349041

Training -> Precision:	0.817818958094	 Recall:  0.946251401054	 F-Score:  0.877359943034	 AUC:  0.956859102428
Testing	 -> Precision:	0.612005627638	 Recall:  0.739237160121	 F-Score:  0.669631403404	 AUC:  0.763001834567

333626/333626 [==============================] - 376s - loss: 0.3490
Epoch 30/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.344425

Training -> Precision:	0.875225225225	 Recall:  0.927581053593	 F-Score:  0.90064289889	 AUC:  0.959872579999
Testing	 -> Precision:	0.669676720246	 Recall:  0.700151057402	 F-Score:  0.684574909997	 AUC:  0.772017358596

333626/333626 [==============================] - 376s - loss: 0.3444
Epoch 31/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.340347

Training -> Precision:	0.869454661918	 Recall:  0.929739715223	 F-Score:  0.898587212189	 AUC:  0.958908595266
Testing	 -> Precision:	0.660829163688	 Recall:  0.698262839879	 F-Score:  0.679030481087	 AUC:  0.766029100692

333626/333626 [==============================] - 376s - loss: 0.3403
Epoch 32/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.336756

Training -> Precision:	0.849955655137	 Recall:  0.944860724812	 F-Score:  0.89489902738	 AUC:  0.962300346084
Testing	 -> Precision:	0.639784946237	 Recall:  0.719033232628	 F-Score:  0.677098150782	 AUC:  0.763790274424

333626/333626 [==============================] - 376s - loss: 0.3366
Epoch 33/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.334562

Training -> Precision:	0.844959508517	 Recall:  0.942068994147	 F-Score:  0.890875722572	 AUC:  0.960251549385
Testing	 -> Precision:	0.640260173449	 Recall:  0.724886706949	 F-Score:  0.679950407368	 AUC:  0.770257167398

333626/333626 [==============================] - 376s - loss: 0.3345
Epoch 34/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.330620

Training -> Precision:	0.883140053524	 Recall:  0.934970318403	 F-Score:  0.908316403434	 AUC:  0.964394413752
Testing	 -> Precision:	0.679697584363	 Recall:  0.695996978852	 F-Score:  0.687750723015	 AUC:  0.772478012966

333626/333626 [==============================] - 387s - loss: 0.3305
Epoch 35/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.326354

Training -> Precision:	0.859226224079	 Recall:  0.947756237287	 F-Score:  0.90132254244	 AUC:  0.964697120857
Testing	 -> Precision:	0.638003709324	 Recall:  0.714501510574	 F-Score:  0.674089249132	 AUC:  0.766058360633

333626/333626 [==============================] - 409s - loss: 0.3263
Epoch 36/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.324071

Training -> Precision:	0.872388138709	 Recall:  0.940699074266	 F-Score:  0.905256745083	 AUC:  0.964326864728
Testing	 -> Precision:	0.659321130265	 Recall:  0.700528700906	 F-Score:  0.679300558455	 AUC:  0.766457138343

333626/333626 [==============================] - 376s - loss: 0.3240
Epoch 37/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.321103

Training -> Precision:	0.857450776425	 Recall:  0.949562040765	 F-Score:  0.901158753687	 AUC:  0.965887365648
Testing	 -> Precision:	0.639920093225	 Recall:  0.72583081571		 F-Score:  0.680173405291	 AUC:  0.765649914759

333626/333626 [==============================] - 376s - loss: 0.3211
Epoch 38/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.318570

Training -> Precision:	0.86963228153	 Recall:  0.947880775458	 F-Score:  0.907072131571	 AUC:  0.966515252907
Testing	 -> Precision:	0.650360453141	 Recall:  0.715445619335	 F-Score:  0.681352274771	 AUC:  0.768603593296

333626/333626 [==============================] - 375s - loss: 0.3186
Epoch 39/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.315674

Training -> Precision:	0.905224603463	 Recall:  0.93107850056		 F-Score:  0.91796954938	 AUC:  0.968722520124
Testing	 -> Precision:	0.693709582598	 Recall:  0.668429003021	 F-Score:  0.680834695644	 AUC:  0.767126402475

333626/333626 [==============================] - 377s - loss: 0.3156
Epoch 40/40
333568/333626 [============================>.] - ETA: 0ss--loss::0.313649

Training -> Precision:	0.857940458214	 Recall:  0.955259662086	 F-Score:  0.90398837175	 AUC:  0.967583328035
Testing	 -> Precision:	0.632523242538	 Recall:  0.732250755287	 F-Score:  0.678743327207	 AUC:  0.772730133522

333626/333626 [==============================] - 376s - loss: 0.3136
20736/207992[============================>.].- ETA:A0sssss

Average Precision Score 0.772730133522
Training
	     precision	  recall  f1-score   support

	  0	 0.981	   0.936     0.958    237270
	  1	 0.858	   0.955     0.904     96356

avg / total	 0.945	   0.941     0.942    333626

Testing
	     precision	  recall  f1-score   support

	  0	 0.903	   0.855     0.878     15503
	  1	 0.633	   0.732     0.679	5296

avg / total	 0.834	   0.824     0.828     20799

Testing Accuracy
0.823501129862
