32  CHARACTERS
[' ', '"', '%', '3', '5', '7', '8', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', '~']
30  LANGUAGES
['SIPAKAPENSE', 'TZUTUJIL_SAN_JUAN_LA_LAGUNA', 'MAM_NORTHERN', 'CHORTI', 'POQOMCHI_WESTERN', 'TZELTAL_BACHAJON', 'SOUTHERN_CAKCHIQUEL_SAN_ANDRES_ITZAPA', 'MAYA_YUCATAN', 'CHONTAL_TABASCO', 'CENTRAL_QUICHE', 'EASTERN_KEKCHI_CAHABON', 'TECO_TECTITAN', 'JACALTEC', 'QANJOBAL_SANTA_EULALIA', 'LACANDON', 'ZINACANTAN_TZOTZIL', 'POCOMAM_EASTERN', 'IXIL_CHAJUL', 'CHUJ', 'CHOL_TUMBALA', 'AGUACATEC', 'MOPAN', 'MOCHO', 'ITZAJ', 'HUASTEC', 'USPANTEKO', 'ACATECO_SAN_MIGUEL_ACATAN', 'SACAPULTECO_SACAPULAS_CENTRO', 'TOJOLABAL', 'CHICOMUCELTEC']
lstm_units 30
epochs 40
batch_size 128
xmaxlen 12
regularization factor 0.02
dropout 0.1
LR 0.001
Embedding Size 10
Tokenize Simple False
Using Concept Fold Data False
Vocab Size :  34
Building model
NO MASKING
NO MASKING
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
Input Word A (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Input Word B (InputLayer)	 (None, 12)	       0
____________________________________________________________________________________________________
Embedding Layer (Embedding)	 (None, 12, 10)	       340
____________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDrop (None, 12, 10)	       0
____________________________________________________________________________________________________
Bidir LSTM Layer (Bidirectional) (None, 12, 60)	       9840
____________________________________________________________________________________________________
LSTM Dropout Layer (SpatialDropo (None, 12, 60)	       0
____________________________________________________________________________________________________
Attention Layer (WbwAttentionLay [(None, 12, 60), (Non 14460
____________________________________________________________________________________________________
r_a_n (Lambda)			 (None, 60)	       0
____________________________________________________________________________________________________
r_b_n (Lambda)			 (None, 60)	       0
____________________________________________________________________________________________________
concatenate_1 (Concatenate)	 (None, 120)	       0
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 120)	       0
____________________________________________________________________________________________________
Hidden Layer (Dense)		 (None, 20)	       2420
____________________________________________________________________________________________________
Output Layer (Dense)		 (None, 1)	       21
====================================================================================================
Total params: 27,081.0
Trainable params: 27,081.0
Non-trainable params: 0.0
____________________________________________________________________________________________________
Model Compiled
Training New Model
Epoch 1/40
25472/25473 [============================>.] - ETA: 0ss--loss::1.07531

Training -> Precision:	0.500881191127	 Recall:  0.857291449969	 F-Score:  0.632321914918	 AUC:  0.726102639979
Testing	 -> Precision:	0.416374269006	 Recall:  0.807256235828	 F-Score:  0.549382716049	 AUC:  0.575484400029

25473/25473 [==============================] - 35s - loss: 1.0753
Epoch 2/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.80001

Training -> Precision:	0.685696556004	 Recall:  0.68961930518		 F-Score:  0.687652336255	 AUC:  0.770059665932
Testing	 -> Precision:	0.553610503282	 Recall:  0.573696145125	 F-Score:  0.563474387528	 AUC:  0.591750636885

25473/25473 [==============================] - 27s - loss: 0.7999
Epoch 3/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.74403

Training -> Precision:	0.73818063254	 Recall:  0.706469731641	 F-Score:  0.721977145894	 AUC:  0.805302083822
Testing	 -> Precision:	0.595294117647	 Recall:  0.573696145125	 F-Score:  0.584295612009	 AUC:  0.632661935948

25473/25473 [==============================] - 27s - loss: 0.7440
Epoch 4/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.72245

Training -> Precision:	0.738772146683	 Recall:  0.745995423341	 F-Score:  0.742366214678	 AUC:  0.818135861276
Testing	 -> Precision:	0.614879649891	 Recall:  0.637188208617	 F-Score:  0.62583518931	 AUC:  0.652051997551

25473/25473 [==============================] - 27s - loss: 0.7224
Epoch 5/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.69264

Training -> Precision:	0.705575723727	 Recall:  0.788433534429	 F-Score:  0.7447069804		 AUC:  0.826890689931
Testing	 -> Precision:	0.581395348837	 Recall:  0.680272108844	 F-Score:  0.626959247649	 AUC:  0.677834137939

25473/25473 [==============================] - 27s - loss: 0.6926
Epoch 6/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.67904

Training -> Precision:	0.741814595661	 Recall:  0.782400665696	 F-Score:  0.761567277513	 AUC:  0.83130124341
Testing	 -> Precision:	0.612970711297	 Recall:  0.664399092971	 F-Score:  0.637649619151	 AUC:  0.661093780564

25473/25473 [==============================] - 27s - loss: 0.6790
Epoch 7/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.67261

Training -> Precision:	0.719614028577	 Recall:  0.806740170585	 F-Score:  0.76069046685	 AUC:  0.842033198922
Testing	 -> Precision:	0.593927893738	 Recall:  0.709750566893	 F-Score:  0.646694214876	 AUC:  0.667158388114

25473/25473 [==============================] - 27s - loss: 0.6726
Epoch 8/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.68783

Training -> Precision:	0.763718392614	 Recall:  0.757125026004	 F-Score:  0.76040741708	 AUC:  0.823840888513
Testing	 -> Precision:	0.671232876712	 Recall:  0.666666666667	 F-Score:  0.668941979522	 AUC:  0.672156942764

25473/25473 [==============================] - 27s - loss: 0.6878
Epoch 9/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.68073

Training -> Precision:	0.733449646215	 Recall:  0.787081339713	 F-Score:  0.759319652802	 AUC:  0.832610823632
Testing	 -> Precision:	0.624489795918	 Recall:  0.69387755102		 F-Score:  0.657357679914	 AUC:  0.67928717461

25473/25473 [==============================] - 27s - loss: 0.6807
Epoch 10/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.67848

Training -> Precision:	0.809455243581	 Recall:  0.701685042646	 F-Score:  0.751727211946	 AUC:  0.829309570628
Testing	 -> Precision:	0.699724517906	 Recall:  0.575963718821	 F-Score:  0.63184079602	 AUC:  0.66415547717

25473/25473 [==============================] - 27s - loss: 0.6784
Epoch 11/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.70879

Training -> Precision:	0.737673297167	 Recall:  0.636467651342	 F-Score:  0.683343570272	 AUC:  0.761288193656
Testing	 -> Precision:	0.615598885794	 Recall:  0.501133786848	 F-Score:  0.5525	 AUC:  0.62228055445

25473/25473 [==============================] - 27s - loss: 0.7087
Epoch 12/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.74011

Training -> Precision:	0.530316860086	 Recall:  0.846057832328	 F-Score:  0.651971785829	 AUC:  0.625965841259
Testing	 -> Precision:	0.434378629501	 Recall:  0.848072562358	 F-Score:  0.574500768049	 AUC:  0.540947220931

25473/25473 [==============================] - 27s - loss: 0.7402
Epoch 13/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.75606

Training -> Precision:	0.818262299229	 Recall:  0.672976908675	 F-Score:  0.738542320644	 AUC:  0.816991334417
Testing	 -> Precision:	0.740947075209	 Recall:  0.603174603175	 F-Score:  0.665	 AUC:  0.678630065601

25473/25473 [==============================] - 27s - loss: 0.7560
Epoch 14/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.71967

Training -> Precision:	0.733271851624	 Recall:  0.74433118369		 F-Score:  0.738760130078	 AUC:  0.817284889641
Testing	 -> Precision:	0.627272727273	 Recall:  0.625850340136	 F-Score:  0.626560726447	 AUC:  0.678912072428

25473/25473 [==============================] - 27s - loss: 0.7196
Epoch 15/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.71381

Training -> Precision:	0.763113745666	 Recall:  0.709694195964	 F-Score:  0.73543519267	 AUC:  0.821388150966
Testing	 -> Precision:	0.683046683047	 Recall:  0.630385487528	 F-Score:  0.655660377358	 AUC:  0.680506967117

25473/25473 [==============================] - 27s - loss: 0.7139
Epoch 16/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.74042

Training -> Precision:	0.660255319149	 Recall:  0.806948200541	 F-Score:  0.726268489047	 AUC:  0.803520840804
Testing	 -> Precision:	0.559440559441	 Recall:  0.725623582766	 F-Score:  0.631786771964	 AUC:  0.680419214189

25473/25473 [==============================] - 27s - loss: 0.7404
Epoch 17/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.74780

Training -> Precision:	0.725037936267	 Recall:  0.74547534845		 F-Score:  0.735114621263	 AUC:  0.813231715852
Testing	 -> Precision:	0.624454148472	 Recall:  0.648526077098	 F-Score:  0.636262513904	 AUC:  0.645120600815

25473/25473 [==============================] - 27s - loss: 0.7478
Epoch 18/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.74627

Training -> Precision:	0.669746361022	 Recall:  0.799251092157	 F-Score:  0.728790249917	 AUC:  0.805973530485
Testing	 -> Precision:	0.552631578947	 Recall:  0.714285714286	 F-Score:  0.623145400593	 AUC:  0.651833694538

25473/25473 [==============================] - 27s - loss: 0.7462
Epoch 19/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.74099

Training -> Precision:	0.741915925627	 Recall:  0.763677969628	 F-Score:  0.752639671963	 AUC:  0.819306756222
Testing	 -> Precision:	0.651515151515	 Recall:  0.68253968254		 F-Score:  0.666666666667	 AUC:  0.678410239292

25473/25473 [==============================] - 27s - loss: 0.7410
Epoch 20/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.72296

Training -> Precision:	0.849167623421	 Recall:  0.615456625754	 F-Score:  0.713665420335	 AUC:  0.801255689357
Testing	 -> Precision:	0.717717717718	 Recall:  0.541950113379	 F-Score:  0.617571059432	 AUC:  0.653902687341

25473/25473 [==============================] - 27s - loss: 0.7229
Epoch 21/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.74194

Training -> Precision:	0.540893650379	 Recall:  0.861244019139	 F-Score:  0.664473156247	 AUC:  0.802227010937
Testing	 -> Precision:	0.451851851852	 Recall:  0.829931972789	 F-Score:  0.585131894484	 AUC:  0.661581439928

25473/25473 [==============================] - 27s - loss: 0.7420
Epoch 22/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.90725

Training -> Precision:	0.401968009016	 Recall:  0.964530892449	 F-Score:  0.567450968393	 AUC:  0.772524678977
Testing	 -> Precision:	0.321401370906	 Recall:  0.956916099773	 F-Score:  0.481185860889	 AUC:  0.621768928856

25473/25473 [==============================] - 27s - loss: 0.9072
Epoch 23/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.82075

Training -> Precision:	0.714830464805	 Recall:  0.721447888496	 F-Score:  0.718123932288	 AUC:  0.698975673543
Testing	 -> Precision:	0.610972568579	 Recall:  0.555555555556	 F-Score:  0.581947743468	 AUC:  0.631760128794

25473/25473 [==============================] - 28s - loss: 0.8207
Epoch 24/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.89579

Training -> Precision:	1.0	 Recall:  0.000312044934471	 F-Score:  0.000623895185609	 AUC:  0.745230549986
Testing	 -> Precision:	0.0	 Recall:  0.0	 F-Score:  0.0	 AUC:  0.607239560687

25473/25473 [==============================] - 27s - loss: 0.8957
Epoch 25/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.82046

Training -> Precision:	0.679456360947	 Recall:  0.764406074475	 F-Score:  0.719432207538	 AUC:  0.75197279177
Testing	 -> Precision:	0.568665377176	 Recall:  0.666666666667	 F-Score:  0.613778705637	 AUC:  0.62898945434

25473/25473 [==============================] - 27s - loss: 0.8204
Epoch 26/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.79531

Training -> Precision:	0.386981225296	 Recall:  0.977636779696	 F-Score:  0.554480561619	 AUC:  0.607502801412
Testing	 -> Precision:	0.305457122608	 Recall:  0.977324263039	 F-Score:  0.465442764579	 AUC:  0.514555238994

25473/25473 [==============================] - 27s - loss: 0.7953
Epoch 27/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.86200

Training -> Precision:	0.616221255438	 Recall:  0.82504680674		 F-Score:  0.705505647959	 AUC:  0.767509221429
Testing	 -> Precision:	0.499259259259	 Recall:  0.764172335601	 F-Score:  0.60394265233	 AUC:  0.639641784131

25473/25473 [==============================] - 27s - loss: 0.8620
Epoch 28/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.87444

Training -> Precision:	0.544433232425	 Recall:  0.841793218223	 F-Score:  0.661219821071	 AUC:  0.728324117929
Testing	 -> Precision:	0.452445652174	 Recall:  0.755102040816	 F-Score:  0.565845369584	 AUC:  0.566333497051

25473/25473 [==============================] - 27s - loss: 0.8744
Epoch 29/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.80651

Training -> Precision:	0.536569703975	 Recall:  0.869149157479	 F-Score:  0.663516893636	 AUC:  0.728106461104
Testing	 -> Precision:	0.450127877238	 Recall:  0.798185941043	 F-Score:  0.575633687653	 AUC:  0.559409370165

25473/25473 [==============================] - 27s - loss: 0.8065
Epoch 30/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.79304

Training -> Precision:	0.656681822234	 Recall:  0.766174329103	 F-Score:  0.707215208103	 AUC:  0.721132328271
Testing	 -> Precision:	0.540145985401	 Recall:  0.671201814059	 F-Score:  0.598584428716	 AUC:  0.580108482181

25473/25473 [==============================] - 27s - loss: 0.7930
Epoch 31/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.78734

Training -> Precision:	0.609076885605	 Recall:  0.780320366133	 F-Score:  0.684145729789	 AUC:  0.730363461172
Testing	 -> Precision:	0.516949152542	 Recall:  0.691609977324	 F-Score:  0.591658583899	 AUC:  0.567105580903

25473/25473 [==============================] - 27s - loss: 0.7874
Epoch 32/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.80977

Training -> Precision:	0.642415994975	 Recall:  0.638339920949	 F-Score:  0.6403714718		 AUC:  0.719629656417
Testing	 -> Precision:	0.522624434389	 Recall:  0.52380952381		 F-Score:  0.523216308041	 AUC:  0.567244164922

25473/25473 [==============================] - 27s - loss: 0.8097
Epoch 33/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.82999

Training -> Precision:	0.600110111947	 Recall:  0.680257957146	 F-Score:  0.63767550702	 AUC:  0.719654098125
Testing	 -> Precision:	0.518867924528	 Recall:  0.62358276644		 F-Score:  0.566426364573	 AUC:  0.571751319129

25473/25473 [==============================] - 27s - loss: 0.8299
Epoch 34/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.83259

Training -> Precision:	0.667738601126	 Recall:  0.604743083004	 F-Score:  0.634681513018	 AUC:  0.700923788017
Testing	 -> Precision:	0.544364508393	 Recall:  0.514739229025	 F-Score:  0.529137529138	 AUC:  0.539289856326

25473/25473 [==============================] - 27s - loss: 0.8325
Epoch 35/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.82077

Training -> Precision:	0.57070750278	 Recall:  0.693883919284	 F-Score:  0.626296765714	 AUC:  0.604419078297
Testing	 -> Precision:	0.505415162455	 Recall:  0.634920634921	 F-Score:  0.562814070352	 AUC:  0.495594860319

25473/25473 [==============================] - 27s - loss: 0.8206
Epoch 36/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.84486

Training -> Precision:	0.539424703892	 Recall:  0.82899937591		 F-Score:  0.65357333224	 AUC:  0.61583789335
Testing	 -> Precision:	0.453691275168	 Recall:  0.766439909297	 F-Score:  0.569983136594	 AUC:  0.532074315248

25473/25473 [==============================] - 27s - loss: 0.8448
Epoch 37/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.85132

Training -> Precision:	0.585096518587	 Recall:  0.721967963387	 F-Score:  0.646365879778	 AUC:  0.627791266528
Testing	 -> Precision:	0.486013986014	 Recall:  0.630385487528	 F-Score:  0.548864758144	 AUC:  0.543794443928

25473/25473 [==============================] - 27s - loss: 0.8513
Epoch 38/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.83222

Training -> Precision:	0.586366590835	 Recall:  0.750676097358	 F-Score:  0.658425326156	 AUC:  0.61810417682
Testing	 -> Precision:	0.485903814262	 Recall:  0.664399092971	 F-Score:  0.561302681992	 AUC:  0.537060902389

25473/25473 [==============================] - 27s - loss: 0.8322
Epoch 39/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.86301

Training -> Precision:	0.446333366865	 Recall:  0.923028916164	 F-Score:  0.601708706265	 AUC:  0.603747731856
Testing	 -> Precision:	0.360747663551	 Recall:  0.875283446712	 F-Score:  0.510919920582	 AUC:  0.492220016746

25473/25473 [==============================] - 27s - loss: 0.8630
Epoch 40/40
25472/25473 [============================>.] - ETA: 0ss--loss::0.92263

Training -> Precision:	0.436251380383	 Recall:  0.903994175161	 F-Score:  0.588502166847	 AUC:  0.512227012087
Testing	 -> Precision:	0.330848089469	 Recall:  0.804988662132	 F-Score:  0.468956406869	 AUC:  0.35640868187

25473/25473 [==============================] - 27s - loss: 0.9226
25473/25473 [==============================] - 12s: 0ss
1440/1458 [============================>.] - ETA: 0s

Average Precision Score 0.35640868187
Training
	     precision	  recall  f1-score   support

	  0	 0.834	   0.292     0.432     15859
	  1	 0.436	   0.904     0.589	9614

avg / total	 0.684	   0.523     0.491     25473

Testing
	     precision	  recall  f1-score   support

	  0	 0.777	   0.294     0.427	1017
	  1	 0.331	   0.805     0.469	 441

avg / total	 0.642	   0.449     0.439	1458

Testing Accuracy
0.448559670782
